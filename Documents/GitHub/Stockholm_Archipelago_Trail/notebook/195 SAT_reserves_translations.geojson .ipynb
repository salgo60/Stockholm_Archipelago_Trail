{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b19702a8-5c46-48c7-bf2d-886787d0f263",
   "metadata": {},
   "source": [
    "## 195 PoC: Koppla SAT-leden till Naturv√•rdsverkets ‚ÄúSkyddad natur‚Äù + maskin√∂versatta f√∂reskrifter\n",
    "\n",
    "* [Issue 195](ss=\n",
    "\n",
    "[Reservatsnamn]  \n",
    "üìú F√∂reskrifter: [SV]  \n",
    "üåç Maskin√∂versatt: [DA] [NN] [EN] [FR] [ZH] [AR]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760625e5-48e3-4582-84b2-0bb23e368763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25a8dc13-2c25-4123-8c88-3d54788808d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Skrev output/SAT_reserves_translations.geojson med 12 features.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import json, sys, time, re\n",
    "from io import BytesIO, StringIO\n",
    "from urllib.parse import urlencode\n",
    "import requests\n",
    "\n",
    "# --- (valfritt) geopandas f√∂r \"sv√•rare\" P3896-k√§llor (WFS/ZIP) ---\n",
    "try:\n",
    "    import geopandas as gpd        # pip install geopandas\n",
    "except Exception:\n",
    "    gpd = None\n",
    "\n",
    "WIKIDATA_SPARQL = \"https://query.wikidata.org/sparql\"\n",
    "UA = {\"User-Agent\": \"SAT-pipeline/1.0 (contact: your-email@example.com)\"}\n",
    "\n",
    "# Fil att skriva\n",
    "OUTFILE = \"output/SAT_reserves_translations.geojson\"\n",
    "\n",
    "# Spr√•klistor\n",
    "RESIDENT_LANGS = [\"sv\",\"en\",\"ar\",\"fi\",\"so\",\"fa\",\"ckb\",\"ti\",\"pl\",\"tr\",\"es\"]\n",
    "TOURIST_LANGS  = [\"nb\",\"nn\",\"da\",\"fi\",\"de\",\"nl\",\"en\",\"fr\",\"es\",\"it\",\"zh\",\"ja\",\"pl\",\"ru\"]\n",
    "\n",
    "def google_translate_url(src_sv_url: str, tl: str) -> str:\n",
    "    base = \"https://translate.google.com/translate\"\n",
    "    q = {\"hl\": \"sv\", \"sl\": \"sv\", \"tl\": tl, \"u\": src_sv_url}\n",
    "    return f\"{base}?{urlencode(q)}\"\n",
    "\n",
    "def fetch_sparql():\n",
    "    q = \"\"\"\n",
    "    SELECT ?res ?resLabel ?foreskrift ?shape ?coord WHERE {\n",
    "      wd:Q131318799 wdt:P3018 ?res .\n",
    "      OPTIONAL { ?res wdt:P856 ?foreskrift }\n",
    "      OPTIONAL { ?res wdt:P3896 ?shape }\n",
    "      OPTIONAL { ?res wdt:P625 ?coord }\n",
    "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"sv,en\". }\n",
    "    }\n",
    "    \"\"\"\n",
    "    r = requests.get(WIKIDATA_SPARQL, params={\"query\": q, \"format\": \"json\"}, headers=UA, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"results\"][\"bindings\"]\n",
    "\n",
    "def is_commons_map(url: str) -> bool:\n",
    "    # Commons Data namespace .map (GeoJSON)\n",
    "    return (\"commons.wikimedia.org\" in url) and (\"/data/main/Data:\" in url or \"action=raw\" in url) and url.endswith(\".map\")\n",
    "\n",
    "def fetch_geojson_from_url(url: str):\n",
    "    \"\"\"\n",
    "    F√∂rs√∂k h√§mta GeoJSON fr√•n P3896:\n",
    "    - Commons .map (GeoJSON) ‚Üí direkt\n",
    "    - URL som slutar p√• .geojson/.json ‚Üí direkt\n",
    "    - Annars: f√∂rs√∂k geopandas.read_file(url) om geopandas finns\n",
    "    Returnerar FeatureCollection-dict eller None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        r = requests.get(url, headers=UA, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        gj = r.json()\n",
    "        \n",
    "        if gj.get(\"type\") == \"FeatureCollection\":\n",
    "            return gj\n",
    "        if gj.get(\"type\") == \"Feature\":\n",
    "            return {\"type\": \"FeatureCollection\", \"features\": [gj]}\n",
    "        # vissa Commons .map kan vara en lista av features:\n",
    "        if isinstance(gj, list):\n",
    "            return {\"type\": \"FeatureCollection\", \"features\": gj}\n",
    "\n",
    "        if gpd is not None:\n",
    "            # geopandas kan ofta l√§sa WFS/ZIP/SHP via URL\n",
    "            gdf = gpd.read_file(url)\n",
    "            if gdf is None or gdf.empty:\n",
    "                return None\n",
    "            return json.loads(gdf.to_json())\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def parse_point_wkt(wkt: str):\n",
    "    # \"Point(lon lat)\" ‚Üí (lon, lat)\n",
    "    try:\n",
    "        s = wkt.strip()\n",
    "        s = s.replace(\"POINT\", \"Point\")\n",
    "        s = s[s.index(\"(\")+1:s.rindex(\")\")]\n",
    "        lon, lat = [float(x) for x in s.split()]\n",
    "        return lon, lat\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def build_feature_from_point(lon: float, lat: float, props: dict) -> dict:\n",
    "    return {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\"type\": \"Point\", \"coordinates\": [lon, lat]},\n",
    "        \"properties\": props,\n",
    "    }\n",
    "\n",
    "def attach_properties_to_all_features(gj: dict, props: dict) -> dict:\n",
    "    out = {\"type\": \"FeatureCollection\", \"features\": []}\n",
    "    for f in gj.get(\"features\", []):\n",
    "        g = f.get(\"geometry\")\n",
    "        if not g:\n",
    "            continue\n",
    "        p = f.get(\"properties\", {}).copy()\n",
    "        p.update(props)\n",
    "        out[\"features\"].append({\"type\": \"Feature\", \"geometry\": g, \"properties\": p})\n",
    "    return out\n",
    "    \n",
    "import urllib.parse\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "def commons_map_url(in_url: str) -> str:\n",
    "    # Parse input URL\n",
    "    parsed = urlparse(in_url)\n",
    "    \n",
    "    # Extract path after /data/main/\n",
    "    path = parsed.path.split(\"/data/main/\")[-1]\n",
    "    \n",
    "    # Decode percent-encodings (e.g. %C3%B6 ‚Üí √∂)\n",
    "    path = unquote(path)\n",
    "    \n",
    "    # Replace + with _ (Commons convention)\n",
    "    path = path.replace(\"+\", \"_\")\n",
    "    \n",
    "    # Build output URL\n",
    "    out_url = f\"https://commons.wikimedia.org/w/index.php?title={path}&action=raw\"\n",
    "    return out_url\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    rows = fetch_sparql()\n",
    "    features = []\n",
    "\n",
    "    for b in rows:\n",
    "        label = b.get(\"resLabel\", {}).get(\"value\") or \"(namnl√∂s)\"\n",
    "        fores = b.get(\"foreskrift\", {}).get(\"value\")   # SV original\n",
    "        shape = b.get(\"shape\", {}).get(\"value\")\n",
    "        coord = b.get(\"coord\", {}).get(\"value\")\n",
    "\n",
    "        \n",
    "        #print(\"Shapeout\",commons_map_url(shape))\n",
    "        shape = commons_map_url(shape)\n",
    "        # http://commons.wikimedia.org/data/main/Data:/Sweden/Nature+reserves/2020/Fj√§rdl√•ng/2002299.map\n",
    "        # https://commons.wikimedia.org/w/index.php?title=Data:/Sweden/Nature_reserves/2020/Fj%C3%A4rdl%C3%A5ng/2002299.map&action=raw\n",
    "        props = {\n",
    "            \"name\": label,\n",
    "            \"foreskrift_sv\": fores,\n",
    "            \"translations\": {tl: google_translate_url(fores, tl) for tl in sorted(set(RESIDENT_LANGS + TOURIST_LANGS))}\n",
    "                        if fores else {},\n",
    "            \"source\": \"Wikidata P3018/P856/P3896; Commons/GeoJSON d√§r tillg√§ngligt\",\n",
    "        }\n",
    "\n",
    "        # 1) F√∂rs√∂k polygon via P3896\n",
    "        \n",
    "        added = False\n",
    "        if shape:\n",
    "            gj = fetch_geojson_from_url(shape)\n",
    "            \n",
    "            if gj:\n",
    "                gj_props = attach_properties_to_all_features(gj, props)\n",
    "                features.extend(gj_props[\"features\"])\n",
    "                added = True\n",
    "        \n",
    "        # 2) Fallback: punkt fr√•n P625\n",
    "        if not added:\n",
    "            if coord:\n",
    "                pt = parse_point_wkt(coord)\n",
    "                if pt:\n",
    "                    lon, lat = pt\n",
    "                else:\n",
    "                    lon, lat = 18.06, 59.33  # stockholm fallback\n",
    "            else:\n",
    "                lon, lat = 18.06, 59.33\n",
    "            features.append(build_feature_from_point(lon, lat, props))\n",
    "\n",
    "        # H√∂vlig paus s√• vi inte spammar endpoints\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    fc = {\"type\": \"FeatureCollection\", \"features\": features}\n",
    "    # skriv\n",
    "    with open(OUTFILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(fc, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Skrev {OUTFILE} med {len(features)} features.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sys.exit(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e3c3b57-7187-4d0a-8fb5-14b859658df2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 187\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Skrev \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTFILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m med \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSystemExit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%tb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693d177-f14f-4421-8932-e7525e9174d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
