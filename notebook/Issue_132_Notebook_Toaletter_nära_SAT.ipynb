{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79dc2ee3-82e9-44fe-9c85-e0f49b8a35e8",
   "metadata": {},
   "source": [
    "# Issue 132 Notebook Toaletter nÃ¤ra SAT\n",
    "* denna [Notebook](https://github.com/salgo60/Stockholm_Archipelago_Trail/blob/main/notebook/Issue_132_Notebook_Toaletter_n%C3%A4ra_SAT.ipynb)\n",
    "* [Issue 132](https://github.com/salgo60/Stockholm_Archipelago_Trail/issues/132)\n",
    "\n",
    "Se liknande lÃ¶sning fÃ¶r Roslagsleden\n",
    "* nu har vi SAT = wikidata [Q131318799](https://www.wikidata.org/wiki/Q131318799)\n",
    "* \"leden\" sitter inte ihop utan varje Ã¶ har sitt segment\n",
    "\n",
    "Jmf dricksvatten [Issue 139](https://github.com/salgo60/Stockholm_Archipelago_Trail/issues/139) \n",
    "\n",
    "\n",
    "Output \n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_07_28_17_12.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_07_28_17_12.html)\n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_07_30_04_22.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_07_30_04_22.html)\n",
    "* [kartor/Issue_132_2_toaletter_nara_stockholm_archipelago_trail_2025_07_30_07_16.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_2_toaletter_nara_stockholm_archipelago_trail_2025_07_30_07_16.html)\n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_17_19_29.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_17_19_29.html)\n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_16_01.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_16_01.html)\n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_23_14.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_23_14.html)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd494e0-4277-42cd-8f35-d97c83229c07",
   "metadata": {},
   "source": [
    "version 0.1\n",
    "* unary_union --> union_all\n",
    "* start updating OSM with pictures from https://commons.wikimedia.org/wiki/Category:SAT_Todo\n",
    "* also count number of seats ie. toilets:number\n",
    "* Fetch SAT etapper via Wikidata\n",
    "* Fetch geometries per relation via Overpass (no zip-mismatch)\n",
    "* Buffer 200 m (Shapely â‰¥2 with union_all())\n",
    "* Fetch toilets as nodes/ways/relations via nwr[...] out center;\n",
    "* Count toilets via toilets:number (fallback male/female/unisex â†’ else 1)\n",
    "* Join to nearest etapp, build summary (CSV)\n",
    "* Build a Folium map with etapper, 200 m buffer, and toilet markers\n",
    "* Export toilets within 200 m as GeoJSON + CSV and save the map HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98b8e5d-53c1-4e11-b150-d75fdeabad97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2025-08-19 23:14:41\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = now.timestamp()\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Start:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d9fdf5-e47f-46be-afbb-2b0735aed757",
   "metadata": {},
   "source": [
    "### New code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d1c0e4-1210-48ed-9fc5-d83b9f09f039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” HÃ¤mtar SAT-etapper frÃ¥n Wikidata...\n",
      "âœ… Hittade 20 etapper med OSM-relationer\n",
      "ðŸ“¡ HÃ¤mtar geometrier frÃ¥n Overpass (per relation)...\n",
      "ðŸ§­ Etapper med geometri: 20\n",
      "ðŸ§® Skapar 200 m-buffert och 200â€“400 m-ring...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fd/md6r13sj0wsbg_6_xl160d300000gn/T/ipykernel_22615/3790676905.py:95: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  buffer_utm_200_u = buffer_utm_200.unary_union\n",
      "/var/folders/fd/md6r13sj0wsbg_6_xl160d300000gn/T/ipykernel_22615/3790676905.py:96: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  buffer_utm_400_u = buffer_utm_400.unary_union\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš½ HÃ¤mtar toaletter (nwr) frÃ¥n Overpass...\n",
      "âœ… Hittade 721 toalett-objekt inom bbox\n",
      "âœ… 96 toalett-objekt inom/vid 200 m\n",
      "âœ… 9 toalett-objekt inom 200â€“400 m\n",
      "ðŸ“Š Summary (â‰¤200 m):\n",
      "            label     island  sites  toilets_total  avg_distance_m  \\\n",
      "10    SAT NÃ¥ttarÃ¶    NÃ¥ttarÃ¶     11             25       72.232629   \n",
      "1    SAT Finnhamn   Finnhamn     16             17       29.151231   \n",
      "2   SAT FjÃ¤rdlÃ¥ng  FjÃ¤rdlÃ¥ng     10             14       50.783603   \n",
      "4      SAT Grinda     Grinda     12             12       31.417178   \n",
      "0     SAT Arholma    Arholma      9             11       39.197231   \n",
      "12       SAT RÃ¥nÃ¶       RÃ¥nÃ¶      6              8       32.477367   \n",
      "14        SAT UtÃ¶        UtÃ¶      7              7       17.529076   \n",
      "5    SAT IngmarsÃ¶   IngmarsÃ¶      5              5       24.822614   \n",
      "13   SAT Sandhamn     SandÃ¶n      4              4       16.953942   \n",
      "7        SAT LidÃ¶       LidÃ¶      3              3       47.205404   \n",
      "8        SAT MÃ¶ja       MÃ¶ja      3              3       17.928814   \n",
      "16        SAT Ã…lÃ¶        Ã…lÃ¶      3              3       35.464055   \n",
      "6    SAT Landsort        Ã–ja      2              2       16.946321   \n",
      "9       SAT NÃ¤mdÃ¶      NÃ¤mdÃ¶      2              2        8.259667   \n",
      "3    SAT Furusund   Furusund      1              1       16.958877   \n",
      "11       SAT OrnÃ¶       OrnÃ¶      1              1        4.276034   \n",
      "15      SAT Yxlan      Yxlan      1              1       94.323707   \n",
      "\n",
      "    avg_toilets_per_site  \n",
      "10              2.272727  \n",
      "1               1.062500  \n",
      "2               1.400000  \n",
      "4               1.000000  \n",
      "0               1.222222  \n",
      "12              1.333333  \n",
      "14              1.000000  \n",
      "5               1.000000  \n",
      "13              1.000000  \n",
      "7               1.000000  \n",
      "8               1.000000  \n",
      "16              1.000000  \n",
      "6               1.000000  \n",
      "9               1.000000  \n",
      "3               1.000000  \n",
      "11              1.000000  \n",
      "15              1.000000  \n",
      "ðŸ§¾ Basic CSV (â‰¤200 m): ../kartor/sat_toaletter_basic_tags_0_200_2025_08_19_23_14.csv\n",
      "ðŸ§¾ Basic CSV (200â€“400 m): ../kartor/sat_toaletter_basic_tags_200_400_2025_08_19_23_14.csv\n",
      "âœ… Klart!\n",
      "â€¢ Summary CSV (â‰¤200 m): ../kartor/sat_toaletter_summary_2025_08_19_23_14.csv\n",
      "â€¢ Toilets GeoJSON â‰¤200 m: ../kartor/sat_toaletter_inrange_0_200_2025_08_19_23_14.geojson\n",
      "â€¢ Toilets CSV â‰¤200 m: ../kartor/sat_toaletter_inrange_0_200_2025_08_19_23_14.csv\n",
      "â€¢ Toilets GeoJSON 200â€“400 m: ../kartor/sat_toaletter_inrange_200_400_2025_08_19_23_14.geojson\n",
      "â€¢ Toilets CSV 200â€“400 m: ../kartor/sat_toaletter_inrange_200_400_2025_08_19_23_14.csv\n",
      "â€¢ Basic CSV â‰¤200 m: ../kartor/sat_toaletter_basic_tags_0_200_2025_08_19_23_14.csv\n",
      "â€¢ Basic CSV 200â€“400 m: ../kartor/sat_toaletter_basic_tags_200_400_2025_08_19_23_14.csv\n",
      "â€¢ Karta: ../kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_23_14.html\n"
     ]
    }
   ],
   "source": [
    "# !pip install geopandas shapely folium requests SPARQLWrapper --quiet\n",
    "\n",
    "import os, re, requests, html\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString, MultiLineString, Point, mapping\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import folium\n",
    "from folium import Marker, Icon, FeatureGroup, LayerControl, Popup\n",
    "from datetime import datetime\n",
    "\n",
    "# =========================\n",
    "# 1) HÃ¤mta SAT-etapper via Wikidata\n",
    "# =========================\n",
    "print(\"ðŸ” HÃ¤mtar SAT-etapper frÃ¥n Wikidata...\")\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "SELECT ?item ?itemLabel ?islandLabel ?osmid WHERE {\n",
    "  ?item wdt:P361 wd:Q131318799;\n",
    "        wdt:P31 wd:Q2143825;\n",
    "        wdt:P402 ?osmid.\n",
    "  OPTIONAL { ?item wdt:P706 ?island. }\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"sv,en\". }\n",
    "}\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "etapper = []\n",
    "for r in results[\"results\"][\"bindings\"]:\n",
    "    etapper.append({\n",
    "        \"id\": r[\"osmid\"][\"value\"],\n",
    "        \"label\": r.get(\"itemLabel\", {}).get(\"value\", \"\"),\n",
    "        \"island\": r.get(\"islandLabel\", {}).get(\"value\", \"\")\n",
    "    })\n",
    "osm_ids = [e['id'] for e in etapper]\n",
    "print(f\"âœ… Hittade {len(osm_ids)} etapper med OSM-relationer\")\n",
    "\n",
    "# =========================\n",
    "# 2) HÃ¤mta geometrier per relation via Overpass\n",
    "# =========================\n",
    "print(\"ðŸ“¡ HÃ¤mtar geometrier frÃ¥n Overpass (per relation)...\")\n",
    "overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "geom_per_rel = {}\n",
    "all_lines = []\n",
    "\n",
    "for rel_id in osm_ids:\n",
    "    q = f\"\"\"\n",
    "    [out:json][timeout:60];\n",
    "    relation({rel_id});\n",
    "    (._;>>;);\n",
    "    out geom;\n",
    "    \"\"\"\n",
    "    r = requests.post(overpass_url, data={\"data\": q})\n",
    "    if r.status_code != 200:\n",
    "        print(f\"âš ï¸ Fel fÃ¶r relation {rel_id}: {r.text[:200]}...\")\n",
    "        continue\n",
    "    rel_geoms = []\n",
    "    for el in r.json().get(\"elements\", []):\n",
    "        if el.get(\"type\") == \"way\" and \"geometry\" in el:\n",
    "            coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in el[\"geometry\"]]\n",
    "            if len(coords) >= 2:\n",
    "                line = LineString(coords)\n",
    "                rel_geoms.append(line)\n",
    "                all_lines.append(line)\n",
    "    if rel_geoms:\n",
    "        geom_per_rel[rel_id] = rel_geoms\n",
    "\n",
    "if not all_lines:\n",
    "    raise ValueError(\"Inga geometrier hittades frÃ¥n OSM-relationer kopplade via Wikidata.\")\n",
    "\n",
    "# Bygg MultiLineString/LineString per etapp\n",
    "meta_rows, geom_rows = [], []\n",
    "for meta in etapper:\n",
    "    geoms = geom_per_rel.get(meta[\"id\"])\n",
    "    if not geoms:\n",
    "        print(f\"âš ï¸ Saknar geometri fÃ¶r {meta['label']} (rel {meta['id']}) â€“ hoppar Ã¶ver.\")\n",
    "        continue\n",
    "    meta_rows.append(meta)\n",
    "    geom_rows.append(MultiLineString(geoms) if len(geoms) > 1 else geoms[0])\n",
    "\n",
    "gdf_trail = gpd.GeoDataFrame(geometry=all_lines, crs=\"EPSG:4326\")\n",
    "meta_gdf = gpd.GeoDataFrame(meta_rows, geometry=geom_rows, crs=\"EPSG:4326\")\n",
    "print(f\"ðŸ§­ Etapper med geometri: {len(meta_gdf)}\")\n",
    "\n",
    "# =========================\n",
    "# 3) Buffert 200 m + ring 200â€“400 m\n",
    "# =========================\n",
    "print(\"ðŸ§® Skapar 200 m-buffert och 200â€“400 m-ring...\")\n",
    "trail_utm = gdf_trail.to_crs(3006)\n",
    "buffer_utm_200 = trail_utm.buffer(200)\n",
    "buffer_utm_400 = trail_utm.buffer(400)\n",
    "\n",
    "# Unionera respektive buffert till en geometri\n",
    "buffer_utm_200_u = buffer_utm_200.unary_union\n",
    "buffer_utm_400_u = buffer_utm_400.unary_union\n",
    "\n",
    "# Ring = 400m minus 200m\n",
    "ring_utm = buffer_utm_400_u.difference(buffer_utm_200_u)\n",
    "\n",
    "# Tillbaka till WGS84\n",
    "buffer_union = gpd.GeoSeries([buffer_utm_200_u], crs=3006).to_crs(4326).iloc[0]\n",
    "ring_union = gpd.GeoSeries([ring_utm], crs=3006).to_crs(4326).iloc[0]\n",
    "\n",
    "# =========================\n",
    "# 4) HÃ¤mta toaletter (nwr + out center) i bbox\n",
    "# =========================\n",
    "def _parse_int(v):\n",
    "    if v is None:\n",
    "        return None\n",
    "    m = re.search(r\"\\d+\", str(v))\n",
    "    return int(m.group()) if m else None\n",
    "\n",
    "def toilets_count_from_tags(tags: dict) -> int:\n",
    "    n = _parse_int(tags.get(\"toilets:number\"))\n",
    "    if n is not None:\n",
    "        return n\n",
    "    parts = [\n",
    "        _parse_int(tags.get(\"male:toilets\")),\n",
    "        _parse_int(tags.get(\"female:toilets\")),\n",
    "        _parse_int(tags.get(\"unisex:toilets\")),\n",
    "    ]\n",
    "    parts = [p for p in parts if p is not None]\n",
    "    if parts:\n",
    "        return sum(parts)\n",
    "    return 1\n",
    "\n",
    "bbox = gdf_trail.total_bounds  # [minx, miny, maxx, maxy]\n",
    "q_toilets = f\"\"\"\n",
    "[out:json][timeout:60];\n",
    "nwr[\"amenity\"=\"toilets\"]({bbox[1]},{bbox[0]},{bbox[3]},{bbox[2]});\n",
    "out center;\n",
    "\"\"\"\n",
    "print(\"ðŸš½ HÃ¤mtar toaletter (nwr) frÃ¥n Overpass...\")\n",
    "r = requests.post(overpass_url, data={\"data\": q_toilets})\n",
    "elements = r.json().get(\"elements\", [])\n",
    "toilets = []\n",
    "for el in elements:\n",
    "    tags = el.get(\"tags\", {})\n",
    "    typ = el.get(\"type\")\n",
    "    if typ == \"node\":\n",
    "        lon, lat = el[\"lon\"], el[\"lat\"]\n",
    "    else:\n",
    "        center = el.get(\"center\")\n",
    "        if not center:\n",
    "            continue\n",
    "        lon, lat = center[\"lon\"], center[\"lat\"]\n",
    "    toilets.append({\n",
    "        \"geometry\": Point(lon, lat),\n",
    "        \"tags\": tags,\n",
    "        \"id\": el[\"id\"],\n",
    "        \"osm_type\": typ,\n",
    "        \"toilets_num\": toilets_count_from_tags(tags),\n",
    "    })\n",
    "\n",
    "gdf_toilets = gpd.GeoDataFrame(toilets, crs=\"EPSG:4326\")\n",
    "print(f\"âœ… Hittade {len(gdf_toilets)} toalett-objekt inom bbox\")\n",
    "\n",
    "# =========================\n",
    "# 5) Dela upp: inom â‰¤200 m och i ringen 200â€“400 m\n",
    "# =========================\n",
    "in_0_200 = gdf_toilets[gdf_toilets.geometry.covered_by(buffer_union)]\n",
    "in_200_400 = gdf_toilets[gdf_toilets.geometry.covered_by(ring_union)]\n",
    "print(f\"âœ… {len(in_0_200)} toalett-objekt inom/vid 200 m\")\n",
    "print(f\"âœ… {len(in_200_400)} toalett-objekt inom 200â€“400 m\")\n",
    "\n",
    "# =========================\n",
    "# 6) NÃ¤rmaste etapp per kategori\n",
    "# =========================\n",
    "meta_utm = meta_gdf.to_crs(3006)\n",
    "toilets_utm_0_200 = in_0_200.to_crs(3006)\n",
    "toilets_utm_200_400 = in_200_400.to_crs(3006)\n",
    "\n",
    "joined_0_200 = gpd.sjoin_nearest(\n",
    "    toilets_utm_0_200,\n",
    "    meta_utm[[\"label\", \"island\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    distance_col=\"distance_m\"\n",
    ").to_crs(4326)\n",
    "\n",
    "joined_200_400 = gpd.sjoin_nearest(\n",
    "    toilets_utm_200_400,\n",
    "    meta_utm[[\"label\", \"island\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    distance_col=\"distance_m\"\n",
    ").to_crs(4326)\n",
    "\n",
    "# =========================\n",
    "# 7) Summary fÃ¶r â‰¤200 m\n",
    "# =========================\n",
    "summary = (\n",
    "    joined_0_200.assign(toilets_num=joined_0_200[\"toilets_num\"].fillna(1))\n",
    "    .groupby([\"label\", \"island\"], as_index=False)\n",
    "    .agg(\n",
    "        sites=(\"geometry\", \"count\"),\n",
    "        toilets_total=(\"toilets_num\", \"sum\"),\n",
    "        avg_distance_m=(\"distance_m\", \"mean\"),\n",
    "    )\n",
    "    .assign(avg_toilets_per_site=lambda df: df[\"toilets_total\"] / df[\"sites\"])\n",
    "    .sort_values([\"toilets_total\", \"sites\"], ascending=[False, False])\n",
    ")\n",
    "print(\"ðŸ“Š Summary (â‰¤200 m):\")\n",
    "print(summary.head(1000))\n",
    "\n",
    "# =========================\n",
    "# 8) Spara filer + grundkarta\n",
    "# =========================\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "os.makedirs(\"../kartor\", exist_ok=True)\n",
    "\n",
    "summary_csv = f\"../kartor/sat_toaletter_summary_{timestamp}.csv\"\n",
    "summary.to_csv(summary_csv, index=False)\n",
    "\n",
    "toilets_geojson_0_200 = f\"../kartor/sat_toaletter_inrange_0_200_{timestamp}.geojson\"\n",
    "toilets_csv_0_200 = f\"../kartor/sat_toaletter_inrange_0_200_{timestamp}.csv\"\n",
    "in_0_200[[\"id\", \"osm_type\", \"toilets_num\", \"tags\", \"geometry\"]].to_file(toilets_geojson_0_200, driver=\"GeoJSON\")\n",
    "in_0_200.drop(columns=\"geometry\").to_csv(toilets_csv_0_200, index=False)\n",
    "\n",
    "toilets_geojson_200_400 = f\"../kartor/sat_toaletter_inrange_200_400_{timestamp}.geojson\"\n",
    "toilets_csv_200_400 = f\"../kartor/sat_toaletter_inrange_200_400_{timestamp}.csv\"\n",
    "in_200_400[[\"id\", \"osm_type\", \"toilets_num\", \"tags\", \"geometry\"]].to_file(toilets_geojson_200_400, driver=\"GeoJSON\")\n",
    "in_200_400.drop(columns=\"geometry\").to_csv(toilets_csv_200_400, index=False)\n",
    "\n",
    "# Bygg karta\n",
    "center = gdf_trail.geometry.union_all().centroid\n",
    "m = folium.Map(location=[center.y, center.x], zoom_start=9, control_scale=True)\n",
    "\n",
    "# Etapper\n",
    "colors = [\n",
    "    \"blue\",\"green\",\"purple\",\"orange\",\"darkred\",\"cadetblue\",\"lightgray\",\"darkblue\",\n",
    "    \"darkgreen\",\"pink\",\"lightblue\",\"lightgreen\",\"gray\",\"black\",\"beige\",\"lightred\"\n",
    "]\n",
    "for i, row in meta_gdf.reset_index(drop=True).iterrows():\n",
    "    color = colors[i % len(colors)]\n",
    "    popup = f\"<b>{html.escape(row['label'])}</b><br>Ã–: {html.escape(row['island'])}\"\n",
    "    folium.GeoJson(\n",
    "        data=mapping(row.geometry),\n",
    "        name=row[\"label\"],\n",
    "        style_function=lambda x, c=color: {\"color\": c, \"weight\": 3}\n",
    "    ).add_child(folium.Popup(popup, max_width=350)).add_to(m)\n",
    "\n",
    "# Buffert-lager (200 m och 200â€“400 m)\n",
    "folium.GeoJson(\n",
    "    data=mapping(buffer_union),\n",
    "    name=\"200 m Buffert\",\n",
    "    style_function=lambda x: {'fillColor': '#0000ff', 'color': '#0000ff', 'weight': 1, 'fillOpacity': 0.1}\n",
    ").add_to(m)\n",
    "\n",
    "folium.GeoJson(\n",
    "    data=mapping(ring_union),\n",
    "    name=\"Ring 200â€“400 m\",\n",
    "    style_function=lambda x: {'fillColor': '#ffa500', 'color': '#ffa500', 'weight': 1, 'fillOpacity': 0.1}\n",
    ").add_to(m)\n",
    "\n",
    "# =========================\n",
    "# 9) Commons helpers (FIX: support Category and avoid double-encoding)\n",
    "# =========================\n",
    "def _quote_commons(title: str) -> str:\n",
    "    # keep existing % escapes to avoid double-encoding already-encoded titles\n",
    "    return requests.utils.quote(title, safe=':/%')\n",
    "\n",
    "def commons_title_to_page(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Returnera korrekt Commons-sida (File:/Image:/Category:/etc).\n",
    "    - Om 'Category:' -> /wiki/Category:...\n",
    "    - Om File:/Image: -> /wiki/File:...\n",
    "    - Om ingen prefix -> anta File:\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        return None\n",
    "    t = title.strip()\n",
    "    low = t.lower()\n",
    "    if low.startswith((\"category:\", \"file:\", \"image:\")):\n",
    "        return f\"https://commons.wikimedia.org/wiki/{_quote_commons(t)}\"\n",
    "    # default: tolkas som fil\n",
    "    return f\"https://commons.wikimedia.org/wiki/{_quote_commons('File:' + t)}\"\n",
    "\n",
    "def commons_title_to_filepath(title: str, thumb_width=400) -> str | None:\n",
    "    \"\"\"\n",
    "    Thumbnail-url via Special:FilePath â€” GÃ„LLER BARA filer.\n",
    "    Om titeln Ã¤r en Category, returnera None (ingen direkt bild).\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        return None\n",
    "    t = title.strip()\n",
    "    low = t.lower()\n",
    "    if low.startswith(\"category:\"):\n",
    "        return None\n",
    "    if not low.startswith((\"file:\", \"image:\")):\n",
    "        t = \"File:\" + t\n",
    "    return f\"https://commons.wikimedia.org/wiki/Special:FilePath/{_quote_commons(t)}?width={thumb_width}\"\n",
    "\n",
    "# Wikidata P18 â†’ Commons thumbnail (ofÃ¶rÃ¤ndrat i sak)\n",
    "_wikidata_image_cache = {}\n",
    "def wikidata_p18_thumb(qid: str, thumb_width=400) -> str | None:\n",
    "    if not qid:\n",
    "        return None\n",
    "    qid = qid.strip()\n",
    "    if qid in _wikidata_image_cache:\n",
    "        return _wikidata_image_cache[qid]\n",
    "    try:\n",
    "        url = f\"https://www.wikidata.org/wiki/Special:EntityData/{qid}.json\"\n",
    "        data = requests.get(url, timeout=15).json()\n",
    "        ent = data.get(\"entities\", {}).get(qid, {})\n",
    "        p18 = ent.get(\"claims\", {}).get(\"P18\", [])\n",
    "        if not p18:\n",
    "            _wikidata_image_cache[qid] = None\n",
    "            return None\n",
    "        filename = p18[0][\"mainsnak\"][\"datavalue\"][\"value\"]\n",
    "        img_url = commons_title_to_filepath(filename, thumb_width=thumb_width)\n",
    "        _wikidata_image_cache[qid] = img_url\n",
    "        return img_url\n",
    "    except Exception:\n",
    "        _wikidata_image_cache[qid] = None\n",
    "        return None\n",
    "\n",
    "def best_image_url_from_tags(tags: dict) -> str | None:\n",
    "    \"\"\"\n",
    "    Prioritet: image=* URL â†’ image=* (File/Image title) â†’ wikimedia_commons=* (om fil) â†’ wikidata P18\n",
    "    OBS: Om wikimedia_commons bÃ¶rjar med Category: returnera ingen bild (endast lÃ¤nk i popup).\n",
    "    \"\"\"\n",
    "    if not tags:\n",
    "        return None\n",
    "    # 1) image=*\n",
    "    if \"image\" in tags and str(tags[\"image\"]).strip():\n",
    "        first = str(tags[\"image\"]).split(\";\")[0].strip()\n",
    "        if first.lower().startswith((\"http://\", \"https://\")):\n",
    "            return first\n",
    "        # tolka som commons-titel\n",
    "        return commons_title_to_filepath(first)\n",
    "    # 2) wikimedia_commons=*\n",
    "    if \"wikimedia_commons\" in tags and str(tags[\"wikimedia_commons\"]).strip():\n",
    "        title = str(tags[\"wikimedia_commons\"]).strip()\n",
    "        thumb = commons_title_to_filepath(title)  # None if Category\n",
    "        if thumb:\n",
    "            return thumb\n",
    "    # 3) wikidata â†’ P18\n",
    "    if \"wikidata\" in tags and str(tags[\"wikidata\"]).strip():\n",
    "        return wikidata_p18_thumb(tags[\"wikidata\"])\n",
    "    return None\n",
    "\n",
    "# =========================\n",
    "# 10) Taggar & QA\n",
    "# =========================\n",
    "BASIC_TAGS = [\n",
    "    \"amenity\", \"access\", \"opening_hours\", \"fee\", \"wheelchair\",\n",
    "    \"toilets:number\", \"unisex\", \"drinking_water\", \"changing_table\",\n",
    "    \"toilet:paper\", \"indoor\", \"operator\", \"website\", \"source\"\n",
    "]\n",
    "\n",
    "def missing_tags(tags: dict) -> list:\n",
    "    missing = []\n",
    "    tags = tags or {}\n",
    "    for k in BASIC_TAGS:\n",
    "        if k == \"amenity\":\n",
    "            if tags.get(\"amenity\") != \"toilets\":\n",
    "                missing.append(\"amenity=toilets\")\n",
    "            continue\n",
    "        v = tags.get(k)\n",
    "        if v is None or str(v).strip() == \"\":\n",
    "            missing.append(k)\n",
    "    if \"unisex\" in missing and ((\"male\" in tags or \"male:toilets\" in tags) and (\"female\" in tags or \"female:toilets\" in tags)):\n",
    "        try:\n",
    "            missing.remove(\"unisex\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return missing\n",
    "\n",
    "def build_basic_table(joined_df):\n",
    "    tag_cols = [\n",
    "        \"access\",\"opening_hours\",\"fee\",\"wheelchair\",\"toilets:number\",\"unisex\",\n",
    "        \"drinking_water\",\"changing_table\",\"toilet:paper\",\"indoor\",\"operator\",\"website\",\"source\",\n",
    "        \"wikidata\",\"wikimedia_commons\",\"image\"\n",
    "    ]\n",
    "    rows = []\n",
    "    for _, r in joined_df.to_crs(4326).iterrows():\n",
    "        tags = r.get(\"tags\", {}) or {}\n",
    "        commons_title = str(tags.get(\"wikimedia_commons\") or \"\").strip() or None\n",
    "        commons_page_url = commons_title_to_page(commons_title) if commons_title else None\n",
    "\n",
    "        img_url = best_image_url_from_tags(tags)\n",
    "        miss = missing_tags(tags)\n",
    "        row = {\n",
    "            \"id\": r[\"id\"],\n",
    "            \"osm_type\": r[\"osm_type\"],\n",
    "            \"lat\": r.geometry.y,\n",
    "            \"lon\": r.geometry.x,\n",
    "            \"label\": r.get(\"label\", \"\"),\n",
    "            \"island\": r.get(\"island\", \"\"),\n",
    "            \"distance_m\": round(float(r.get(\"distance_m\", 0)), 1),\n",
    "            \"toilets_num\": int(r.get(\"toilets_num\", 1)),\n",
    "            \"image_url\": img_url,\n",
    "            \"missing_tags\": \", \".join(miss),\n",
    "            \"wikimedia_commons_title\": commons_title,\n",
    "            \"wikimedia_commons_url\": commons_page_url\n",
    "        }\n",
    "        for k in tag_cols:\n",
    "            row[k] = (tags.get(k) if isinstance(tags, dict) else None)\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# =========================\n",
    "# 11) Bygg tabeller och lager fÃ¶r â‰¤200 m och 200â€“400 m\n",
    "# =========================\n",
    "basic_df_0_200 = build_basic_table(joined_0_200)\n",
    "basic_df_200_400 = build_basic_table(joined_200_400)\n",
    "\n",
    "basic_csv_0_200 = f\"../kartor/sat_toaletter_basic_tags_0_200_{timestamp}.csv\"\n",
    "basic_df_0_200.to_csv(basic_csv_0_200, index=False)\n",
    "basic_csv_200_400 = f\"../kartor/sat_toaletter_basic_tags_200_400_{timestamp}.csv\"\n",
    "basic_df_200_400.to_csv(basic_csv_200_400, index=False)\n",
    "\n",
    "print(\"ðŸ§¾ Basic CSV (â‰¤200 m):\", basic_csv_0_200)\n",
    "print(\"ðŸ§¾ Basic CSV (200â€“400 m):\", basic_csv_200_400)\n",
    "\n",
    "def add_markers(df, feature_group, marker_color):\n",
    "    for _, r in df.iterrows():\n",
    "        osm_url = f\"https://www.openstreetmap.org/{'node' if r['osm_type']=='node' else 'way' if r['osm_type']=='way' else 'relation'}/{r['id']}\"\n",
    "        img_html = f'<div style=\"margin:6px 0\"><img src=\"{html.escape(str(r[\"image_url\"]))}\" referrerpolicy=\"no-referrer\" style=\"max-width:280px; height:auto; display:block;\"/></div>' if r.get(\"image_url\") else \"\"\n",
    "        miss_html = f\"<div style='color:#b00; margin-top:4px'><b>Saknade taggar:</b> {html.escape(str(r['missing_tags']))}</div>\" if r.get(\"missing_tags\") else \"\"\n",
    "        commons_html = \"\"\n",
    "        if r.get(\"wikimedia_commons_url\"):\n",
    "            title = r.get(\"wikimedia_commons_title\") or \"Wikimedia Commons\"\n",
    "            commons_html = f'<div style=\"margin-top:4px\">ðŸ“· <a href=\"{html.escape(str(r[\"wikimedia_commons_url\"]))}\" target=\"_blank\">{html.escape(str(title))}</a></div>'\n",
    "        kv = []\n",
    "        for k in [\"opening_hours\",\"fee\",\"wheelchair\",\"access\",\"toilets:number\",\"unisex\",\"drinking_water\",\"changing_table\"]:\n",
    "            v = r.get(k)\n",
    "            if pd.notna(v) and str(v).strip() != \"\":\n",
    "                kv.append(f\"{k}={html.escape(str(v))}\")\n",
    "        kv_html = (\"<div>\" + \"<br>\".join(kv) + \"</div>\") if kv else \"\"\n",
    "        popup_html = f\"\"\"\n",
    "        <div style=\"font-size:13px; line-height:1.4\">\n",
    "          <b><a href=\"{osm_url}\" target=\"_blank\">OSM ({r['osm_type']}) {int(r['id'])}</a></b><br>\n",
    "          Etapp: <b>{html.escape(str(r.get('label') or ''))}</b> (Ã–: {html.escape(str(r.get('island') or ''))})<br>\n",
    "          AvstÃ¥nd: ~{r['distance_m']} m<br>\n",
    "          Antal toaletter: <b>{int(r['toilets_num'])}</b>\n",
    "          {img_html}\n",
    "          {kv_html}\n",
    "          {commons_html}\n",
    "          {miss_html}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        Marker(\n",
    "            location=[r[\"lat\"], r[\"lon\"]],\n",
    "            popup=Popup(popup_html, max_width=320),\n",
    "            icon=Icon(color=marker_color, icon=\"info-sign\")\n",
    "        ).add_to(feature_group)\n",
    "\n",
    "# â‰¤200 m lager\n",
    "toilets_pic_fg_0_200 = FeatureGroup(name=\"Toaletter â‰¤200 m (bild, Commons, saknade taggar)\")\n",
    "add_markers(basic_df_0_200, toilets_pic_fg_0_200, marker_color=\"darkblue\")\n",
    "toilets_pic_fg_0_200.add_to(m)\n",
    "\n",
    "# 200â€“400 m lager\n",
    "toilets_pic_fg_200_400 = FeatureGroup(name=\"Toaletter 200â€“400 m (bild, Commons, saknade taggar)\")\n",
    "add_markers(basic_df_200_400, toilets_pic_fg_200_400, marker_color=\"orange\")\n",
    "toilets_pic_fg_200_400.add_to(m)\n",
    "\n",
    "LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# =========================\n",
    "# 12) Spara karta + output\n",
    "# =========================\n",
    "map_html = f\"../kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_{timestamp}.html\"\n",
    "m.save(map_html)\n",
    "\n",
    "print(\"âœ… Klart!\")\n",
    "print(f\"â€¢ Summary CSV (â‰¤200 m): {summary_csv}\")\n",
    "print(f\"â€¢ Toilets GeoJSON â‰¤200 m: {toilets_geojson_0_200}\")\n",
    "print(f\"â€¢ Toilets CSV â‰¤200 m: {toilets_csv_0_200}\")\n",
    "print(f\"â€¢ Toilets GeoJSON 200â€“400 m: {toilets_geojson_200_400}\")\n",
    "print(f\"â€¢ Toilets CSV 200â€“400 m: {toilets_csv_200_400}\")\n",
    "print(f\"â€¢ Basic CSV â‰¤200 m: {basic_csv_0_200}\")\n",
    "print(f\"â€¢ Basic CSV 200â€“400 m: {basic_csv_200_400}\")\n",
    "print(f\"â€¢ Karta: {map_html}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ecd8aa2-fd2f-4792-9715-4f7bb4af6fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2025-08-19 23:14:57\n",
      "Total time elapsed: 15.51 seconds\n"
     ]
    }
   ],
   "source": [
    " # End timer and calculate duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print current date and total time\n",
    "print(\"Date:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5827d-1e5e-4ae2-9bb8-49bbc70cfa77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
