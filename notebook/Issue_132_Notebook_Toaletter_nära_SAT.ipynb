{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79dc2ee3-82e9-44fe-9c85-e0f49b8a35e8",
   "metadata": {},
   "source": [
    "# Issue 132 Notebook Toaletter n√§ra SAT\n",
    "* denna [Notebook](https://github.com/salgo60/Stockholm_Archipelago_Trail/blob/main/notebook/Issue_132_Notebook_Toaletter_n%C3%A4ra_SAT.ipynb)\n",
    "* [Issue 132](https://github.com/salgo60/Stockholm_Archipelago_Trail/issues/132)\n",
    "\n",
    "Se liknande l√∂sning f√∂r Roslagsleden\n",
    "* nu har vi SAT = wikidata [Q131318799](https://www.wikidata.org/wiki/Q131318799)\n",
    "* \"leden\" sitter inte ihop utan varje √∂ har sitt segment\n",
    "\n",
    "Jmf dricksvatten [Issue 139](https://github.com/salgo60/Stockholm_Archipelago_Trail/issues/139) \n",
    "\n",
    "\n",
    "Output \n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_07_28_17_12.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_07_28_17_12.html)\n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_07_30_04_22.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_07_30_04_22.html)\n",
    "* [kartor/Issue_132_2_toaletter_nara_stockholm_archipelago_trail_2025_07_30_07_16.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_2_toaletter_nara_stockholm_archipelago_trail_2025_07_30_07_16.html)\n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_17_19_29.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_17_19_29.html)\n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_16_01.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_16_01.html)\n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_23_14.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_23_14.html)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd494e0-4277-42cd-8f35-d97c83229c07",
   "metadata": {},
   "source": [
    "version 0.1\n",
    "* unary_union --> union_all\n",
    "* start updating OSM with pictures from https://commons.wikimedia.org/wiki/Category:SAT_Todo\n",
    "* also count number of seats ie. toilets:number\n",
    "* Fetch SAT etapper via Wikidata\n",
    "* Fetch geometries per relation via Overpass (no zip-mismatch)\n",
    "* Buffer 200 m (Shapely ‚â•2 with union_all())\n",
    "* Fetch toilets as nodes/ways/relations via nwr[...] out center;\n",
    "* Count toilets via toilets:number (fallback male/female/unisex ‚Üí else 1)\n",
    "* Join to nearest etapp, build summary (CSV)\n",
    "* Build a Folium map with etapper, 200 m buffer, and toilet markers\n",
    "* Export toilets within 200 m as GeoJSON + CSV and save the map HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98b8e5d-53c1-4e11-b150-d75fdeabad97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2025-08-19 23:14:41\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = now.timestamp()\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Start:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d9fdf5-e47f-46be-afbb-2b0735aed757",
   "metadata": {},
   "source": [
    "### New code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d1c0e4-1210-48ed-9fc5-d83b9f09f039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç H√§mtar SAT-etapper fr√•n Wikidata...\n",
      "‚úÖ Hittade 20 etapper med OSM-relationer\n",
      "üì° H√§mtar geometrier fr√•n Overpass (per relation)...\n",
      "üß≠ Etapper med geometri: 20\n",
      "üßÆ Skapar 200 m-buffert och 200‚Äì400 m-ring...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fd/md6r13sj0wsbg_6_xl160d300000gn/T/ipykernel_22615/3790676905.py:95: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  buffer_utm_200_u = buffer_utm_200.unary_union\n",
      "/var/folders/fd/md6r13sj0wsbg_6_xl160d300000gn/T/ipykernel_22615/3790676905.py:96: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  buffer_utm_400_u = buffer_utm_400.unary_union\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöΩ H√§mtar toaletter (nwr) fr√•n Overpass...\n",
      "‚úÖ Hittade 721 toalett-objekt inom bbox\n",
      "‚úÖ 96 toalett-objekt inom/vid 200 m\n",
      "‚úÖ 9 toalett-objekt inom 200‚Äì400 m\n",
      "üìä Summary (‚â§200 m):\n",
      "            label     island  sites  toilets_total  avg_distance_m  \\\n",
      "10    SAT N√•ttar√∂    N√•ttar√∂     11             25       72.232629   \n",
      "1    SAT Finnhamn   Finnhamn     16             17       29.151231   \n",
      "2   SAT Fj√§rdl√•ng  Fj√§rdl√•ng     10             14       50.783603   \n",
      "4      SAT Grinda     Grinda     12             12       31.417178   \n",
      "0     SAT Arholma    Arholma      9             11       39.197231   \n",
      "12       SAT R√•n√∂       R√•n√∂      6              8       32.477367   \n",
      "14        SAT Ut√∂        Ut√∂      7              7       17.529076   \n",
      "5    SAT Ingmars√∂   Ingmars√∂      5              5       24.822614   \n",
      "13   SAT Sandhamn     Sand√∂n      4              4       16.953942   \n",
      "7        SAT Lid√∂       Lid√∂      3              3       47.205404   \n",
      "8        SAT M√∂ja       M√∂ja      3              3       17.928814   \n",
      "16        SAT √Öl√∂        √Öl√∂      3              3       35.464055   \n",
      "6    SAT Landsort        √ñja      2              2       16.946321   \n",
      "9       SAT N√§md√∂      N√§md√∂      2              2        8.259667   \n",
      "3    SAT Furusund   Furusund      1              1       16.958877   \n",
      "11       SAT Orn√∂       Orn√∂      1              1        4.276034   \n",
      "15      SAT Yxlan      Yxlan      1              1       94.323707   \n",
      "\n",
      "    avg_toilets_per_site  \n",
      "10              2.272727  \n",
      "1               1.062500  \n",
      "2               1.400000  \n",
      "4               1.000000  \n",
      "0               1.222222  \n",
      "12              1.333333  \n",
      "14              1.000000  \n",
      "5               1.000000  \n",
      "13              1.000000  \n",
      "7               1.000000  \n",
      "8               1.000000  \n",
      "16              1.000000  \n",
      "6               1.000000  \n",
      "9               1.000000  \n",
      "3               1.000000  \n",
      "11              1.000000  \n",
      "15              1.000000  \n",
      "üßæ Basic CSV (‚â§200 m): ../kartor/sat_toaletter_basic_tags_0_200_2025_08_19_23_14.csv\n",
      "üßæ Basic CSV (200‚Äì400 m): ../kartor/sat_toaletter_basic_tags_200_400_2025_08_19_23_14.csv\n",
      "‚úÖ Klart!\n",
      "‚Ä¢ Summary CSV (‚â§200 m): ../kartor/sat_toaletter_summary_2025_08_19_23_14.csv\n",
      "‚Ä¢ Toilets GeoJSON ‚â§200 m: ../kartor/sat_toaletter_inrange_0_200_2025_08_19_23_14.geojson\n",
      "‚Ä¢ Toilets CSV ‚â§200 m: ../kartor/sat_toaletter_inrange_0_200_2025_08_19_23_14.csv\n",
      "‚Ä¢ Toilets GeoJSON 200‚Äì400 m: ../kartor/sat_toaletter_inrange_200_400_2025_08_19_23_14.geojson\n",
      "‚Ä¢ Toilets CSV 200‚Äì400 m: ../kartor/sat_toaletter_inrange_200_400_2025_08_19_23_14.csv\n",
      "‚Ä¢ Basic CSV ‚â§200 m: ../kartor/sat_toaletter_basic_tags_0_200_2025_08_19_23_14.csv\n",
      "‚Ä¢ Basic CSV 200‚Äì400 m: ../kartor/sat_toaletter_basic_tags_200_400_2025_08_19_23_14.csv\n",
      "‚Ä¢ Karta: ../kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_23_14.html\n"
     ]
    }
   ],
   "source": [
    "# !pip install geopandas shapely folium requests SPARQLWrapper --quiet\n",
    "\n",
    "import os, re, requests, html\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString, MultiLineString, Point, mapping\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import folium\n",
    "from folium import Marker, Icon, FeatureGroup, LayerControl, Popup\n",
    "from datetime import datetime\n",
    "\n",
    "# =========================\n",
    "# 1) H√§mta SAT-etapper via Wikidata\n",
    "# =========================\n",
    "print(\"üîç H√§mtar SAT-etapper fr√•n Wikidata...\")\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "SELECT ?item ?itemLabel ?islandLabel ?osmid WHERE {\n",
    "  ?item wdt:P361 wd:Q131318799;\n",
    "        wdt:P31 wd:Q2143825;\n",
    "        wdt:P402 ?osmid.\n",
    "  OPTIONAL { ?item wdt:P706 ?island. }\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"sv,en\". }\n",
    "}\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "etapper = []\n",
    "for r in results[\"results\"][\"bindings\"]:\n",
    "    etapper.append({\n",
    "        \"id\": r[\"osmid\"][\"value\"],\n",
    "        \"label\": r.get(\"itemLabel\", {}).get(\"value\", \"\"),\n",
    "        \"island\": r.get(\"islandLabel\", {}).get(\"value\", \"\")\n",
    "    })\n",
    "osm_ids = [e['id'] for e in etapper]\n",
    "print(f\"‚úÖ Hittade {len(osm_ids)} etapper med OSM-relationer\")\n",
    "\n",
    "# =========================\n",
    "# 2) H√§mta geometrier per relation via Overpass\n",
    "# =========================\n",
    "print(\"üì° H√§mtar geometrier fr√•n Overpass (per relation)...\")\n",
    "overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "geom_per_rel = {}\n",
    "all_lines = []\n",
    "\n",
    "for rel_id in osm_ids:\n",
    "    q = f\"\"\"\n",
    "    [out:json][timeout:60];\n",
    "    relation({rel_id});\n",
    "    (._;>>;);\n",
    "    out geom;\n",
    "    \"\"\"\n",
    "    r = requests.post(overpass_url, data={\"data\": q})\n",
    "    if r.status_code != 200:\n",
    "        print(f\"‚ö†Ô∏è Fel f√∂r relation {rel_id}: {r.text[:200]}...\")\n",
    "        continue\n",
    "    rel_geoms = []\n",
    "    for el in r.json().get(\"elements\", []):\n",
    "        if el.get(\"type\") == \"way\" and \"geometry\" in el:\n",
    "            coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in el[\"geometry\"]]\n",
    "            if len(coords) >= 2:\n",
    "                line = LineString(coords)\n",
    "                rel_geoms.append(line)\n",
    "                all_lines.append(line)\n",
    "    if rel_geoms:\n",
    "        geom_per_rel[rel_id] = rel_geoms\n",
    "\n",
    "if not all_lines:\n",
    "    raise ValueError(\"Inga geometrier hittades fr√•n OSM-relationer kopplade via Wikidata.\")\n",
    "\n",
    "# Bygg MultiLineString/LineString per etapp\n",
    "meta_rows, geom_rows = [], []\n",
    "for meta in etapper:\n",
    "    geoms = geom_per_rel.get(meta[\"id\"])\n",
    "    if not geoms:\n",
    "        print(f\"‚ö†Ô∏è Saknar geometri f√∂r {meta['label']} (rel {meta['id']}) ‚Äì hoppar √∂ver.\")\n",
    "        continue\n",
    "    meta_rows.append(meta)\n",
    "    geom_rows.append(MultiLineString(geoms) if len(geoms) > 1 else geoms[0])\n",
    "\n",
    "gdf_trail = gpd.GeoDataFrame(geometry=all_lines, crs=\"EPSG:4326\")\n",
    "meta_gdf = gpd.GeoDataFrame(meta_rows, geometry=geom_rows, crs=\"EPSG:4326\")\n",
    "print(f\"üß≠ Etapper med geometri: {len(meta_gdf)}\")\n",
    "\n",
    "# =========================\n",
    "# 3) Buffert 200 m + ring 200‚Äì400 m\n",
    "# =========================\n",
    "print(\"üßÆ Skapar 200 m-buffert och 200‚Äì400 m-ring...\")\n",
    "trail_utm = gdf_trail.to_crs(3006)\n",
    "buffer_utm_200 = trail_utm.buffer(200)\n",
    "buffer_utm_400 = trail_utm.buffer(400)\n",
    "\n",
    "# Unionera respektive buffert till en geometri\n",
    "buffer_utm_200_u = buffer_utm_200.unary_union\n",
    "buffer_utm_400_u = buffer_utm_400.unary_union\n",
    "\n",
    "# Ring = 400m minus 200m\n",
    "ring_utm = buffer_utm_400_u.difference(buffer_utm_200_u)\n",
    "\n",
    "# Tillbaka till WGS84\n",
    "buffer_union = gpd.GeoSeries([buffer_utm_200_u], crs=3006).to_crs(4326).iloc[0]\n",
    "ring_union = gpd.GeoSeries([ring_utm], crs=3006).to_crs(4326).iloc[0]\n",
    "\n",
    "# =========================\n",
    "# 4) H√§mta toaletter (nwr + out center) i bbox\n",
    "# =========================\n",
    "def _parse_int(v):\n",
    "    if v is None:\n",
    "        return None\n",
    "    m = re.search(r\"\\d+\", str(v))\n",
    "    return int(m.group()) if m else None\n",
    "\n",
    "def toilets_count_from_tags(tags: dict) -> int:\n",
    "    n = _parse_int(tags.get(\"toilets:number\"))\n",
    "    if n is not None:\n",
    "        return n\n",
    "    parts = [\n",
    "        _parse_int(tags.get(\"male:toilets\")),\n",
    "        _parse_int(tags.get(\"female:toilets\")),\n",
    "        _parse_int(tags.get(\"unisex:toilets\")),\n",
    "    ]\n",
    "    parts = [p for p in parts if p is not None]\n",
    "    if parts:\n",
    "        return sum(parts)\n",
    "    return 1\n",
    "\n",
    "bbox = gdf_trail.total_bounds  # [minx, miny, maxx, maxy]\n",
    "q_toilets = f\"\"\"\n",
    "[out:json][timeout:60];\n",
    "nwr[\"amenity\"=\"toilets\"]({bbox[1]},{bbox[0]},{bbox[3]},{bbox[2]});\n",
    "out center;\n",
    "\"\"\"\n",
    "print(\"üöΩ H√§mtar toaletter (nwr) fr√•n Overpass...\")\n",
    "r = requests.post(overpass_url, data={\"data\": q_toilets})\n",
    "elements = r.json().get(\"elements\", [])\n",
    "toilets = []\n",
    "for el in elements:\n",
    "    tags = el.get(\"tags\", {})\n",
    "    typ = el.get(\"type\")\n",
    "    if typ == \"node\":\n",
    "        lon, lat = el[\"lon\"], el[\"lat\"]\n",
    "    else:\n",
    "        center = el.get(\"center\")\n",
    "        if not center:\n",
    "            continue\n",
    "        lon, lat = center[\"lon\"], center[\"lat\"]\n",
    "    toilets.append({\n",
    "        \"geometry\": Point(lon, lat),\n",
    "        \"tags\": tags,\n",
    "        \"id\": el[\"id\"],\n",
    "        \"osm_type\": typ,\n",
    "        \"toilets_num\": toilets_count_from_tags(tags),\n",
    "    })\n",
    "\n",
    "gdf_toilets = gpd.GeoDataFrame(toilets, crs=\"EPSG:4326\")\n",
    "print(f\"‚úÖ Hittade {len(gdf_toilets)} toalett-objekt inom bbox\")\n",
    "\n",
    "# =========================\n",
    "# 5) Dela upp: inom ‚â§200 m och i ringen 200‚Äì400 m\n",
    "# =========================\n",
    "in_0_200 = gdf_toilets[gdf_toilets.geometry.covered_by(buffer_union)]\n",
    "in_200_400 = gdf_toilets[gdf_toilets.geometry.covered_by(ring_union)]\n",
    "print(f\"‚úÖ {len(in_0_200)} toalett-objekt inom/vid 200 m\")\n",
    "print(f\"‚úÖ {len(in_200_400)} toalett-objekt inom 200‚Äì400 m\")\n",
    "\n",
    "# =========================\n",
    "# 6) N√§rmaste etapp per kategori\n",
    "# =========================\n",
    "meta_utm = meta_gdf.to_crs(3006)\n",
    "toilets_utm_0_200 = in_0_200.to_crs(3006)\n",
    "toilets_utm_200_400 = in_200_400.to_crs(3006)\n",
    "\n",
    "joined_0_200 = gpd.sjoin_nearest(\n",
    "    toilets_utm_0_200,\n",
    "    meta_utm[[\"label\", \"island\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    distance_col=\"distance_m\"\n",
    ").to_crs(4326)\n",
    "\n",
    "joined_200_400 = gpd.sjoin_nearest(\n",
    "    toilets_utm_200_400,\n",
    "    meta_utm[[\"label\", \"island\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    distance_col=\"distance_m\"\n",
    ").to_crs(4326)\n",
    "\n",
    "# =========================\n",
    "# 7) Summary f√∂r ‚â§200 m\n",
    "# =========================\n",
    "summary = (\n",
    "    joined_0_200.assign(toilets_num=joined_0_200[\"toilets_num\"].fillna(1))\n",
    "    .groupby([\"label\", \"island\"], as_index=False)\n",
    "    .agg(\n",
    "        sites=(\"geometry\", \"count\"),\n",
    "        toilets_total=(\"toilets_num\", \"sum\"),\n",
    "        avg_distance_m=(\"distance_m\", \"mean\"),\n",
    "    )\n",
    "    .assign(avg_toilets_per_site=lambda df: df[\"toilets_total\"] / df[\"sites\"])\n",
    "    .sort_values([\"toilets_total\", \"sites\"], ascending=[False, False])\n",
    ")\n",
    "print(\"üìä Summary (‚â§200 m):\")\n",
    "print(summary.head(1000))\n",
    "\n",
    "# =========================\n",
    "# 8) Spara filer + grundkarta\n",
    "# =========================\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "os.makedirs(\"../kartor\", exist_ok=True)\n",
    "\n",
    "summary_csv = f\"../kartor/sat_toaletter_summary_{timestamp}.csv\"\n",
    "summary.to_csv(summary_csv, index=False)\n",
    "\n",
    "toilets_geojson_0_200 = f\"../kartor/sat_toaletter_inrange_0_200_{timestamp}.geojson\"\n",
    "toilets_csv_0_200 = f\"../kartor/sat_toaletter_inrange_0_200_{timestamp}.csv\"\n",
    "in_0_200[[\"id\", \"osm_type\", \"toilets_num\", \"tags\", \"geometry\"]].to_file(toilets_geojson_0_200, driver=\"GeoJSON\")\n",
    "in_0_200.drop(columns=\"geometry\").to_csv(toilets_csv_0_200, index=False)\n",
    "\n",
    "toilets_geojson_200_400 = f\"../kartor/sat_toaletter_inrange_200_400_{timestamp}.geojson\"\n",
    "toilets_csv_200_400 = f\"../kartor/sat_toaletter_inrange_200_400_{timestamp}.csv\"\n",
    "in_200_400[[\"id\", \"osm_type\", \"toilets_num\", \"tags\", \"geometry\"]].to_file(toilets_geojson_200_400, driver=\"GeoJSON\")\n",
    "in_200_400.drop(columns=\"geometry\").to_csv(toilets_csv_200_400, index=False)\n",
    "\n",
    "# Bygg karta\n",
    "center = gdf_trail.geometry.union_all().centroid\n",
    "m = folium.Map(location=[center.y, center.x], zoom_start=9, control_scale=True)\n",
    "\n",
    "# Etapper\n",
    "colors = [\n",
    "    \"blue\",\"green\",\"purple\",\"orange\",\"darkred\",\"cadetblue\",\"lightgray\",\"darkblue\",\n",
    "    \"darkgreen\",\"pink\",\"lightblue\",\"lightgreen\",\"gray\",\"black\",\"beige\",\"lightred\"\n",
    "]\n",
    "for i, row in meta_gdf.reset_index(drop=True).iterrows():\n",
    "    color = colors[i % len(colors)]\n",
    "    popup = f\"<b>{html.escape(row['label'])}</b><br>√ñ: {html.escape(row['island'])}\"\n",
    "    folium.GeoJson(\n",
    "        data=mapping(row.geometry),\n",
    "        name=row[\"label\"],\n",
    "        style_function=lambda x, c=color: {\"color\": c, \"weight\": 3}\n",
    "    ).add_child(folium.Popup(popup, max_width=350)).add_to(m)\n",
    "\n",
    "# Buffert-lager (200 m och 200‚Äì400 m)\n",
    "folium.GeoJson(\n",
    "    data=mapping(buffer_union),\n",
    "    name=\"200 m Buffert\",\n",
    "    style_function=lambda x: {'fillColor': '#0000ff', 'color': '#0000ff', 'weight': 1, 'fillOpacity': 0.1}\n",
    ").add_to(m)\n",
    "\n",
    "folium.GeoJson(\n",
    "    data=mapping(ring_union),\n",
    "    name=\"Ring 200‚Äì400 m\",\n",
    "    style_function=lambda x: {'fillColor': '#ffa500', 'color': '#ffa500', 'weight': 1, 'fillOpacity': 0.1}\n",
    ").add_to(m)\n",
    "\n",
    "# =========================\n",
    "# 9) Commons helpers (FIX: support Category and avoid double-encoding)\n",
    "# =========================\n",
    "def _quote_commons(title: str) -> str:\n",
    "    # keep existing % escapes to avoid double-encoding already-encoded titles\n",
    "    return requests.utils.quote(title, safe=':/%')\n",
    "\n",
    "def commons_title_to_page(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Returnera korrekt Commons-sida (File:/Image:/Category:/etc).\n",
    "    - Om 'Category:' -> /wiki/Category:...\n",
    "    - Om File:/Image: -> /wiki/File:...\n",
    "    - Om ingen prefix -> anta File:\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        return None\n",
    "    t = title.strip()\n",
    "    low = t.lower()\n",
    "    if low.startswith((\"category:\", \"file:\", \"image:\")):\n",
    "        return f\"https://commons.wikimedia.org/wiki/{_quote_commons(t)}\"\n",
    "    # default: tolkas som fil\n",
    "    return f\"https://commons.wikimedia.org/wiki/{_quote_commons('File:' + t)}\"\n",
    "\n",
    "def commons_title_to_filepath(title: str, thumb_width=400) -> str | None:\n",
    "    \"\"\"\n",
    "    Thumbnail-url via Special:FilePath ‚Äî G√ÑLLER BARA filer.\n",
    "    Om titeln √§r en Category, returnera None (ingen direkt bild).\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        return None\n",
    "    t = title.strip()\n",
    "    low = t.lower()\n",
    "    if low.startswith(\"category:\"):\n",
    "        return None\n",
    "    if not low.startswith((\"file:\", \"image:\")):\n",
    "        t = \"File:\" + t\n",
    "    return f\"https://commons.wikimedia.org/wiki/Special:FilePath/{_quote_commons(t)}?width={thumb_width}\"\n",
    "\n",
    "# Wikidata P18 ‚Üí Commons thumbnail (of√∂r√§ndrat i sak)\n",
    "_wikidata_image_cache = {}\n",
    "def wikidata_p18_thumb(qid: str, thumb_width=400) -> str | None:\n",
    "    if not qid:\n",
    "        return None\n",
    "    qid = qid.strip()\n",
    "    if qid in _wikidata_image_cache:\n",
    "        return _wikidata_image_cache[qid]\n",
    "    try:\n",
    "        url = f\"https://www.wikidata.org/wiki/Special:EntityData/{qid}.json\"\n",
    "        data = requests.get(url, timeout=15).json()\n",
    "        ent = data.get(\"entities\", {}).get(qid, {})\n",
    "        p18 = ent.get(\"claims\", {}).get(\"P18\", [])\n",
    "        if not p18:\n",
    "            _wikidata_image_cache[qid] = None\n",
    "            return None\n",
    "        filename = p18[0][\"mainsnak\"][\"datavalue\"][\"value\"]\n",
    "        img_url = commons_title_to_filepath(filename, thumb_width=thumb_width)\n",
    "        _wikidata_image_cache[qid] = img_url\n",
    "        return img_url\n",
    "    except Exception:\n",
    "        _wikidata_image_cache[qid] = None\n",
    "        return None\n",
    "\n",
    "def best_image_url_from_tags(tags: dict) -> str | None:\n",
    "    \"\"\"\n",
    "    Prioritet: image=* URL ‚Üí image=* (File/Image title) ‚Üí wikimedia_commons=* (om fil) ‚Üí wikidata P18\n",
    "    OBS: Om wikimedia_commons b√∂rjar med Category: returnera ingen bild (endast l√§nk i popup).\n",
    "    \"\"\"\n",
    "    if not tags:\n",
    "        return None\n",
    "    # 1) image=*\n",
    "    if \"image\" in tags and str(tags[\"image\"]).strip():\n",
    "        first = str(tags[\"image\"]).split(\";\")[0].strip()\n",
    "        if first.lower().startswith((\"http://\", \"https://\")):\n",
    "            return first\n",
    "        # tolka som commons-titel\n",
    "        return commons_title_to_filepath(first)\n",
    "    # 2) wikimedia_commons=*\n",
    "    if \"wikimedia_commons\" in tags and str(tags[\"wikimedia_commons\"]).strip():\n",
    "        title = str(tags[\"wikimedia_commons\"]).strip()\n",
    "        thumb = commons_title_to_filepath(title)  # None if Category\n",
    "        if thumb:\n",
    "            return thumb\n",
    "    # 3) wikidata ‚Üí P18\n",
    "    if \"wikidata\" in tags and str(tags[\"wikidata\"]).strip():\n",
    "        return wikidata_p18_thumb(tags[\"wikidata\"])\n",
    "    return None\n",
    "\n",
    "# =========================\n",
    "# 10) Taggar & QA\n",
    "# =========================\n",
    "BASIC_TAGS = [\n",
    "    \"amenity\", \"access\", \"opening_hours\", \"fee\", \"wheelchair\",\n",
    "    \"toilets:number\", \"unisex\", \"drinking_water\", \"changing_table\",\n",
    "    \"toilet:paper\", \"indoor\", \"operator\", \"website\", \"source\"\n",
    "]\n",
    "\n",
    "def missing_tags(tags: dict) -> list:\n",
    "    missing = []\n",
    "    tags = tags or {}\n",
    "    for k in BASIC_TAGS:\n",
    "        if k == \"amenity\":\n",
    "            if tags.get(\"amenity\") != \"toilets\":\n",
    "                missing.append(\"amenity=toilets\")\n",
    "            continue\n",
    "        v = tags.get(k)\n",
    "        if v is None or str(v).strip() == \"\":\n",
    "            missing.append(k)\n",
    "    if \"unisex\" in missing and ((\"male\" in tags or \"male:toilets\" in tags) and (\"female\" in tags or \"female:toilets\" in tags)):\n",
    "        try:\n",
    "            missing.remove(\"unisex\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return missing\n",
    "\n",
    "def build_basic_table(joined_df):\n",
    "    tag_cols = [\n",
    "        \"access\",\"opening_hours\",\"fee\",\"wheelchair\",\"toilets:number\",\"unisex\",\n",
    "        \"drinking_water\",\"changing_table\",\"toilet:paper\",\"indoor\",\"operator\",\"website\",\"source\",\n",
    "        \"wikidata\",\"wikimedia_commons\",\"image\"\n",
    "    ]\n",
    "    rows = []\n",
    "    for _, r in joined_df.to_crs(4326).iterrows():\n",
    "        tags = r.get(\"tags\", {}) or {}\n",
    "        commons_title = str(tags.get(\"wikimedia_commons\") or \"\").strip() or None\n",
    "        commons_page_url = commons_title_to_page(commons_title) if commons_title else None\n",
    "\n",
    "        img_url = best_image_url_from_tags(tags)\n",
    "        miss = missing_tags(tags)\n",
    "        row = {\n",
    "            \"id\": r[\"id\"],\n",
    "            \"osm_type\": r[\"osm_type\"],\n",
    "            \"lat\": r.geometry.y,\n",
    "            \"lon\": r.geometry.x,\n",
    "            \"label\": r.get(\"label\", \"\"),\n",
    "            \"island\": r.get(\"island\", \"\"),\n",
    "            \"distance_m\": round(float(r.get(\"distance_m\", 0)), 1),\n",
    "            \"toilets_num\": int(r.get(\"toilets_num\", 1)),\n",
    "            \"image_url\": img_url,\n",
    "            \"missing_tags\": \", \".join(miss),\n",
    "            \"wikimedia_commons_title\": commons_title,\n",
    "            \"wikimedia_commons_url\": commons_page_url\n",
    "        }\n",
    "        for k in tag_cols:\n",
    "            row[k] = (tags.get(k) if isinstance(tags, dict) else None)\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# =========================\n",
    "# 11) Bygg tabeller och lager f√∂r ‚â§200 m och 200‚Äì400 m\n",
    "# =========================\n",
    "basic_df_0_200 = build_basic_table(joined_0_200)\n",
    "basic_df_200_400 = build_basic_table(joined_200_400)\n",
    "\n",
    "basic_csv_0_200 = f\"../kartor/sat_toaletter_basic_tags_0_200_{timestamp}.csv\"\n",
    "basic_df_0_200.to_csv(basic_csv_0_200, index=False)\n",
    "basic_csv_200_400 = f\"../kartor/sat_toaletter_basic_tags_200_400_{timestamp}.csv\"\n",
    "basic_df_200_400.to_csv(basic_csv_200_400, index=False)\n",
    "\n",
    "print(\"üßæ Basic CSV (‚â§200 m):\", basic_csv_0_200)\n",
    "print(\"üßæ Basic CSV (200‚Äì400 m):\", basic_csv_200_400)\n",
    "\n",
    "def add_markers(df, feature_group, marker_color):\n",
    "    for _, r in df.iterrows():\n",
    "        osm_url = f\"https://www.openstreetmap.org/{'node' if r['osm_type']=='node' else 'way' if r['osm_type']=='way' else 'relation'}/{r['id']}\"\n",
    "        img_html = f'<div style=\"margin:6px 0\"><img src=\"{html.escape(str(r[\"image_url\"]))}\" referrerpolicy=\"no-referrer\" style=\"max-width:280px; height:auto; display:block;\"/></div>' if r.get(\"image_url\") else \"\"\n",
    "        miss_html = f\"<div style='color:#b00; margin-top:4px'><b>Saknade taggar:</b> {html.escape(str(r['missing_tags']))}</div>\" if r.get(\"missing_tags\") else \"\"\n",
    "        commons_html = \"\"\n",
    "        if r.get(\"wikimedia_commons_url\"):\n",
    "            title = r.get(\"wikimedia_commons_title\") or \"Wikimedia Commons\"\n",
    "            commons_html = f'<div style=\"margin-top:4px\">üì∑ <a href=\"{html.escape(str(r[\"wikimedia_commons_url\"]))}\" target=\"_blank\">{html.escape(str(title))}</a></div>'\n",
    "        kv = []\n",
    "        for k in [\"opening_hours\",\"fee\",\"wheelchair\",\"access\",\"toilets:number\",\"unisex\",\"drinking_water\",\"changing_table\"]:\n",
    "            v = r.get(k)\n",
    "            if pd.notna(v) and str(v).strip() != \"\":\n",
    "                kv.append(f\"{k}={html.escape(str(v))}\")\n",
    "        kv_html = (\"<div>\" + \"<br>\".join(kv) + \"</div>\") if kv else \"\"\n",
    "        popup_html = f\"\"\"\n",
    "        <div style=\"font-size:13px; line-height:1.4\">\n",
    "          <b><a href=\"{osm_url}\" target=\"_blank\">OSM ({r['osm_type']}) {int(r['id'])}</a></b><br>\n",
    "          Etapp: <b>{html.escape(str(r.get('label') or ''))}</b> (√ñ: {html.escape(str(r.get('island') or ''))})<br>\n",
    "          Avst√•nd: ~{r['distance_m']} m<br>\n",
    "          Antal toaletter: <b>{int(r['toilets_num'])}</b>\n",
    "          {img_html}\n",
    "          {kv_html}\n",
    "          {commons_html}\n",
    "          {miss_html}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        Marker(\n",
    "            location=[r[\"lat\"], r[\"lon\"]],\n",
    "            popup=Popup(popup_html, max_width=320),\n",
    "            icon=Icon(color=marker_color, icon=\"info-sign\")\n",
    "        ).add_to(feature_group)\n",
    "\n",
    "# ‚â§200 m lager\n",
    "toilets_pic_fg_0_200 = FeatureGroup(name=\"Toaletter ‚â§200 m (bild, Commons, saknade taggar)\")\n",
    "add_markers(basic_df_0_200, toilets_pic_fg_0_200, marker_color=\"darkblue\")\n",
    "toilets_pic_fg_0_200.add_to(m)\n",
    "\n",
    "# 200‚Äì400 m lager\n",
    "toilets_pic_fg_200_400 = FeatureGroup(name=\"Toaletter 200‚Äì400 m (bild, Commons, saknade taggar)\")\n",
    "add_markers(basic_df_200_400, toilets_pic_fg_200_400, marker_color=\"orange\")\n",
    "toilets_pic_fg_200_400.add_to(m)\n",
    "\n",
    "LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# =========================\n",
    "# 12) Spara karta + output\n",
    "# =========================\n",
    "map_html = f\"../kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_{timestamp}.html\"\n",
    "m.save(map_html)\n",
    "\n",
    "print(\"‚úÖ Klart!\")\n",
    "print(f\"‚Ä¢ Summary CSV (‚â§200 m): {summary_csv}\")\n",
    "print(f\"‚Ä¢ Toilets GeoJSON ‚â§200 m: {toilets_geojson_0_200}\")\n",
    "print(f\"‚Ä¢ Toilets CSV ‚â§200 m: {toilets_csv_0_200}\")\n",
    "print(f\"‚Ä¢ Toilets GeoJSON 200‚Äì400 m: {toilets_geojson_200_400}\")\n",
    "print(f\"‚Ä¢ Toilets CSV 200‚Äì400 m: {toilets_csv_200_400}\")\n",
    "print(f\"‚Ä¢ Basic CSV ‚â§200 m: {basic_csv_0_200}\")\n",
    "print(f\"‚Ä¢ Basic CSV 200‚Äì400 m: {basic_csv_200_400}\")\n",
    "print(f\"‚Ä¢ Karta: {map_html}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ecd8aa2-fd2f-4792-9715-4f7bb4af6fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2025-08-19 23:14:57\n",
      "Total time elapsed: 15.51 seconds\n"
     ]
    }
   ],
   "source": [
    " # End timer and calculate duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print current date and total time\n",
    "print(\"Date:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5827d-1e5e-4ae2-9bb8-49bbc70cfa77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
