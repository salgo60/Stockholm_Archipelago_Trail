{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79dc2ee3-82e9-44fe-9c85-e0f49b8a35e8",
   "metadata": {},
   "source": [
    "# Issue 132 Notebook Toaletter n√§ra SAT\n",
    "* denna [Notebook](https://github.com/salgo60/Stockholm_Archipelago_Trail/blob/main/notebook/Issue_132_Notebook_Toaletter_n%C3%A4ra_SAT.ipynb)\n",
    "* [Issue 132](https://github.com/salgo60/Stockholm_Archipelago_Trail/issues/132)\n",
    "\n",
    "Se liknande l√∂sning f√∂r Roslagsleden\n",
    "* nu har vi SAT = wikidata [Q131318799](https://www.wikidata.org/wiki/Q131318799)\n",
    "* \"leden\" sitter inte ihop utan varje √∂ har sitt segment\n",
    "\n",
    "Jmf dricksvatten [Issue 139](https://github.com/salgo60/Stockholm_Archipelago_Trail/issues/139) \n",
    "\n",
    "\n",
    "Output \n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_07_28_17_12.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_07_28_17_12.html)\n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_07_30_04_22.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_07_30_04_22.html)\n",
    "* [kartor/Issue_132_2_toaletter_nara_stockholm_archipelago_trail_2025_07_30_07_16.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_2_toaletter_nara_stockholm_archipelago_trail_2025_07_30_07_16.html)\n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_17_19_29.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_17_19_29.html)\n",
    "* [kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_16_01.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_16_01.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd494e0-4277-42cd-8f35-d97c83229c07",
   "metadata": {},
   "source": [
    "version 0.1\n",
    "* unary_union --> union_all\n",
    "* start updating OSM with pictures from https://commons.wikimedia.org/wiki/Category:SAT_Todo\n",
    "* also count number of seats ie. toilets:number\n",
    "* Fetch SAT etapper via Wikidata\n",
    "* Fetch geometries per relation via Overpass (no zip-mismatch)\n",
    "* Buffer 200 m (Shapely ‚â•2 with union_all())\n",
    "* Fetch toilets as nodes/ways/relations via nwr[...] out center;\n",
    "* Count toilets via toilets:number (fallback male/female/unisex ‚Üí else 1)\n",
    "* Join to nearest etapp, build summary (CSV)\n",
    "* Build a Folium map with etapper, 200 m buffer, and toilet markers\n",
    "* Export toilets within 200 m as GeoJSON + CSV and save the map HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98b8e5d-53c1-4e11-b150-d75fdeabad97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2025-08-19 16:04:27\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = now.timestamp()\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Start:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf9ace7-5785-4440-997e-e0ffaa82b7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç H√§mtar SAT-etapper fr√•n Wikidata...\n",
      "‚úÖ Hittade 20 etapper med OSM-relationer\n",
      "üì° H√§mtar geometrier fr√•n Overpass (per relation)...\n",
      "üß≠ Etapper med geometri: 20\n",
      "üßÆ Skapar 200 m-buffert...\n",
      "üöΩ H√§mtar toaletter (nwr) fr√•n Overpass...\n",
      "‚úÖ Hittade 723 toalett-objekt inom bbox\n",
      "‚úÖ 97 toalett-objekt inom/vid 200 m\n",
      "üìä Summary:\n",
      "            label     island  sites  toilets_total  avg_distance_m  \\\n",
      "10    SAT N√•ttar√∂    N√•ttar√∂     11             25       72.232629   \n",
      "1    SAT Finnhamn   Finnhamn     16             17       29.151231   \n",
      "2   SAT Fj√§rdl√•ng  Fj√§rdl√•ng     10             14       50.783603   \n",
      "4      SAT Grinda     Grinda     12             12       31.417178   \n",
      "0     SAT Arholma    Arholma      9             11       39.197231   \n",
      "14        SAT Ut√∂        Ut√∂      8              8       17.478826   \n",
      "12       SAT R√•n√∂       R√•n√∂      6              8       32.673998   \n",
      "5    SAT Ingmars√∂   Ingmars√∂      5              5       24.822614   \n",
      "13   SAT Sandhamn     Sand√∂n      4              4       16.953942   \n",
      "7        SAT Lid√∂       Lid√∂      3              4       47.205404   \n",
      "8        SAT M√∂ja       M√∂ja      3              3       17.928814   \n",
      "16        SAT √Öl√∂        √Öl√∂      3              3       35.464055   \n",
      "6    SAT Landsort        √ñja      2              2       16.946321   \n",
      "9       SAT N√§md√∂      N√§md√∂      2              2        8.259667   \n",
      "3    SAT Furusund   Furusund      1              1       16.958877   \n",
      "11       SAT Orn√∂       Orn√∂      1              1        4.276034   \n",
      "15      SAT Yxlan      Yxlan      1              1       94.323707   \n",
      "\n",
      "    avg_toilets_per_site  \n",
      "10              2.272727  \n",
      "1               1.062500  \n",
      "2               1.400000  \n",
      "4               1.000000  \n",
      "0               1.222222  \n",
      "14              1.000000  \n",
      "12              1.333333  \n",
      "5               1.000000  \n",
      "13              1.000000  \n",
      "7               1.333333  \n",
      "8               1.000000  \n",
      "16              1.000000  \n",
      "6               1.000000  \n",
      "9               1.000000  \n",
      "3               1.000000  \n",
      "11              1.000000  \n",
      "15              1.000000  \n",
      "‚úÖ Klart!\n",
      "‚Ä¢ Summary CSV: ../kartor/sat_toaletter_summary_2025_08_19_16_24.csv\n",
      "‚Ä¢ Toilets GeoJSON: ../kartor/sat_toaletter_inrange_2025_08_19_16_24.geojson\n",
      "‚Ä¢ Toilets CSV: ../kartor/sat_toaletter_inrange_2025_08_19_16_24.csv\n",
      "‚Ä¢ Karta: ../kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_16_24.html\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c92892a-c0e4-4a90-9de6-6fccdc0effbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f9aab56-6f67-407d-baf6-c7a194ca8e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç H√§mtar SAT-etapper fr√•n Wikidata...\n",
      "‚úÖ Hittade 20 etapper med OSM-relationer\n",
      "üì° H√§mtar geometrier fr√•n Overpass (per relation)...\n",
      "‚ö†Ô∏è Fel f√∂r relation 19013473: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n",
      "    \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:...\n",
      "‚ö†Ô∏è Fel f√∂r relation 19012684: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n",
      "    \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:...\n",
      "‚ö†Ô∏è Fel f√∂r relation 19016280: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n",
      "    \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:...\n",
      "‚ö†Ô∏è Fel f√∂r relation 19014515: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n",
      "    \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:...\n",
      "‚ö†Ô∏è Saknar geometri f√∂r SAT N√§md√∂ (rel 19013473) ‚Äì hoppar √∂ver.\n",
      "‚ö†Ô∏è Saknar geometri f√∂r SAT √Öl√∂ (rel 19012684) ‚Äì hoppar √∂ver.\n",
      "‚ö†Ô∏è Saknar geometri f√∂r SAT Fj√§rdl√•ng (rel 19016280) ‚Äì hoppar √∂ver.\n",
      "‚ö†Ô∏è Saknar geometri f√∂r SAT Svarts√∂ (rel 19014515) ‚Äì hoppar √∂ver.\n",
      "üß≠ Etapper med geometri: 16\n",
      "üßÆ Skapar 200 m-buffert...\n",
      "üöΩ H√§mtar toaletter (nwr) fr√•n Overpass...\n",
      "‚úÖ Hittade 723 toalett-objekt inom bbox\n",
      "‚úÖ 82 toalett-objekt inom/vid 200 m\n",
      "üìä Summary:\n",
      "           label    island  sites  toilets_total  avg_distance_m  \\\n",
      "8    SAT N√•ttar√∂   N√•ttar√∂     11             25       72.232629   \n",
      "1   SAT Finnhamn  Finnhamn     16             17       29.151231   \n",
      "3     SAT Grinda    Grinda     12             12       31.417178   \n",
      "0    SAT Arholma   Arholma      9             11       39.197231   \n",
      "12       SAT Ut√∂       Ut√∂      8              8       17.478826   \n",
      "10      SAT R√•n√∂      R√•n√∂      6              8       32.673998   \n",
      "4   SAT Ingmars√∂  Ingmars√∂      5              5       24.822614   \n",
      "11  SAT Sandhamn    Sand√∂n      4              4       16.953942   \n",
      "6       SAT Lid√∂      Lid√∂      3              4       47.205404   \n",
      "7       SAT M√∂ja      M√∂ja      3              3       17.928814   \n",
      "5   SAT Landsort       √ñja      2              2       16.946321   \n",
      "2   SAT Furusund  Furusund      1              1       16.958877   \n",
      "9       SAT Orn√∂      Orn√∂      1              1        4.276034   \n",
      "13     SAT Yxlan     Yxlan      1              1       94.323707   \n",
      "\n",
      "    avg_toilets_per_site  \n",
      "8               2.272727  \n",
      "1               1.062500  \n",
      "3               1.000000  \n",
      "0               1.222222  \n",
      "12              1.000000  \n",
      "10              1.333333  \n",
      "4               1.000000  \n",
      "11              1.000000  \n",
      "6               1.333333  \n",
      "7               1.000000  \n",
      "5               1.000000  \n",
      "2               1.000000  \n",
      "9               1.000000  \n",
      "13              1.000000  \n",
      "üßæ Basic tags-tabell sparad: ../kartor/sat_toaletter_basic_tags_2025_08_19_16_34.csv\n",
      "‚úÖ Klart!\n",
      "‚Ä¢ Summary CSV: ../kartor/sat_toaletter_summary_2025_08_19_16_34.csv\n",
      "‚Ä¢ Toilets GeoJSON: ../kartor/sat_toaletter_inrange_2025_08_19_16_34.geojson\n",
      "‚Ä¢ Toilets CSV: ../kartor/sat_toaletter_inrange_2025_08_19_16_34.csv\n",
      "‚Ä¢ Basic CSV (inkl. Commons): ../kartor/sat_toaletter_basic_tags_2025_08_19_16_34.csv\n",
      "‚Ä¢ Karta: ../kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_2025_08_19_16_34.html\n"
     ]
    }
   ],
   "source": [
    "# !pip install geopandas shapely folium requests SPARQLWrapper --quiet\n",
    "\n",
    "import os, re, requests, html\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString, MultiLineString, Point, mapping\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from collections import defaultdict\n",
    "import folium\n",
    "from folium import Marker, Icon, FeatureGroup, LayerControl, Popup\n",
    "from datetime import datetime\n",
    "\n",
    "# =========================\n",
    "# 1) H√§mta SAT-etapper via Wikidata\n",
    "# =========================\n",
    "print(\"üîç H√§mtar SAT-etapper fr√•n Wikidata...\")\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "SELECT ?item ?itemLabel ?islandLabel ?osmid WHERE {\n",
    "  ?item wdt:P361 wd:Q131318799;\n",
    "        wdt:P31 wd:Q2143825;\n",
    "        wdt:P402 ?osmid.\n",
    "  OPTIONAL { ?item wdt:P706 ?island. }\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"sv,en\". }\n",
    "}\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "etapper = []\n",
    "for r in results[\"results\"][\"bindings\"]:\n",
    "    etapper.append({\n",
    "        \"id\": r[\"osmid\"][\"value\"],\n",
    "        \"label\": r.get(\"itemLabel\", {}).get(\"value\", \"\"),\n",
    "        \"island\": r.get(\"islandLabel\", {}).get(\"value\", \"\")\n",
    "    })\n",
    "osm_ids = [e['id'] for e in etapper]\n",
    "print(f\"‚úÖ Hittade {len(osm_ids)} etapper med OSM-relationer\")\n",
    "\n",
    "# =========================\n",
    "# 2) H√§mta geometrier per relation via Overpass\n",
    "# =========================\n",
    "print(\"üì° H√§mtar geometrier fr√•n Overpass (per relation)...\")\n",
    "overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "geom_per_rel = {}\n",
    "all_lines = []\n",
    "\n",
    "for rel_id in osm_ids:\n",
    "    q = f\"\"\"\n",
    "    [out:json][timeout:60];\n",
    "    relation({rel_id});\n",
    "    (._;>>;);\n",
    "    out geom;\n",
    "    \"\"\"\n",
    "    r = requests.post(overpass_url, data={\"data\": q})\n",
    "    if r.status_code != 200:\n",
    "        print(f\"‚ö†Ô∏è Fel f√∂r relation {rel_id}: {r.text[:200]}...\")\n",
    "        continue\n",
    "    rel_geoms = []\n",
    "    for el in r.json().get(\"elements\", []):\n",
    "        if el.get(\"type\") == \"way\" and \"geometry\" in el:\n",
    "            coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in el[\"geometry\"]]\n",
    "            if len(coords) >= 2:\n",
    "                line = LineString(coords)\n",
    "                rel_geoms.append(line)\n",
    "                all_lines.append(line)\n",
    "    if rel_geoms:\n",
    "        geom_per_rel[rel_id] = rel_geoms\n",
    "\n",
    "if not all_lines:\n",
    "    raise ValueError(\"Inga geometrier hittades fr√•n OSM-relationer kopplade via Wikidata.\")\n",
    "\n",
    "# Bygg MultiLineString/LineString per etapp\n",
    "meta_rows, geom_rows = [], []\n",
    "for meta in etapper:\n",
    "    geoms = geom_per_rel.get(meta[\"id\"])\n",
    "    if not geoms:\n",
    "        print(f\"‚ö†Ô∏è Saknar geometri f√∂r {meta['label']} (rel {meta['id']}) ‚Äì hoppar √∂ver.\")\n",
    "        continue\n",
    "    meta_rows.append(meta)\n",
    "    geom_rows.append(MultiLineString(geoms) if len(geoms) > 1 else geoms[0])\n",
    "\n",
    "gdf_trail = gpd.GeoDataFrame(geometry=all_lines, crs=\"EPSG:4326\")\n",
    "meta_gdf = gpd.GeoDataFrame(meta_rows, geometry=geom_rows, crs=\"EPSG:4326\")\n",
    "print(f\"üß≠ Etapper med geometri: {len(meta_gdf)}\")\n",
    "\n",
    "# =========================\n",
    "# 3) Buffert 200 m (Shapely 2: union_all)\n",
    "# =========================\n",
    "print(\"üßÆ Skapar 200 m-buffert...\")\n",
    "buffer_utm = gdf_trail.to_crs(3006).buffer(200)   # 200 m i SWEREF 99 TM\n",
    "buffer_wgs84 = buffer_utm.to_crs(4326)            # tillbaka till WGS84\n",
    "buffer_union = buffer_wgs84.union_all()           # EN (multi)polygon\n",
    "\n",
    "# =========================\n",
    "# 4) H√§mta toaletter (noder/ways/relationer) via nwr + out center\n",
    "# =========================\n",
    "def _parse_int(v):\n",
    "    if v is None:\n",
    "        return None\n",
    "    m = re.search(r\"\\d+\", str(v))\n",
    "    return int(m.group()) if m else None\n",
    "\n",
    "def toilets_count_from_tags(tags: dict) -> int:\n",
    "    \"\"\"\n",
    "    Prioritet:\n",
    "      1) toilets:number\n",
    "      2) sum(male:toilets, female:toilets, unisex:toilets)\n",
    "      3) default = 1\n",
    "    \"\"\"\n",
    "    n = _parse_int(tags.get(\"toilets:number\"))\n",
    "    if n is not None:\n",
    "        return n\n",
    "    parts = [\n",
    "        _parse_int(tags.get(\"male:toilets\")),\n",
    "        _parse_int(tags.get(\"female:toilets\")),\n",
    "        _parse_int(tags.get(\"unisex:toilets\")),\n",
    "    ]\n",
    "    parts = [p for p in parts if p is not None]\n",
    "    if parts:\n",
    "        return sum(parts)\n",
    "    return 1\n",
    "\n",
    "bbox = gdf_trail.total_bounds  # [minx, miny, maxx, maxy]\n",
    "q_toilets = f\"\"\"\n",
    "[out:json][timeout:60];\n",
    "nwr[\"amenity\"=\"toilets\"]({bbox[1]},{bbox[0]},{bbox[3]},{bbox[2]});\n",
    "out center;\n",
    "\"\"\"\n",
    "print(\"üöΩ H√§mtar toaletter (nwr) fr√•n Overpass...\")\n",
    "r = requests.post(overpass_url, data={\"data\": q_toilets})\n",
    "elements = r.json().get(\"elements\", [])\n",
    "toilets = []\n",
    "for el in elements:\n",
    "    tags = el.get(\"tags\", {})\n",
    "    typ = el.get(\"type\")\n",
    "    if typ == \"node\":\n",
    "        lon, lat = el[\"lon\"], el[\"lat\"]\n",
    "    else:\n",
    "        center = el.get(\"center\")\n",
    "        if not center:\n",
    "            continue\n",
    "        lon, lat = center[\"lon\"], center[\"lat\"]\n",
    "    toilets.append({\n",
    "        \"geometry\": Point(lon, lat),\n",
    "        \"tags\": tags,\n",
    "        \"id\": el[\"id\"],\n",
    "        \"osm_type\": typ,\n",
    "        \"toilets_num\": toilets_count_from_tags(tags),\n",
    "    })\n",
    "\n",
    "gdf_toilets = gpd.GeoDataFrame(toilets, crs=\"EPSG:4326\")\n",
    "print(f\"‚úÖ Hittade {len(gdf_toilets)} toalett-objekt inom bbox\")\n",
    "\n",
    "# =========================\n",
    "# 5) Filtrera till de som ligger inom/vid 200 m-bufferten\n",
    "# =========================\n",
    "in_range = gdf_toilets[gdf_toilets.geometry.covered_by(buffer_union)]  # covered_by inkluderar gr√§nsen\n",
    "print(f\"‚úÖ {len(in_range)} toalett-objekt inom/vid 200 m\")\n",
    "\n",
    "# =========================\n",
    "# 6) N√§rmaste etapp per toalett\n",
    "# =========================\n",
    "meta_utm = meta_gdf.to_crs(3006)\n",
    "toilets_utm = in_range.to_crs(3006)\n",
    "joined = gpd.sjoin_nearest(\n",
    "    toilets_utm,\n",
    "    meta_utm[[\"label\", \"island\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    distance_col=\"distance_m\"\n",
    ").to_crs(4326)\n",
    "\n",
    "# =========================\n",
    "# 7) Summary (r√§kna toilets:number)\n",
    "# =========================\n",
    "summary = (\n",
    "    joined.assign(toilets_num=joined[\"toilets_num\"].fillna(1))\n",
    "    .groupby([\"label\", \"island\"], as_index=False)\n",
    "    .agg(\n",
    "        sites=(\"geometry\", \"count\"),\n",
    "        toilets_total=(\"toilets_num\", \"sum\"),\n",
    "        avg_distance_m=(\"distance_m\", \"mean\"),\n",
    "    )\n",
    "    .assign(avg_toilets_per_site=lambda df: df[\"toilets_total\"] / df[\"sites\"])\n",
    "    .sort_values([\"toilets_total\", \"sites\"], ascending=[False, False])\n",
    ")\n",
    "print(\"üìä Summary:\")\n",
    "print(summary.head(1000))\n",
    "\n",
    "# =========================\n",
    "# 8) Spara filer + grundkarta\n",
    "# =========================\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "os.makedirs(\"../kartor\", exist_ok=True)\n",
    "\n",
    "# Spara summary\n",
    "summary_csv = f\"../kartor/sat_toaletter_summary_{timestamp}.csv\"\n",
    "summary.to_csv(summary_csv, index=False)\n",
    "\n",
    "# Spara toaletter inom 200 m (GeoJSON + CSV)\n",
    "toilets_geojson = f\"../kartor/sat_toaletter_inrange_{timestamp}.geojson\"\n",
    "toilets_csv = f\"../kartor/sat_toaletter_inrange_{timestamp}.csv\"\n",
    "in_range[[\"id\", \"osm_type\", \"toilets_num\", \"tags\", \"geometry\"]].to_file(toilets_geojson, driver=\"GeoJSON\")\n",
    "in_range.drop(columns=\"geometry\").to_csv(toilets_csv, index=False)\n",
    "\n",
    "# Bygg karta\n",
    "center = gdf_trail.geometry.union_all().centroid\n",
    "m = folium.Map(location=[center.y, center.x], zoom_start=9, control_scale=True)\n",
    "\n",
    "# Etapper\n",
    "colors = [\n",
    "    \"blue\",\"green\",\"purple\",\"orange\",\"darkred\",\"cadetblue\",\"lightgray\",\"darkblue\",\n",
    "    \"darkgreen\",\"pink\",\"lightblue\",\"lightgreen\",\"gray\",\"black\",\"beige\",\"lightred\"\n",
    "]\n",
    "for i, row in meta_gdf.reset_index(drop=True).iterrows():\n",
    "    color = colors[i % len(colors)]\n",
    "    popup = f\"<b>{html.escape(row['label'])}</b><br>√ñ: {html.escape(row['island'])}\"\n",
    "    folium.GeoJson(\n",
    "        data=mapping(row.geometry),\n",
    "        name=row[\"label\"],\n",
    "        style_function=lambda x, c=color: {\"color\": c, \"weight\": 3}\n",
    "    ).add_child(folium.Popup(popup, max_width=350)).add_to(m)\n",
    "\n",
    "# Buffert\n",
    "folium.GeoJson(\n",
    "    data=mapping(buffer_union),\n",
    "    name=\"200 m Buffert\",\n",
    "    style_function=lambda x: {'fillColor': '#0000ff', 'color': '#0000ff', 'weight': 1, 'fillOpacity': 0.1}\n",
    ").add_to(m)\n",
    "\n",
    "# =========================\n",
    "# 9) Helpers f√∂r bilder + Commons + saknade taggar\n",
    "# =========================\n",
    "def commons_title_to_filepage(title: str) -> str:\n",
    "    \"\"\"Returnera Commons filsida-URL fr√•n titel med/utan 'File:' prefix.\"\"\"\n",
    "    if not title:\n",
    "        return None\n",
    "    t = title.strip()\n",
    "    if not t.lower().startswith((\"file:\", \"image:\")):\n",
    "        t = \"File:\" + t\n",
    "    return f\"https://commons.wikimedia.org/wiki/{requests.utils.quote(t, safe=':/')}\"\n",
    "\n",
    "def commons_title_to_filepath(title: str, thumb_width=400) -> str:\n",
    "    \"\"\"Thumbnail-url via Special:FilePath (redirect) fr√•n en Commons-titel.\"\"\"\n",
    "    if not title:\n",
    "        return None\n",
    "    t = title.strip()\n",
    "    if not t.lower().startswith((\"file:\", \"image:\")):\n",
    "        t = \"File:\" + t\n",
    "    return f\"https://commons.wikimedia.org/wiki/Special:FilePath/{requests.utils.quote(t, safe=':/')}?width={thumb_width}\"\n",
    "\n",
    "_wikidata_image_cache = {}\n",
    "\n",
    "def wikidata_p18_thumb(qid: str, thumb_width=400) -> str:\n",
    "    \"\"\"H√§mta P18 och ge en Commons thumbnail-url (cachead).\"\"\"\n",
    "    if not qid:\n",
    "        return None\n",
    "    qid = qid.strip()\n",
    "    if qid in _wikidata_image_cache:\n",
    "        return _wikidata_image_cache[qid]\n",
    "    try:\n",
    "        url = f\"https://www.wikidata.org/wiki/Special:EntityData/{qid}.json\"\n",
    "        data = requests.get(url, timeout=15).json()\n",
    "        ent = data.get(\"entities\", {}).get(qid, {})\n",
    "        p18 = ent.get(\"claims\", {}).get(\"P18\", [])\n",
    "        if not p18:\n",
    "            _wikidata_image_cache[qid] = None\n",
    "            return None\n",
    "        filename = p18[0][\"mainsnak\"][\"datavalue\"][\"value\"]\n",
    "        img_url = commons_title_to_filepath(filename, thumb_width=thumb_width)\n",
    "        _wikidata_image_cache[qid] = img_url\n",
    "        return img_url\n",
    "    except Exception:\n",
    "        _wikidata_image_cache[qid] = None\n",
    "        return None\n",
    "\n",
    "def best_image_url_from_tags(tags: dict) -> str:\n",
    "    \"\"\"\n",
    "    Priority: image=* URL ‚Üí wikimedia_commons=* ‚Üí wikidata=Q‚Ä¶ (P18)\n",
    "    \"\"\"\n",
    "    if not tags:\n",
    "        return None\n",
    "    # 1) image=* (kan vara URL eller Commons-titel)\n",
    "    if \"image\" in tags and str(tags[\"image\"]).strip():\n",
    "        first = str(tags[\"image\"]).split(\";\")[0].strip()\n",
    "        if first.lower().startswith((\"http://\", \"https://\")):\n",
    "            return first\n",
    "        return commons_title_to_filepath(first)\n",
    "    # 2) wikimedia_commons=*\n",
    "    if \"wikimedia_commons\" in tags and str(tags[\"wikimedia_commons\"]).strip():\n",
    "        return commons_title_to_filepath(tags[\"wikimedia_commons\"])\n",
    "    # 3) wikidata ‚Üí P18\n",
    "    if \"wikidata\" in tags and str(tags[\"wikidata\"]).strip():\n",
    "        return wikidata_p18_thumb(tags[\"wikidata\"])\n",
    "    return None\n",
    "\n",
    "BASIC_TAGS = [\n",
    "    \"amenity\",          # should be 'toilets'\n",
    "    \"access\",\n",
    "    \"opening_hours\",\n",
    "    \"fee\",\n",
    "    \"wheelchair\",\n",
    "    \"toilets:number\",\n",
    "    \"unisex\",\n",
    "    \"drinking_water\",\n",
    "    \"changing_table\",\n",
    "    \"toilet:paper\",\n",
    "    \"indoor\",\n",
    "    \"operator\",\n",
    "    \"website\",\n",
    "    \"source\"\n",
    "]\n",
    "\n",
    "def missing_tags(tags: dict) -> list:\n",
    "    \"\"\"Lista av saknade/obesatta BASIC_TAGS (amenity m√•ste vara toilets).\"\"\"\n",
    "    missing = []\n",
    "    tags = tags or {}\n",
    "    for k in BASIC_TAGS:\n",
    "        if k == \"amenity\":\n",
    "            if tags.get(\"amenity\") != \"toilets\":\n",
    "                missing.append(\"amenity=toilets\")\n",
    "            continue\n",
    "        v = tags.get(k)\n",
    "        if v is None or str(v).strip() == \"\":\n",
    "            missing.append(k)\n",
    "    # OK att hoppa √∂ver 'unisex' om b√•de male/female finns\n",
    "    if \"unisex\" in missing and ((\"male\" in tags or \"male:toilets\" in tags) and (\"female\" in tags or \"female:toilets\" in tags)):\n",
    "        try:\n",
    "            missing.remove(\"unisex\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return missing\n",
    "\n",
    "# =========================\n",
    "# 10) Bygg \"basic tags\"-tabell inkl. Commons-attribut & l√§nkar\n",
    "# =========================\n",
    "def _safe_get(d, k, default=None):\n",
    "    try:\n",
    "        return d.get(k, default)\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "base_cols = [\n",
    "    \"id\", \"osm_type\", \"toilets_num\", \"distance_m\", \"label\", \"island\"\n",
    "]\n",
    "\n",
    "tag_cols = [\n",
    "    \"access\",\"opening_hours\",\"fee\",\"wheelchair\",\"toilets:number\",\"unisex\",\n",
    "    \"drinking_water\",\"changing_table\",\"toilet:paper\",\"indoor\",\"operator\",\"website\",\"source\",\n",
    "    \"wikidata\",\"wikimedia_commons\",\"image\"\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for _, r in joined.to_crs(4326).iterrows():\n",
    "    tags = r.get(\"tags\", {}) or {}\n",
    "\n",
    "    # Resolve Commons attributes\n",
    "    commons_title = None\n",
    "    commons_page_url = None\n",
    "    if \"wikimedia_commons\" in tags and str(tags[\"wikimedia_commons\"]).strip():\n",
    "        commons_title = str(tags[\"wikimedia_commons\"]).strip()\n",
    "        commons_page_url = commons_title_to_filepage(commons_title)\n",
    "\n",
    "    img_url = best_image_url_from_tags(tags)\n",
    "    miss = missing_tags(tags)\n",
    "    row = {\n",
    "        \"id\": r[\"id\"],\n",
    "        \"osm_type\": r[\"osm_type\"],\n",
    "        \"lat\": r.geometry.y,\n",
    "        \"lon\": r.geometry.x,\n",
    "        \"label\": r.get(\"label\", \"\"),\n",
    "        \"island\": r.get(\"island\", \"\"),\n",
    "        \"distance_m\": round(float(r.get(\"distance_m\", 0)), 1),\n",
    "        \"toilets_num\": int(r.get(\"toilets_num\", 1)),\n",
    "        \"image_url\": img_url,\n",
    "        \"missing_tags\": \", \".join(miss),\n",
    "        \"wikimedia_commons_title\": commons_title,\n",
    "        \"wikimedia_commons_url\": commons_page_url\n",
    "    }\n",
    "    for k in tag_cols:\n",
    "        row[k] = _safe_get(tags, k)\n",
    "    rows.append(row)\n",
    "\n",
    "basic_df = pd.DataFrame(rows)\n",
    "\n",
    "# Spara \"basic tags\" tabell (inkl. Commons-l√§nkar)\n",
    "basic_csv = f\"../kartor/sat_toaletter_basic_tags_{timestamp}.csv\"\n",
    "basic_df.to_csv(basic_csv, index=False)\n",
    "print(\"üßæ Basic tags-tabell sparad:\", basic_csv)\n",
    "\n",
    "# =========================\n",
    "# 11) Folium-layer: bild + saknade taggar + Commons-l√§nk\n",
    "# =========================\n",
    "toilets_pic_fg = FeatureGroup(name=\"Toaletter (bild, saknade taggar, Commons-l√§nk)\")\n",
    "\n",
    "for _, r in basic_df.iterrows():\n",
    "    osm_url = f\"https://www.openstreetmap.org/{'node' if r['osm_type']=='node' else 'way' if r['osm_type']=='way' else 'relation'}/{r['id']}\"\n",
    "    img_html = \"\"\n",
    "    if pd.notna(r[\"image_url\"]) and r[\"image_url\"]:\n",
    "        img_html = f'<div style=\"margin:6px 0\"><img src=\"{html.escape(r[\"image_url\"])}\" referrerpolicy=\"no-referrer\" style=\"max-width:280px; height:auto; display:block;\"/></div>'\n",
    "\n",
    "    miss_html = \"\"\n",
    "    if r[\"missing_tags\"]:\n",
    "        miss_html = f\"<div style='color:#b00; margin-top:4px'><b>Saknade taggar:</b> {html.escape(r['missing_tags'])}</div>\"\n",
    "\n",
    "    commons_html = \"\"\n",
    "    if pd.notna(r.get(\"wikimedia_commons_url\")) and r.get(\"wikimedia_commons_url\"):\n",
    "        title = r.get(\"wikimedia_commons_title\") or \"Wikimedia Commons\"\n",
    "        commons_html = f'<div style=\"margin-top:4px\">üì∑ <a href=\"{html.escape(r[\"wikimedia_commons_url\"])}\" target=\"_blank\">{html.escape(str(title))}</a></div>'\n",
    "\n",
    "    # visa n√•gra nyckeltaggar\n",
    "    kv = []\n",
    "    for k in [\"opening_hours\", \"fee\", \"wheelchair\", \"access\", \"toilets:number\", \"unisex\", \"drinking_water\", \"changing_table\"]:\n",
    "        v = r.get(k)\n",
    "        if pd.notna(v) and str(v).strip() != \"\":\n",
    "            kv.append(f\"{k}={html.escape(str(v))}\")\n",
    "    kv_html = (\"<div>\" + \"<br>\".join(kv) + \"</div>\") if kv else \"\"\n",
    "\n",
    "    popup_html = f\"\"\"\n",
    "    <div style=\"font-size:13px; line-height:1.4\">\n",
    "      <b><a href=\"{osm_url}\" target=\"_blank\">OSM ({r['osm_type']}) {int(r['id'])}</a></b><br>\n",
    "      Etapp: <b>{html.escape(str(r['label'] or ''))}</b> (√ñ: {html.escape(str(r['island'] or ''))})<br>\n",
    "      Avst√•nd: ~{r['distance_m']} m<br>\n",
    "      Antal toaletter: <b>{int(r['toilets_num'])}</b>\n",
    "      {img_html}\n",
    "      {kv_html}\n",
    "      {commons_html}\n",
    "      {miss_html}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    Marker(\n",
    "        location=[r[\"lat\"], r[\"lon\"]],\n",
    "        popup=Popup(popup_html, max_width=320),\n",
    "        icon=Icon(color=\"darkblue\", icon=\"info-sign\")\n",
    "    ).add_to(toilets_pic_fg)\n",
    "\n",
    "toilets_pic_fg.add_to(m)\n",
    "LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "# =========================\n",
    "# 12) Spara karta + output\n",
    "# =========================\n",
    "map_html = f\"../kartor/Issue_132_toaletter_nara_stockholm_archipelago_trail_{timestamp}.html\"\n",
    "m.save(map_html)\n",
    "\n",
    "print(\"‚úÖ Klart!\")\n",
    "print(f\"‚Ä¢ Summary CSV: {summary_csv}\")\n",
    "print(f\"‚Ä¢ Toilets GeoJSON: {toilets_geojson}\")\n",
    "print(f\"‚Ä¢ Toilets CSV: {toilets_csv}\")\n",
    "print(f\"‚Ä¢ Basic CSV (inkl. Commons): {basic_csv}\")\n",
    "print(f\"‚Ä¢ Karta: {map_html}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44661d20-2c14-4fb0-8a46-416f1a1bbab4",
   "metadata": {},
   "outputs": [],
   "source": [
    " # End timer and calculate duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print current date and total time\n",
    "print(\"Date:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecfcecc-d898-4685-b130-65ce27e2f147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
