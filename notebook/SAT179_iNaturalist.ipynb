{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda39827-283b-479b-a094-4db14153e3a6",
   "metadata": {},
   "source": [
    "### iNaturlist \n",
    "* [#179](https://github.com/salgo60/Stockholm_Archipelago_Trail/issues/179) \"Koppla SAT till artobservationer\"\n",
    "* [this Notebook](https://github.com/salgo60/Stockholm_Archipelago_Trail/tree/main/notebook/SAT179_iNaturalist.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022819a8-6a01-44bb-95d3-9cb60ba77871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started: 2025-09-21 22:41\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime  \n",
    "start_time = time.time()\n",
    "start_str = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "print(f\"Started: {start_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b22dfd0-02ea-446e-91c3-1ed2a534350f",
   "metadata": {},
   "source": [
    "1) Läs leden från lokal GeoJSON \"SAT_full.geojson\"\n",
    "2) Buffert runt leden som sökzon för iNat BUFFER_DEG\n",
    "\n",
    "Funka ej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cbc9312-5456-4a90-ba47-a59be781e18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Plantae:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded1edacc31f465c9e1dafbe641b9aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Animal taxa:   0%|          | 0/8 [00:00<?, ?taxon/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aves:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mammalia:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reptilia:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Amphibia:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef3a15256334e6492e600616fc6368a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Insecta:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mollusca:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Animalia:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Växter: 1058 | Djur: 8137\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TimestampedGeoJson.__init__() got an unexpected keyword argument 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 218\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(search_geom,(Polygon,MultiPolygon)):\n\u001b[1;32m    215\u001b[0m     folium\u001b[38;5;241m.\u001b[39mGeoJson(mapping(search_geom), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSökzon\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    216\u001b[0m                    style_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#3388ff\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m1\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfillOpacity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0.05\u001b[39m})\u001b[38;5;241m.\u001b[39madd_to(m)\n\u001b[0;32m--> 218\u001b[0m \u001b[43mTimestampedGeoJson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplants_fc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP1D\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP3D\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m                   \u001b[49m\u001b[43madd_last_point\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_play\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mdate_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYYYY-MM-DD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVäxter – tidsserie\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_to(m)\n\u001b[1;32m    222\u001b[0m TimestampedGeoJson(animals_fc, period\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP1D\u001b[39m\u001b[38;5;124m\"\u001b[39m, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP3D\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m                    add_last_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, auto_play\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    224\u001b[0m                    date_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYYYY-MM-DD\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDjur – tidsserie\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39madd_to(m)\n\u001b[1;32m    226\u001b[0m folium\u001b[38;5;241m.\u001b[39mLayerControl(collapsed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39madd_to(m)\n",
      "\u001b[0;31mTypeError\u001b[0m: TimestampedGeoJson.__init__() got an unexpected keyword argument 'name'"
     ]
    }
   ],
   "source": [
    "# i en notebook-cell (en gång)\n",
    "!pip install -q tqdm\n",
    "from tqdm.auto import tqdm \n",
    "import json, time, requests, folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "from shapely.geometry import shape, LineString, MultiLineString, Polygon, MultiPolygon\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "# --- 0) Läs leden från lokal GeoJSON ---\n",
    "with open(\"SAT_full.geojson\", encoding=\"utf-8\") as f:\n",
    "    gj = json.load(f)\n",
    "\n",
    "lines = []\n",
    "for feat in gj[\"features\"]:\n",
    "    g = shape(feat[\"geometry\"])\n",
    "    if isinstance(g, LineString):\n",
    "        if len(g.coords) >= 2: lines.append(g)\n",
    "    elif isinstance(g, MultiLineString):\n",
    "        for seg in g.geoms:\n",
    "            if len(seg.coords) >= 2: lines.append(seg)\n",
    "\n",
    "if not lines:\n",
    "    raise ValueError(\"SAT_full.geojson innehåller inga linjesegment.\")\n",
    "\n",
    "trail = unary_union(lines)\n",
    "center_lat, center_lon = trail.centroid.y, trail.centroid.x\n",
    "\n",
    "# --- 1) Buffert runt leden som sökzon för iNat ---\n",
    "BUFFER_DEG = 0.003  # ~300 m vid 59–60° lat, justera vid behov\n",
    "search_geom = trail.buffer(BUFFER_DEG)\n",
    "if isinstance(search_geom, (Polygon, MultiPolygon)):\n",
    "    search_geom = search_geom.simplify(0.0002, preserve_topology=True)\n",
    "\n",
    "# --- 2) iNaturalist helpers (loopar alla delpolygoner) ---  \n",
    "import time, requests\n",
    "from shapely.geometry import shape, Polygon, MultiPolygon, LineString\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "INAT_URL = \"https://api.inaturalist.org/v1/observations\"\n",
    "\n",
    "import time, requests\n",
    "from shapely.geometry import shape, Polygon, MultiPolygon, LineString\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "INAT_URL = \"https://api.inaturalist.org/v1/observations\"\n",
    "\n",
    "def _polygon_param_from_poly(poly: Polygon, simplify_tol: float = 0.0002, step: int = 1):\n",
    "    p = poly.simplify(simplify_tol, preserve_topology=True)\n",
    "    ring = list(p.exterior.coords)[::step]\n",
    "    if ring[0] != ring[-1]:\n",
    "        ring.append(ring[0])\n",
    "    return \",\".join(f\"{lng},{lat}\" for (lng, lat) in ring)\n",
    "\n",
    "def _bbox_params_from_poly(poly: Polygon):\n",
    "    minx, miny, maxx, maxy = poly.bounds\n",
    "    return {\"swlng\": minx, \"swlat\": miny, \"nelng\": maxx, \"nelat\": maxy}\n",
    "\n",
    "def _inat_query_for_polygon(poly: Polygon, params_base: dict, per_page=200, max_pages=5, pause=0.2, pbar=None):\n",
    "    \"\"\"\n",
    "    Kör iNat mot polygon. Har adaptiv förenkling + bbox-fallback.\n",
    "    Uppdaterar valfri tqdm-progressbar efter varje hämtad sida.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    params = dict(params_base)\n",
    "    params.update({\n",
    "        \"verifiable\": \"true\",\n",
    "        \"order_by\": \"observed_on\",\n",
    "        \"order\": \"desc\",\n",
    "        \"per_page\": per_page\n",
    "    })\n",
    "\n",
    "    # 1) adaptiv polygon (för att undvika 414)\n",
    "    for simplify_tol in (0.0002, 0.0004, 0.0008, 0.0016):\n",
    "        for step in (1, 2, 3, 4):\n",
    "            polygon_param = _polygon_param_from_poly(poly, simplify_tol=simplify_tol, step=step)\n",
    "            params_poly = dict(params, polygon=polygon_param)\n",
    "            try:\n",
    "                # Första sidan\n",
    "                r = requests.get(INAT_URL, params=dict(params_poly, page=1), timeout=30)\n",
    "                if r.status_code == 414:\n",
    "                    raise requests.HTTPError(\"414 URI Too Large (polygon)\", response=r)\n",
    "                r.raise_for_status()\n",
    "                data = r.json()\n",
    "                batch = data.get(\"results\", [])\n",
    "                results.extend(batch)\n",
    "                if pbar: pbar.update(1)\n",
    "\n",
    "                # Paginerat\n",
    "                for page in range(2, max_pages + 1):\n",
    "                    r = requests.get(INAT_URL, params=dict(params_poly, page=page), timeout=30)\n",
    "                    r.raise_for_status()\n",
    "                    b2 = r.json().get(\"results\", [])\n",
    "                    results.extend(b2)\n",
    "                    if pbar: pbar.update(1)\n",
    "                    if len(b2) < per_page:\n",
    "                        break\n",
    "                    time.sleep(pause)\n",
    "                return results\n",
    "            except requests.HTTPError as e:\n",
    "                # prova nästa simplifiering—bubbla inte upp 414\n",
    "                if getattr(e, \"response\", None) is None or e.response.status_code != 414:\n",
    "                    raise\n",
    "\n",
    "    # 2) Fallback till bbox\n",
    "    params_bbox = dict(params, **_bbox_params_from_poly(poly))\n",
    "    for page in range(1, max_pages + 1):\n",
    "        r = requests.get(INAT_URL, params=dict(params_bbox, page=page), timeout=30)\n",
    "        r.raise_for_status()\n",
    "        b = r.json().get(\"results\", [])\n",
    "        results.extend(b)\n",
    "        if pbar: pbar.update(1)\n",
    "        if len(b) < per_page:\n",
    "            break\n",
    "        time.sleep(pause)\n",
    "    return results\n",
    "\n",
    "def fetch_inat_all_parts(geom_like,\n",
    "                         iconic_taxa=None, d1=None, d2=None,\n",
    "                         per_page=200, max_pages=5, pause=0.2,\n",
    "                         show_progress=True, desc=\"Fetch\"):\n",
    "    \"\"\"\n",
    "    Tar LineString/Polygon/MultiPolygon, buffrar vid behov, loopar delpolygoner,\n",
    "    deduplar observationer och visar progressbar.\n",
    "    \"\"\"\n",
    "    g = geom_like if hasattr(geom_like, \"geom_type\") else shape(geom_like)\n",
    "    if g.geom_type == \"LineString\":\n",
    "        g = g.buffer(0.0015)  # ~150 m\n",
    "    elif g.geom_type not in (\"Polygon\", \"MultiPolygon\"):\n",
    "        g = unary_union(g)\n",
    "\n",
    "    polys = [g] if isinstance(g, Polygon) else [p for p in g.geoms if p.area > 1e-10]\n",
    "\n",
    "    base = {}\n",
    "    if iconic_taxa: base[\"iconic_taxa\"] = iconic_taxa\n",
    "    if d1: base[\"d1\"] = d1\n",
    "    if d2: base[\"d2\"] = d2\n",
    "\n",
    "    total_steps = len(polys) * max_pages  # ungefärligt (per polygon x sidor)\n",
    "    pbar = tqdm(total=total_steps, desc=desc, unit=\"page\", leave=False) if show_progress else None\n",
    "\n",
    "    all_obs = {}\n",
    "    try:\n",
    "        for poly in polys:\n",
    "            part = _inat_query_for_polygon(poly, base, per_page=per_page, max_pages=max_pages, pause=pause, pbar=pbar)\n",
    "            for o in part:\n",
    "                all_obs[o[\"id\"]] = o\n",
    "    finally:\n",
    "        if pbar: pbar.close()\n",
    "    return list(all_obs.values())\n",
    "\n",
    "\n",
    "# --- 3) Hämta data (~1000 per kategori om det finns) --- \n",
    "from datetime import date, timedelta\n",
    "d2 = date.today().isoformat()\n",
    "d1 = (date.today() - timedelta(days=20)).isoformat()  # senaste 30 dagarna\n",
    "\n",
    "# Växter\n",
    "plants = fetch_inat_all_parts(search_geom, iconic_taxa=\"Plantae\", d1=d1, d2=d2,\n",
    "                              per_page=200, max_pages=5, show_progress=True, desc=\"Plantae\")\n",
    "\n",
    "# Djur (visa övergripande progress för taxagrupper)\n",
    "animal_taxa = [\"Aves\",\"Mammalia\",\"Reptilia\",\"Amphibia\",\"Insecta\",\"Arachnida\",\"Mollusca\",\"Animalia\"]\n",
    "animals_all = []\n",
    "with tqdm(total=len(animal_taxa), desc=\"Animal taxa\", unit=\"taxon\") as t_taxa:\n",
    "    for tx in animal_taxa:\n",
    "        part = fetch_inat_all_parts(search_geom, iconic_taxa=tx, d1=d1, d2=d2,\n",
    "                                    per_page=200, max_pages=5, show_progress=True, desc=tx)\n",
    "        animals_all.extend(part)\n",
    "        t_taxa.update(1)\n",
    "animals = list({o[\"id\"]: o for o in animals_all}.values())\n",
    "print(f\"Växter: {len(plants)} | Djur: {len(animals)}\")\n",
    "\n",
    "# --- 4) Bygg FeatureCollections med 'time' + bild i popup ---\n",
    "def obs_to_feature(o):\n",
    "    if not o.get(\"geojson\"): return None\n",
    "    lon, lat = o[\"geojson\"][\"coordinates\"]\n",
    "    date = o.get(\"observed_on\") or o.get(\"created_at\") or \"\"\n",
    "    taxon = o.get(\"taxon\") or {}\n",
    "    cname = taxon.get(\"preferred_common_name\") or taxon.get(\"name\") or \"okänd\"\n",
    "    sname = taxon.get(\"name\") or \"\"\n",
    "    url   = f\"https://www.inaturalist.org/observations/{o['id']}\"\n",
    "    img = \"\"\n",
    "    photos = o.get(\"photos\") or []\n",
    "    if photos:\n",
    "        raw = photos[0].get(\"url\", \"\")\n",
    "        if raw: img = raw.replace(\"square\",\"medium\")\n",
    "\n",
    "    popup = f\"<b>{cname}</b><br><i>{sname}</i><br>{date}<br>\"\n",
    "    if img: popup += f\"<img src='{img}' width='220'><br>\"\n",
    "    popup += f\"<a href='{url}' target='_blank'>Visa i iNaturalist</a>\"\n",
    "\n",
    "    return {\n",
    "        \"type\":\"Feature\",\n",
    "        \"geometry\":{\"type\":\"Point\",\"coordinates\":[lon,lat]},\n",
    "        \"properties\":{\"time\":date,\"popup\":popup}\n",
    "    }\n",
    "\n",
    "def to_fc(obs): \n",
    "    feats = [obs_to_feature(o) for o in obs]\n",
    "    return {\"type\":\"FeatureCollection\",\"features\":[f for f in feats if f]}\n",
    "\n",
    "plants_fc  = to_fc(plants)\n",
    "animals_fc = to_fc(animals)\n",
    "\n",
    "# --- 5) Karta med separata tidslager ---\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=10, control_scale=True)\n",
    "\n",
    "# leden\n",
    "folium.GeoJson(mapping(trail), name=\"SAT-led\",\n",
    "               style_function=lambda x: {\"color\":\"#1e40af\",\"weight\":3}).add_to(m)\n",
    "\n",
    "# (valfritt) visa bufferten\n",
    "if isinstance(search_geom,(Polygon,MultiPolygon)):\n",
    "    folium.GeoJson(mapping(search_geom), name=\"Sökzon\",\n",
    "                   style_function=lambda x: {\"color\":\"#3388ff\",\"weight\":1,\"fillOpacity\":0.05}).add_to(m)\n",
    "\n",
    "TimestampedGeoJson(plants_fc,  period=\"P1D\", duration=\"P3D\",\n",
    "                   add_last_point=True, auto_play=True,  loop=True,\n",
    "                   date_options=\"YYYY-MM-DD\", name=\"Växter – tidsserie\").add_to(m)\n",
    "\n",
    "TimestampedGeoJson(animals_fc, period=\"P1D\", duration=\"P3D\",\n",
    "                   add_last_point=True, auto_play=False, loop=True,\n",
    "                   date_options=\"YYYY-MM-DD\", name=\"Djur – tidsserie\").add_to(m)\n",
    "\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "m.save(\"inat_realtime_poc2.html\")\n",
    "print(\"Sparade: inat_realtime_poc2.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7985bbf6-1c81-4c37-be57-8ddc3998b60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6083374e-1ea2-432f-97a5-494c45cad8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# --- Pick a group label from an observation dict ---------------------------\n",
    "def get_group_label(obs):\n",
    "    \"\"\"\n",
    "    Try common places for a taxon group label.\n",
    "    Priority:\n",
    "      1) obs['group'] / obs['taxon_group'] (if you already computed it)\n",
    "      2) obs['taxon']['iconic_taxon_name'] (iNaturalist)\n",
    "      3) obs['taxon']['rank'] == 'class' from ancestors (fallback)\n",
    "      4) 'Other'\n",
    "    \"\"\"\n",
    "    # 1) Precomputed fields\n",
    "    for k in (\"group\", \"taxon_group\"):\n",
    "        v = obs.get(k)\n",
    "        if v: \n",
    "            return str(v)\n",
    "\n",
    "    # 2) iNaturalist taxon iconics\n",
    "    taxon = obs.get(\"taxon\") or {}\n",
    "    iconic = taxon.get(\"iconic_taxon_name\")\n",
    "    if iconic:\n",
    "        return str(iconic)\n",
    "\n",
    "    # 3) Fallback: try to read 'class' from ancestors if present\n",
    "    # iNat shape: taxon['ancestors'] is a list of taxon dicts with 'rank'/'name'\n",
    "    for anc in (taxon.get(\"ancestors\") or []):\n",
    "        if str(anc.get(\"rank\", \"\")).lower() == \"class\" and anc.get(\"name\"):\n",
    "            return str(anc[\"name\"])\n",
    "\n",
    "    return \"Other\"\n",
    "\n",
    "# --- Build all_groups from a list[dict] or a pandas DataFrame --------------\n",
    "def build_all_groups(data, group_col=None, whitelist=None, blacklist=None, min_per_group=1):\n",
    "    \"\"\"\n",
    "    data: list of observation dicts OR a pandas DataFrame.\n",
    "    group_col: if using DataFrame and you already have a group column, name it here.\n",
    "    whitelist/blacklist: sets of group names to include/exclude.\n",
    "    min_per_group: groups smaller than this are folded into 'Other'.\n",
    "    \"\"\"\n",
    "    groups = defaultdict(list)\n",
    "\n",
    "    # Case A: pandas DataFrame\n",
    "    try:\n",
    "        import pandas as pd  # only used if df is passed\n",
    "        is_df = isinstance(data, pd.DataFrame)\n",
    "    except Exception:\n",
    "        is_df = False\n",
    "\n",
    "    if is_df:\n",
    "        if group_col and group_col in data.columns:\n",
    "            for g, sub in data.groupby(group_col):\n",
    "                gname = str(g) if g is not None else \"Other\"\n",
    "                if whitelist and gname not in whitelist: \n",
    "                    continue\n",
    "                if blacklist and gname in blacklist: \n",
    "                    continue\n",
    "                groups[gname].extend(sub.to_dict(\"records\"))\n",
    "        else:\n",
    "            # derive group from each row\n",
    "            for _, row in data.iterrows():\n",
    "                obs = row.to_dict()\n",
    "                gname = get_group_label(obs)\n",
    "                if whitelist and gname not in whitelist: \n",
    "                    continue\n",
    "                if blacklist and gname in blacklist: \n",
    "                    continue\n",
    "                groups[gname].append(obs)\n",
    "    else:\n",
    "        # Case B: list of dict observations\n",
    "        for obs in data:\n",
    "            gname = get_group_label(obs)\n",
    "            if whitelist and gname not in whitelist: \n",
    "                continue\n",
    "            if blacklist and gname in blacklist: \n",
    "                continue\n",
    "            groups[gname].append(obs)\n",
    "\n",
    "    # Fold tiny groups into \"Other\" if requested\n",
    "    if min_per_group > 1:\n",
    "        other = []\n",
    "        for g in list(groups.keys()):\n",
    "            if len(groups[g]) < min_per_group and g != \"Other\":\n",
    "                other.extend(groups.pop(g))\n",
    "        if other:\n",
    "            groups[\"Other\"].extend(other)\n",
    "\n",
    "    # Sort by descending size (nice for reporting/legend order)\n",
    "    return dict(sorted(groups.items(), key=lambda kv: (-len(kv[1]), kv[0])))\n",
    "\n",
    "# --- Example usage ---------------------------------------------------------\n",
    "# 1) From a plain list of observation dicts (e.g., iNat API 'results'):\n",
    "# observations = results  # list[dict]\n",
    "# all_groups = build_all_groups(observations, whitelist=None, blacklist=None, min_per_group=3)\n",
    "\n",
    "# 2) From a pandas DataFrame with a 'group' column you computed earlier:\n",
    "# all_groups = build_all_groups(df, group_col=\"group\", min_per_group=1)\n",
    "\n",
    "# Quick sanity print:\n",
    "# for g, lst in all_groups.items():\n",
    "#     print(f\"{g}: {len(lst)} observations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77872f66-5916-432d-bde3-0523b52df4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aves:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fca097b9d446e3851c62f3aee43284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mammalia:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Amphibia:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Insecta:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Arachnida:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mollusca:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea13bb32ff44780b684b822fbc3013f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Animalia:   0%|          | 0/80 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='api.inaturalist.org', port=443): Read timed out. (read timeout=30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1423\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1423\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/util/retry.py:474\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/util/util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:367\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    369\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='api.inaturalist.org', port=443): Read timed out. (read timeout=30)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m all_groups \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlantae\u001b[39m\u001b[38;5;124m\"\u001b[39m: plants}\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tx \u001b[38;5;129;01min\u001b[39;00m animal_taxa:\n\u001b[0;32m---> 86\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_inat_all_parts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_geom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43miconic_taxa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43md1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mper_page\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_pages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# progressbar för hämtningen (som du hade)\u001b[39;49;00m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtx\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     all_groups[tx] \u001b[38;5;241m=\u001b[39m obs\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# --- Kartan ---\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 145\u001b[0m, in \u001b[0;36mfetch_inat_all_parts\u001b[0;34m(geom_like, iconic_taxa, d1, d2, per_page, max_pages, pause, show_progress, desc)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m poly \u001b[38;5;129;01min\u001b[39;00m polys:\n\u001b[0;32m--> 145\u001b[0m         part \u001b[38;5;241m=\u001b[39m \u001b[43m_inat_query_for_polygon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_page\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_page\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_pages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_pages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpause\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpause\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m part:\n\u001b[1;32m    147\u001b[0m             all_obs[o[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m o\n",
      "Cell \u001b[0;32mIn[2], line 80\u001b[0m, in \u001b[0;36m_inat_query_for_polygon\u001b[0;34m(poly, params_base, per_page, max_pages, pause, pbar)\u001b[0m\n\u001b[1;32m     77\u001b[0m params_poly \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(params, polygon\u001b[38;5;241m=\u001b[39mpolygon_param)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# Första sidan\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINAT_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams_poly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m414\u001b[39m:\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m414 URI Too Large (polygon)\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m=\u001b[39mr)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/requests/adapters.py:713\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='api.inaturalist.org', port=443): Read timed out. (read timeout=30)"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import mapping\n",
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "\n",
    "# progress bars\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(x, **kwargs):  # fallback if tqdm isn't installed\n",
    "        return x\n",
    "\n",
    "# --- Färgkodning per taxa ---\n",
    "TAXON_COLORS = {\n",
    "    \"Plantae\":   \"#2b8a3e\",  # grön\n",
    "    \"Aves\":      \"#1d4ed8\",  # blå\n",
    "    \"Mammalia\":  \"#78350f\",  # brun\n",
    "    \"Reptilia\":  \"#059669\",  # grön-turkos\n",
    "    \"Amphibia\":  \"#14b8a6\",  # cyan\n",
    "    \"Insecta\":   \"#eab308\",  # gul\n",
    "    \"Arachnida\": \"#7f1d1d\",  # mörkröd\n",
    "    \"Mollusca\":  \"#9333ea\",  # lila\n",
    "    \"Animalia\":  \"#6b7280\",  # grå\n",
    "}\n",
    "\n",
    "# --- Helper: observation → Feature med popup ---\n",
    "def obs_to_feature(o, color=\"#3388ff\"):\n",
    "    gj = o.get(\"geojson\")\n",
    "    if not (isinstance(gj, dict) and isinstance(gj.get(\"coordinates\"), (list, tuple)) and len(gj[\"coordinates\"]) >= 2):\n",
    "        return None\n",
    "\n",
    "    lon, lat = gj[\"coordinates\"][:2]\n",
    "\n",
    "    # iNat tider: preferera observed_on (datum), annars time_observed_at (ISO), annars created_at\n",
    "    date = o.get(\"observed_on\") or o.get(\"time_observed_at\") or o.get(\"created_at\") or \"\"\n",
    "\n",
    "    taxon = o.get(\"taxon\") or {}\n",
    "    cname = taxon.get(\"preferred_common_name\") or taxon.get(\"name\") or \"okänd\"\n",
    "    sname = taxon.get(\"name\") or \"\"\n",
    "    url   = f\"https://www.inaturalist.org/observations/{o['id']}\"\n",
    "\n",
    "    # Förhandsbild\n",
    "    img = \"\"\n",
    "    photos = o.get(\"photos\") or []\n",
    "    if photos:\n",
    "        raw = photos[0].get(\"url\", \"\")\n",
    "        if raw:\n",
    "            img = raw.replace(\"square\", \"medium\")\n",
    "\n",
    "    popup = f\"<b>{cname}</b><br><i>{sname}</i><br>{date}<br>\"\n",
    "    if img:\n",
    "        popup += f\"<img src='{img}' width='220'><br>\"\n",
    "    popup += f\"<a href='{url}' target='_blank'>Visa i iNaturalist</a>\"\n",
    "\n",
    "    return {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\"type\": \"Point\", \"coordinates\": [lon, lat]},\n",
    "        \"properties\": {\n",
    "            \"time\": date,   # TimestampedGeoJson accepterar 'time' som sträng per feature\n",
    "            \"popup\": popup,\n",
    "            \"icon\": \"circle\",\n",
    "            \"iconstyle\": {\n",
    "                \"color\": color,\n",
    "                \"fillColor\": color,\n",
    "                \"fillOpacity\": 0.8\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "def to_fc(obs, color=\"#3388ff\", desc=None):\n",
    "    \"\"\"Bygger FeatureCollection med progressbar + returnerar bounds och antal hoppade.\"\"\"\n",
    "    feats, bounds, skipped = [], [], 0\n",
    "    for o in tqdm(obs, desc=desc, leave=False):\n",
    "        f = obs_to_feature(o, color)\n",
    "        if f:\n",
    "            feats.append(f)\n",
    "            lon, lat = f[\"geometry\"][\"coordinates\"]\n",
    "            bounds.append((lat, lon))\n",
    "        else:\n",
    "            skipped += 1\n",
    "    return {\"type\": \"FeatureCollection\", \"features\": feats}, bounds, skipped\n",
    "\n",
    "# --- Taxagrupper att hämta ---\n",
    "animal_taxa = [\"Aves\",\"Mammalia\",\"Reptilia\",\"Amphibia\",\"Insecta\",\"Arachnida\",\"Mollusca\",\"Animalia\"]\n",
    "all_groups = {\"Plantae\": plants}\n",
    "for tx in animal_taxa:\n",
    "    obs = fetch_inat_all_parts(\n",
    "        search_geom,\n",
    "        iconic_taxa=tx,\n",
    "        d1=d1, d2=d2,\n",
    "        per_page=200, max_pages=5,\n",
    "        show_progress=True,   # progressbar för hämtningen (som du hade)\n",
    "        desc=tx\n",
    "    )\n",
    "    all_groups[tx] = obs\n",
    "\n",
    "# --- Kartan ---\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=10, control_scale=True)\n",
    "\n",
    "# SAT-leden\n",
    "folium.GeoJson(\n",
    "    mapping(trail),\n",
    "    name=\"SAT-led\",\n",
    "    style_function=lambda x: {\"color\": \"#1e40af\", \"weight\": 3}\n",
    ").add_to(m)\n",
    "\n",
    "# (valfritt) Bufferten\n",
    "folium.GeoJson(\n",
    "    mapping(search_geom),\n",
    "    name=\"Sökzon\",\n",
    "    style_function=lambda x: {\"color\": \"#3388ff\",\"weight\":1,\"fillOpacity\":0.05}\n",
    ").add_to(m)\n",
    "\n",
    "# --- Lägg till ett tidslager per taxa med egen färg ---\n",
    "all_bounds = []\n",
    "for tx, obs in tqdm(all_groups.items(), desc=\"Bygger tidslager\", total=len(all_groups)):\n",
    "    color = TAXON_COLORS.get(tx, \"#3388ff\")\n",
    "    fc, bounds, skipped = to_fc(obs, color=color, desc=f\"{tx} → features\")\n",
    "    all_bounds.extend(bounds)\n",
    "\n",
    "    # VIKTIGT: lägg TimestampedGeoJson DIREKT på kartan (inte i FeatureGroup) för att undvika crash\n",
    "    TimestampedGeoJson(\n",
    "        fc,\n",
    "        name=f\"{tx} – tidsserie\",  # så syns lagret i LayerControl\n",
    "        control=True,\n",
    "        period=\"P1D\",\n",
    "        duration=\"P3D\",\n",
    "        add_last_point=True,\n",
    "        auto_play=False,\n",
    "        loop=True,\n",
    "        max_speed=1,\n",
    "        loop_button=True,\n",
    "        date_options=\"YYYY-MM-DD\",\n",
    "        time_slider_drag_update=True\n",
    "    ).add_to(m)\n",
    "\n",
    "    if skipped:\n",
    "        # skriv i tqdm-raden för att inte förstöra progressbaren\n",
    "        tqdm.write(f\"⚠️ {tx}: hoppade över {skipped} obs utan koordinater/bild/format.\")\n",
    "\n",
    "# Auto-zoom till alla punkter om vi har några\n",
    "if all_bounds:\n",
    "    m.fit_bounds(all_bounds)\n",
    "\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "m.save(\"inat_taxa_layers_colored.html\")\n",
    "print(\"✅ Sparade: inat_taxa_layers_colored.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0040191a-25d9-454a-9e52-01611c051ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce016b3-4693-4458-ae44-078f63414953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number observations fetched \n",
    "for tx, obs in all_groups.items():\n",
    "    print(f\"{tx}: {len(obs)} observations\")  \n",
    "\n",
    "total_obs = sum(len(obs) for obs in all_groups.values())\n",
    "print(f\"Total observations fetched: {total_obs}\")  \n",
    "list(all_groups[\"Aves\"][:3])  # look at first 3 bird obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff34ef-f48f-4a87-9bc2-f2d6e048ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def summarize_by_date(observations, label=\"\"):\n",
    "    \"\"\"Takes a list of iNat obs and returns a dataframe grouped by date\"\"\"\n",
    "    rows = []\n",
    "    for o in observations:\n",
    "        date = o.get(\"observed_on\") or o.get(\"created_at\")\n",
    "        if date:\n",
    "            rows.append({\"date\": date[:10], \"id\": o[\"id\"]})\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[\"date\",\"count\"])\n",
    "    summary = df.groupby(\"date\").count().rename(columns={\"id\":\"count\"}).reset_index()\n",
    "    summary[\"group\"] = label\n",
    "    return summary\n",
    "\n",
    "# Example: make summaries for each group\n",
    "dfs = []\n",
    "for tx, obs in all_groups.items():\n",
    "    dfs.append(summarize_by_date(obs, label=tx))\n",
    "\n",
    "summary_all = pd.concat(dfs).sort_values([\"date\",\"group\"])\n",
    "\n",
    "summary_all.head(10)   # look at first 10 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a570d9f-914b-4478-a66a-41405286fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pivot = summary_all.pivot(index=\"date\", columns=\"group\", values=\"count\").fillna(0)\n",
    "\n",
    "pivot.plot(kind=\"bar\", stacked=True, figsize=(12,6))\n",
    "plt.title(\"Observations per day by group\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5fa7b1-b75c-4b5c-b0b4-4332ea0fab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"GeoJSON saved to {output_path}\")\n",
    "    print(f\"Finished in {duration:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ee679-14b0-44ec-98e1-2cf78a381db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6711cab1-d002-4516-a685-5d384138fe75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
