{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9e5db7-dea3-430a-9b04-b6c7a8a79783",
   "metadata": {},
   "source": [
    "## 73 SAT Wheelchair Map\n",
    "\n",
    "### version 3.3 \n",
    "\n",
    "* this [Notebook](https://github.com/salgo60/Stockholm_Archipelago_Trail/blob/main/notebook/Issue_73_—_SAT_Wheelchair_Map_&_Stats.ipynb)\n",
    "  * Latest maps [SAT Wheel chair Map](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/notebook/output/SAT_WHEELCHAIR_073_wheelchair_latest.html) \n",
    "\n",
    "---- \n",
    "* Issue [73 SAT Wheel chair map](https://github.com/salgo60/Stockholm_Archipelago_Trail/issues/73)\n",
    "\n",
    "* Try to get better quality WHeelchair data in OSM for SAT\n",
    "---- \n",
    "\n",
    "\n",
    "       \n",
    "    \n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8ce4b5-f854-433f-a139-8ea08d5b87fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2025-09-16 04:10:16\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = now.timestamp()\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Start:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083df370-9323-47ec-a1db-6f046b9741cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fd/md6r13sj0wsbg_6_xl160d300000gn/T/ipykernel_23854/3636932931.py:444: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  lines_union = sat_m.unary_union\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./output/SAT_WHEELCHAIR_073_wheelchair_20250916_0410.html\n",
      "Updated: output/SAT_WHEELCHAIR_073_wheelchair_latest.html\n",
      "Saved map: ./output/SAT_WHEELCHAIR_073_wheelchair_20250916_0410.html\n",
      "Saved stats: ./output/SAT_WHEELCHAIR_073_wheelchair_stats_20250916_0410.csv\n",
      "Saved per-section stats: ./output/SAT_WHEELCHAIR_073_wheelchair_stats_sections_20250916_0410.csv\n",
      "Saved raw POIs: ./output/SAT_WHEELCHAIR_073_wheelchair_raw_20250916_0410.csv\n",
      "Saved per-section stats: ./output/SAT_WHEELCHAIR_073_wheelchair_stats_sections_20250916_0410.csv\n",
      "      section status_bucket dist_band  count\n",
      "  SAT Arholma       missing     ≤100m      3\n",
      " SAT Finnhamn       missing     ≤100m      8\n",
      "SAT Fjärdlång       missing     ≤100m      1\n",
      " SAT Furusund       missing     ≤100m      3\n",
      "   SAT Grinda       missing     ≤100m      5\n",
      "     SAT Lidö       missing     ≤100m      5\n",
      "     SAT Möja       missing     ≤100m      1\n",
      "  SAT Nåttarö       missing     ≤100m      1\n",
      "     SAT Ornö       missing     ≤100m      2\n",
      "  SAT Runmarö       missing     ≤100m      1\n",
      "     SAT Rånö       missing     ≤100m      6\n",
      " SAT Sandhamn       missing     ≤100m      3\n",
      "  SAT Svartsö       missing     ≤100m      1\n",
      "      SAT Utö       missing     ≤100m      4\n",
      "      SAT Ålö       missing     ≤100m      1\n",
      "  SAT Arholma       missing     ≤200m      8\n",
      "SAT Fjärdlång       missing     ≤200m      5\n",
      " SAT Furusund       missing     ≤200m      3\n",
      "   SAT Grinda       missing     ≤200m     11\n",
      "     SAT Lidö       missing     ≤200m      6\n",
      "     SAT Möja       missing     ≤200m      1\n",
      "    SAT Nämdö       missing     ≤200m      1\n",
      "  SAT Nåttarö       missing     ≤200m      8\n",
      "     SAT Ornö       missing     ≤200m      3\n",
      "  SAT Runmarö       missing     ≤200m      2\n",
      "     SAT Rånö       missing     ≤200m      5\n",
      "      SAT Utö       missing     ≤200m      6\n",
      "      SAT Ålö       missing     ≤200m      3\n",
      "  SAT Arholma       missing      ≤50m     20\n",
      " SAT Finnhamn       missing      ≤50m     36\n",
      "SAT Fjärdlång       missing      ≤50m      7\n",
      " SAT Furusund       missing      ≤50m      7\n",
      "   SAT Grinda       missing      ≤50m     28\n",
      " SAT Ingmarsö       missing      ≤50m     11\n",
      " SAT Landsort       missing      ≤50m     26\n",
      "     SAT Lidö       missing      ≤50m      5\n",
      "     SAT Möja       missing      ≤50m      6\n",
      "    SAT Nämdö       missing      ≤50m     10\n",
      "  SAT Nåttarö       missing      ≤50m     11\n",
      "     SAT Ornö       missing      ≤50m     15\n",
      "  SAT Runmarö       missing      ≤50m      3\n",
      "     SAT Rånö       missing      ≤50m      6\n",
      " SAT Sandhamn       missing      ≤50m     10\n",
      "  SAT Svartsö       missing      ≤50m     10\n",
      "      SAT Utö       missing      ≤50m     28\n",
      "      SAT Ålö       missing      ≤50m      8\n",
      "     Öjaleden       missing      ≤50m      8\n",
      "  SAT Arholma            no     ≤100m      2\n",
      " SAT Finnhamn            no     ≤100m      3\n",
      "   SAT Grinda            no     ≤100m      8\n",
      "     SAT Lidö            no     ≤100m      2\n",
      "     SAT Ornö            no     ≤100m      2\n",
      "     SAT Rånö            no     ≤100m      4\n",
      "      SAT Utö            no     ≤100m      2\n",
      " SAT Finnhamn            no     ≤200m     10\n",
      "   SAT Grinda            no     ≤200m      4\n",
      " SAT Ingmarsö            no     ≤200m      4\n",
      "     SAT Möja            no     ≤200m      1\n",
      "    SAT Yxlan            no     ≤200m      4\n",
      "  SAT Arholma            no      ≤50m     16\n",
      " SAT Finnhamn            no      ≤50m     18\n",
      "SAT Fjärdlång            no      ≤50m      4\n",
      "   SAT Grinda            no      ≤50m     22\n",
      " SAT Ingmarsö            no      ≤50m      6\n",
      " SAT Landsort            no      ≤50m      6\n",
      "     SAT Lidö            no      ≤50m      2\n",
      "     SAT Möja            no      ≤50m      2\n",
      "    SAT Nämdö            no      ≤50m      4\n",
      "  SAT Nåttarö            no      ≤50m      4\n",
      "     SAT Ornö            no      ≤50m      3\n",
      "  SAT Runmarö            no      ≤50m      1\n",
      "     SAT Rånö            no      ≤50m      4\n",
      " SAT Sandhamn            no      ≤50m      4\n",
      "      SAT Utö            no      ≤50m      5\n",
      "      SAT Ålö            no      ≤50m      4\n",
      "     Öjaleden            no      ≤50m      2\n",
      " SAT Finnhamn           yes     ≤100m      1\n",
      "     SAT Ornö           yes     ≤100m      1\n",
      "  SAT Svartsö           yes     ≤100m      2\n",
      "   SAT Grinda           yes     ≤200m      5\n",
      "  SAT Svartsö           yes     ≤200m      3\n",
      " SAT Finnhamn           yes      ≤50m      2\n",
      "   SAT Grinda           yes      ≤50m     17\n",
      " SAT Landsort           yes      ≤50m      1\n",
      "     SAT Möja           yes      ≤50m      1\n",
      "  SAT Nåttarö           yes      ≤50m      2\n",
      "  SAT Runmarö           yes      ≤50m      1\n",
      "     SAT Rånö           yes      ≤50m      2\n",
      " SAT Sandhamn           yes      ≤50m      2\n",
      "  SAT Svartsö           yes      ≤50m      4\n",
      "      SAT Ålö           yes      ≤50m      4\n",
      "✅ Wheelchair analysis ready → ./output/SAT_WHEELCHAIR_073_wheelchair_20250916_0410.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/array.py:408: UserWarning: Geometry is in a geographic CRS. Results from 'sjoin_nearest' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/array.py:408: UserWarning: Geometry is in a geographic CRS. Results from 'sjoin_nearest' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Issue 73 — SAT: markera rullstol (wheelchair)\n",
    "# ----------------------------------------------------------------------------\n",
    "# Complete, notebook-ready rewrite\n",
    "#\n",
    "# What this does\n",
    "#  - Loads SAT trail geometry (from Wikidata -> OSM Overpass)\n",
    "#  - Fetches wheelchair-relevant POIs near the trail using small, reliable\n",
    "#    Overpass queries (tagged first, then curated amenities/tourism), tiled if needed\n",
    "#  - Computes distance bands to the trail (≤50 m, ≤100 m, ≤200 m)\n",
    "#  - Builds a Folium map with points colored by wheelchair status\n",
    "#      * green  = wheelchair=yes\n",
    "#      * red    = wheelchair=no\n",
    "#      * orange = missing/unknown\n",
    "#    Layers are grouped by distance band for easy toggling.\n",
    "#  - Popups start with Wheelmap link, then OSM + iD editor\n",
    "#  - Exports CSVs: raw POIs and stats (status × distance band), and saves HTML\n",
    "#    as timestamped + *_latest.html\n",
    "#\n",
    "# Dependencies (install if needed):\n",
    "#   pip install requests pandas geopandas shapely folium\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "# --- Stdlib\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "from urllib.parse import quote\n",
    "from datetime import datetime\n",
    "import html as _html\n",
    "\n",
    "# --- Third-party\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "import shapely\n",
    "import folium\n",
    "from folium import GeoJson, GeoJsonPopup\n",
    "\n",
    "# =================== Config ==================================================\n",
    "ISSUE_NUMBER = 73\n",
    "PROJECT_NAME = \"SAT_WHEELCHAIR_073\"\n",
    "OUTPUT_DIR   = \"./output\"           # change if you want another folder\n",
    "STAMP        = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "WD_ENDPOINT  = \"https://query.wikidata.org/sparql\"\n",
    "OVERPASS_ENDPOINTS = [\n",
    "    \"https://overpass-api.de/api/interpreter\",\n",
    "    \"https://overpass.kumi.systems/api/interpreter\",\n",
    "]\n",
    "UA = {\"User-Agent\": \"SAT-wheelchair/1.1 (salgo60 tools)\"}\n",
    "\n",
    "# Distance bands (meters)\n",
    "DIST_BANDS = [50, 100, 200]\n",
    "\n",
    "# Tiling the bbox keeps Overpass requests small & reliable\n",
    "TILE_NX = 2\n",
    "TILE_NY = 2\n",
    "\n",
    "# Curated feature classes where wheelchair=* is most relevant\n",
    "CURATED_AMENITY = (\n",
    "    \"toilets|cafe|restaurant|shelter|drinking_water|\"\n",
    "    \"place_of_worship|atm|pub|bar\"\n",
    ")\n",
    "CURATED_TOURISM = \"attraction|museum|information|alpine_hut|camp_site|picnic_site|viewpoint\"\n",
    "\n",
    "# Colors\n",
    "COLOR_YES = \"#2ecc71\"   # green\n",
    "COLOR_NO  = \"#e74c3c\"   # red\n",
    "COLOR_MIS = \"#f39c12\"   # orange (missing/unknown)\n",
    "TRAIL_COLOR = \"#111827\" # near-black\n",
    "\n",
    "# =================== Helpers: links =========================================\n",
    "\n",
    "def _osm_view_link(osm_type: str, osmid: int | str) -> str:\n",
    "    return f\"https://www.openstreetmap.org/{osm_type}/{int(osmid)}\"\n",
    "\n",
    "def _osm_edit_link(osm_type: str, osmid: int | str) -> str:\n",
    "    t = osm_type.lower()\n",
    "    if t == \"node\":   return f\"https://www.openstreetmap.org/edit?editor=id&node={int(osmid)}\"\n",
    "    if t == \"way\":    return f\"https://www.openstreetmap.org/edit?editor=id&way={int(osmid)}\"\n",
    "    return f\"https://www.openstreetmap.org/edit?editor=id&relation={int(osmid)}\"\n",
    "\n",
    "def _wheelmap_link(osm_type: str, osmid: int | str) -> str:\n",
    "    return f\"https://wheelmap.org/{osm_type}/{int(osmid)}\"\n",
    "\n",
    "# =================== Wikidata: fetch SAT sections ============================\n",
    "\n",
    "def fetch_sat_sections_from_wikidata(trail_qid: str = \"Q131318799\") -> pd.DataFrame:\n",
    "    query = f\"\"\"\n",
    "    SELECT ?section ?sectionLabel ?osmr ?osmw_p10689 ?osmw_p11693 WHERE {{\n",
    "      VALUES ?trail {{ wd:{trail_qid} }}\n",
    "      {{ ?section wdt:P361+ ?trail . }} UNION {{ ?trail wdt:P527 ?section . }}\n",
    "      FILTER(?section != ?trail)\n",
    "      OPTIONAL {{ ?section wdt:P402 ?osmr }}\n",
    "      OPTIONAL {{ ?section wdt:P10689 ?osmw_p10689 }}\n",
    "      OPTIONAL {{ ?section wdt:P11693 ?osmw_p11693 }}\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"sv,en\". }}\n",
    "    }}\n",
    "    ORDER BY ?sectionLabel\n",
    "    \"\"\"\n",
    "    headers = {\"Accept\": \"application/sparql-results+json\", **UA}\n",
    "    r = requests.get(WD_ENDPOINT, params={\"query\": query}, headers=headers, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    rows = []\n",
    "    for b in data[\"results\"][\"bindings\"]:\n",
    "        qid   = b[\"section\"][\"value\"].split(\"/\")[-1]\n",
    "        label = b.get(\"sectionLabel\", {}).get(\"value\", qid)\n",
    "        osmr  = b.get(\"osmr\", {}).get(\"value\")\n",
    "        osmw1 = b.get(\"osmw_p10689\", {}).get(\"value\")\n",
    "        osmw2 = b.get(\"osmw_p11693\", {}).get(\"value\")\n",
    "        osmw  = osmw1 or osmw2\n",
    "        rows.append({\n",
    "            \"section_qid\": qid,\n",
    "            \"sectionLabel\": label,\n",
    "            \"osmr\": pd.to_numeric(osmr, errors=\"coerce\"),\n",
    "            \"osmw\": pd.to_numeric(osmw, errors=\"coerce\"),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df[\"osmr\"] = df[\"osmr\"].astype(\"Int64\")\n",
    "        df[\"osmw\"] = df[\"osmw\"].astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "# =================== Overpass (robust) ======================================\n",
    "\n",
    "def _overpass(query: str, retries: int = 2, pause: float = 2.0) -> dict:\n",
    "    headers = {\n",
    "        \"User-Agent\": UA[\"User-Agent\"],\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "    last_err = None\n",
    "    for ep in OVERPASS_ENDPOINTS:\n",
    "        for i in range(retries):\n",
    "            try:\n",
    "                resp = requests.post(ep, data={\"data\": query}, headers=headers, timeout=180)\n",
    "                if resp.status_code == 429:\n",
    "                    time.sleep(pause * (i + 1)); continue\n",
    "                if resp.status_code >= 400:\n",
    "                    raise RuntimeError(\n",
    "                        f\"Overpass HTTP {resp.status_code} @ {ep}\\n--- Query ---\\n{query}\\n--- Server says ---\\n{resp.text[:2000]}\\n\"\n",
    "                    )\n",
    "                return resp.json()\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "                time.sleep(pause * (i + 1))\n",
    "    raise RuntimeError(f\"Overpass failed on all endpoints.\\nLast error:\\n{last_err}\")\n",
    "\n",
    "# =================== SAT ways from OSM ======================================\n",
    "\n",
    "def _fetch_ways_for_relation(rel_id: int) -> list[dict]:\n",
    "    q = f\"\"\"\n",
    "[out:json][timeout:180];\n",
    "relation({rel_id});\n",
    "way(r);\n",
    "out tags geom;\n",
    "\"\"\"\n",
    "    data = _overpass(q)\n",
    "    return [el for el in data.get(\"elements\", []) if el.get(\"type\") == \"way\"]\n",
    "\n",
    "\n",
    "def _fetch_way(way_id: int) -> list[dict]:\n",
    "    q = f\"\"\"\n",
    "[out:json][timeout:120];\n",
    "way({way_id});\n",
    "out tags geom;\n",
    "\"\"\"\n",
    "    data = _overpass(q)\n",
    "    return [el for el in data.get(\"elements\", []) if el.get(\"type\") == \"way\"]\n",
    "\n",
    "CORE_WAY_TAGS = [\"name\",\"highway\",\"surface\",\"tracktype\",\"foot\",\"bicycle\",\"sac_scale\",\"trail_visibility\",\"smoothness\",\"width\",\"image\"]\n",
    "\n",
    "def _way_to_feature(el: dict) -> dict | None:\n",
    "    if \"geometry\" not in el: return None\n",
    "    coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in el[\"geometry\"]]\n",
    "    if len(coords) < 2: return None\n",
    "    tags = el.get(\"tags\", {}) or {}\n",
    "    props = {\"osmid\": el[\"id\"]}\n",
    "    for k in CORE_WAY_TAGS: props[k] = tags.get(k)\n",
    "    return {\"properties\": props, \"geometry\": LineString(coords)}\n",
    "\n",
    "\n",
    "def _elements_to_gdf(elements: list[dict]) -> gpd.GeoDataFrame:\n",
    "    feats = []\n",
    "    for el in elements:\n",
    "        f = _way_to_feature(el)\n",
    "        if f: feats.append(f)\n",
    "    if not feats:\n",
    "        return gpd.GeoDataFrame(columns=[\"osmid\",*CORE_WAY_TAGS,\"geometry\"], geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "    df  = pd.DataFrame([f[\"properties\"] for f in feats])\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=[f[\"geometry\"] for f in feats], crs=\"EPSG:4326\")\n",
    "    for k in [\"osmid\",*CORE_WAY_TAGS]:\n",
    "        if k not in gdf.columns: gdf[k] = None\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def build_sat_seg_gdfs(trail_qid: str = \"Q131318799\", prefer_relation: bool = True) -> dict[str, gpd.GeoDataFrame]:\n",
    "    meta = fetch_sat_sections_from_wikidata(trail_qid)\n",
    "    if meta.empty:\n",
    "        print(\"Hittade inga etapper i Wikidata för\", trail_qid)\n",
    "        return {}\n",
    "    out: dict[str, gpd.GeoDataFrame] = {}\n",
    "    for _, row in meta.iterrows():\n",
    "        label  = str(row[\"sectionLabel\"]).strip() or row[\"section_qid\"]\n",
    "        rel_id = row[\"osmr\"] if pd.notna(row[\"osmr\"]) else None\n",
    "        way_id = row[\"osmw\"] if pd.notna(row[\"osmw\"]) else None\n",
    "        elements: list[dict] = []\n",
    "        if prefer_relation and rel_id:\n",
    "            try:\n",
    "                elements = _fetch_ways_for_relation(int(rel_id))\n",
    "            except Exception as e:\n",
    "                print(f\"[{label}] relation {rel_id} failed: {e}\")\n",
    "        if (not elements) and way_id:\n",
    "            try:\n",
    "                elements = _fetch_way(int(way_id))\n",
    "            except Exception as e:\n",
    "                print(f\"[{label}] way {way_id} failed: {e}\")\n",
    "        gdf = _elements_to_gdf(elements)\n",
    "        if \"name\" not in gdf.columns:\n",
    "            gdf[\"name\"] = None\n",
    "        gdf[\"name\"] = gdf[\"name\"].fillna(label)\n",
    "        out[label] = gdf\n",
    "    return out\n",
    "\n",
    "# =================== BBox helpers & tiling ==================================\n",
    "\n",
    "def _bbox_from_gdfs(gdfs: dict[str, gpd.GeoDataFrame]) -> tuple[float,float,float,float]:\n",
    "    boxes = []\n",
    "    for g in gdfs.values():\n",
    "        if g is None or g.empty: continue\n",
    "        minx, miny, maxx, maxy = g.to_crs(epsg=4326).total_bounds\n",
    "        boxes.append((minx, miny, maxx, maxy))\n",
    "    if not boxes:\n",
    "        return (18.0, 59.0, 19.0, 60.0)\n",
    "    minx = min(b[0] for b in boxes); miny = min(b[1] for b in boxes)\n",
    "    maxx = max(b[2] for b in boxes); maxy = max(b[3] for b in boxes)\n",
    "    return (minx, miny, maxx, maxy)\n",
    "\n",
    "\n",
    "def _expand_bbox_meters(bbox4326: tuple[float,float,float,float], meters: int = 1500) -> tuple[float,float,float,float]:\n",
    "    gs = gpd.GeoSeries([shapely.geometry.box(*bbox4326)], crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
    "    minx, miny, maxx, maxy = gs.total_bounds\n",
    "    minx -= meters; miny -= meters; maxx += meters; maxy += meters\n",
    "    bb2 = gpd.GeoSeries([shapely.geometry.box(minx, miny, maxx, maxy)], crs=\"EPSG:3857\").to_crs(epsg=4326)\n",
    "    return tuple(bb2.total_bounds.tolist())  # type: ignore\n",
    "\n",
    "\n",
    "def _tile_bbox(minx, miny, maxx, maxy, nx=TILE_NX, ny=TILE_NY):\n",
    "    dx = (maxx - minx) / max(nx,1)\n",
    "    dy = (maxy - miny) / max(ny,1)\n",
    "    tiles = []\n",
    "    for ix in range(nx):\n",
    "        for iy in range(ny):\n",
    "            x0 = minx + ix*dx; x1 = x0 + dx\n",
    "            y0 = miny + iy*dy; y1 = y0 + dy\n",
    "            tiles.append((x0, y0, x1, y1))\n",
    "    return tiles\n",
    "\n",
    "# =================== Overpass queries for POIs ===============================\n",
    "\n",
    "def _q_tagged_wheelchair(minx, miny, maxx, maxy) -> str:\n",
    "    # only objects that already have wheelchair=*\n",
    "    return f\"\"\"\n",
    "[out:json][timeout:120];\n",
    "(\n",
    "  node[\"wheelchair\"]({miny},{minx},{maxy},{maxx});\n",
    "  way [\"wheelchair\"]({miny},{minx},{maxy},{maxx});\n",
    ");\n",
    "out body tags center qt;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def _q_curated_candidates(minx, miny, maxx, maxy) -> str:\n",
    "    # likely relevant objects even if wheelchair is missing\n",
    "    return f\"\"\"\n",
    "[out:json][timeout:120];\n",
    "(\n",
    "  node[\"amenity\"~\"^({CURATED_AMENITY})$\"]({miny},{minx},{maxy},{maxx});\n",
    "  way [\"amenity\"~\"^({CURATED_AMENITY})$\"]({miny},{minx},{maxy},{maxx});\n",
    "  node[\"tourism\"~\"^({CURATED_TOURISM})$\"]({miny},{minx},{maxy},{maxx});\n",
    "  way [\"tourism\"~\"^({CURATED_TOURISM})$\"]({miny},{minx},{maxy},{maxx});\n",
    ");\n",
    "out body tags center qt;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def fetch_wheelchair_candidates(minx: float, miny: float, maxx: float, maxy: float, tiled: bool = True) -> dict:\n",
    "    \"\"\"Two-stage fetch (tagged first, then curated), optionally tiled.\"\"\"\n",
    "    tiles = _tile_bbox(minx, miny, maxx, maxy) if tiled else [(minx, miny, maxx, maxy)]\n",
    "    elements = []\n",
    "    for (x0, y0, x1, y1) in tiles:\n",
    "        for q in (_q_tagged_wheelchair(x0, y0, x1, y1), _q_curated_candidates(x0, y0, x1, y1)):\n",
    "            part = _overpass(q)\n",
    "            if part and \"elements\" in part:\n",
    "                elements.extend(part[\"elements\"])\n",
    "        time.sleep(0.5)  # be nice to Overpass\n",
    "    return {\"elements\": elements}\n",
    "\n",
    "# =================== Convert POIs to GeoDataFrame ===========================\n",
    "\n",
    "def _pois_to_points_gdf(data: dict) -> gpd.GeoDataFrame:\n",
    "    rows = []\n",
    "    for el in data.get(\"elements\", []):\n",
    "        t = el.get(\"type\")\n",
    "        tags = el.get(\"tags\", {}) or {}\n",
    "        if t == \"node\":\n",
    "            lon = el.get(\"lon\"); lat = el.get(\"lat\")\n",
    "            if lon is None or lat is None: continue\n",
    "            rows.append({\n",
    "                \"osm_type\": \"node\",\n",
    "                \"osmid\": el[\"id\"],\n",
    "                \"lon\": lon, \"lat\": lat,\n",
    "                \"name\": tags.get(\"name\"),\n",
    "                \"wheelchair\": tags.get(\"wheelchair\"),\n",
    "                \"amenity\": tags.get(\"amenity\"),\n",
    "                \"tourism\": tags.get(\"tourism\"),\n",
    "            })\n",
    "        elif t == \"way\":\n",
    "            c = el.get(\"center\")\n",
    "            if not c: continue  # we used 'out center'; skip if missing\n",
    "            rows.append({\n",
    "                \"osm_type\": \"way\",\n",
    "                \"osmid\": el[\"id\"],\n",
    "                \"lon\": c.get(\"lon\"), \"lat\": c.get(\"lat\"),\n",
    "                \"name\": tags.get(\"name\"),\n",
    "                \"wheelchair\": tags.get(\"wheelchair\"),\n",
    "                \"amenity\": tags.get(\"amenity\"),\n",
    "                \"tourism\": tags.get(\"tourism\"),\n",
    "            })\n",
    "    if not rows:\n",
    "        return gpd.GeoDataFrame(columns=[\"osm_type\",\"osmid\",\"name\",\"wheelchair\",\"amenity\",\"tourism\",\"geometry\"], geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "    df = pd.DataFrame(rows).dropna(subset=[\"lon\",\"lat\"])  # safety\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]), crs=\"EPSG:4326\")\n",
    "    return gdf\n",
    "\n",
    "# =================== Distance & bands =======================================\n",
    "\n",
    "def _nearest_distance_to_lines(point_m: shapely.geometry.base.BaseGeometry, lines_union_m: shapely.geometry.base.BaseGeometry) -> float:\n",
    "    if lines_union_m.is_empty: return float(\"inf\")\n",
    "    return float(point_m.distance(lines_union_m))\n",
    "\n",
    "\n",
    "def _band_label(d_m: float) -> str:\n",
    "    for thr in DIST_BANDS:\n",
    "        if d_m <= thr: return f\"≤{thr}m\"\n",
    "    return f\">{DIST_BANDS[-1]}m\"\n",
    "\n",
    "# =================== Popup builder ==========================================\n",
    "\n",
    "\n",
    "\n",
    "def _popup_html(row: pd.Series) -> str:\n",
    "    osm_type = str(row.get(\"osm_type\",\"way\"))\n",
    "    osmid    = int(row.get(\"osmid\")) if pd.notna(row.get(\"osmid\")) else None\n",
    "    title    = row.get(\"name\") or f\"{osm_type} {osmid}\"\n",
    "    status   = (str(row.get(\"wheelchair\")) or \"\").strip().lower()\n",
    "    status_h = status if status in {\"yes\",\"no\",\"limited\",\"designated\"} else (\"unknown\" if status else \"missing\")\n",
    "    color    = COLOR_YES if status == \"yes\" else (COLOR_NO if status == \"no\" else COLOR_MIS)\n",
    "\n",
    "    wl = _wheelmap_link(osm_type, osmid) if osmid else \"#\"\n",
    "    ov = _osm_view_link(osm_type, osmid) if osmid else \"#\"\n",
    "    oe = _osm_edit_link(osm_type, osmid) if osmid else \"#\"\n",
    "\n",
    "    meta = []\n",
    "    for k in (\"amenity\",\"tourism\"):\n",
    "        if pd.notna(row.get(k)):\n",
    "            meta.append(f\"{k}={_html.escape(str(row[k]))}\")\n",
    "\n",
    "    dist_info = f\"Dist to trail: {row.get('dist_m', float('nan')):.0f} m ({row.get('dist_band','')})\"\n",
    "\n",
    "    # Build the optional metadata chip separately (prevents nested f-string issues)\n",
    "    meta_chip = \"\"\n",
    "    if meta:\n",
    "        joined = \" • \".join(meta)\n",
    "        meta_chip = (\n",
    "            \"<span style=\\\"display:inline-block;padding:2px 8px;border-radius:999px;\"\n",
    "            \"background:#6e7781;color:white;\\\">\" + joined + \"</span>\"\n",
    "        )\n",
    "\n",
    "    html = f\"\"\"\n",
    "<div style=\"max-width:520px\">\n",
    "  <div style=\"border-radius:12px;padding:10px;background:#ffffff;box-shadow:0 1px 6px rgba(0,0,0,.08);font-family:system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Helvetica,Arial,sans-serif;font-size:14px;color:#24292f;\">\n",
    "    <div style=\"font-weight:700;font-size:18px;margin:0 0 6px 0;\">{_html.escape(str(title))}</div>\n",
    "    <div style=\"margin:6px 0;display:flex;gap:8px;align-items:center;\">\n",
    "      <a href=\"{_html.escape(wl)}\" target=\"_blank\" style=\"display:inline-block;padding:4px 8px;border-radius:999px;background:#1f6feb;color:white;text-decoration:none;\">Wheelmap</a>\n",
    "      <a href=\"{_html.escape(ov)}\" target=\"_blank\" style=\"display:inline-block;padding:4px 8px;border-radius:999px;background:#374151;color:white;text-decoration:none;\">OSM</a>\n",
    "      <a href=\"{_html.escape(oe)}\" target=\"_blank\" style=\"display:inline-block;padding:4px 8px;border-radius:999px;background:#111827;color:white;text-decoration:none;\">iD editor</a>\n",
    "    </div>\n",
    "    <div style=\"margin:6px 0;display:flex;flex-wrap:wrap;gap:6px;align-items:center;\">\n",
    "      <span style=\"display:inline-block;padding:2px 8px;border-radius:999px;background:{color};color:white;\">wheelchair: {status_h}</span>\n",
    "      <span style=\"display:inline-block;padding:2px 8px;border-radius:999px;background:#6e7781;color:white;\">{_html.escape(dist_info)}</span>\n",
    "      {meta_chip}\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "    return html\n",
    "\n",
    "# =================== Map & stats ============================================\n",
    "\n",
    "def make_wheelchair_map(etapp_gdfs: dict[str, gpd.GeoDataFrame],\n",
    "                        OUTPUT_DIR: str = OUTPUT_DIR,\n",
    "                        PROJECT_NAME: str = PROJECT_NAME,\n",
    "                        STAMP: str = STAMP,\n",
    "                        tiled_fetch: bool = True) -> tuple[str, pd.DataFrame]:\n",
    "    if not etapp_gdfs:\n",
    "        raise RuntimeError(\"No SAT data — build etapp_gdfs first\")\n",
    "\n",
    "    # Combine SAT lines\n",
    "    lines = []\n",
    "    for section, g in etapp_gdfs.items():\n",
    "        if g is None or g.empty: continue\n",
    "        gf = g[[\"geometry\"]].copy(); gf[\"section\"] = section\n",
    "        lines.append(gf)\n",
    "    sat = gpd.GeoDataFrame(pd.concat(lines, ignore_index=True), geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "    # Bbox and fetch POIs\n",
    "    minx, miny, maxx, maxy = _bbox_from_gdfs(etapp_gdfs)\n",
    "    bbox_exp = _expand_bbox_meters((minx, miny, maxx, maxy), meters=1500)\n",
    "    data = fetch_wheelchair_candidates(*bbox_exp, tiled=tiled_fetch)\n",
    "    pois = _pois_to_points_gdf(data)\n",
    "\n",
    "    # Prepare map\n",
    "    minx, miny, maxx, maxy = sat.total_bounds\n",
    "    m = folium.Map(location=[(miny+maxy)/2, (minx+maxx)/2], zoom_start=10, control_scale=True, tiles=\"OpenStreetMap\")\n",
    "    GeoJson(sat[[\"geometry\"]], name=\"SAT\", style_function=lambda _f: {\"weight\": 4, \"color\": TRAIL_COLOR}).add_to(m)\n",
    "\n",
    "    if pois.empty:\n",
    "        folium.LayerControl(collapsed=False).add_to(m)\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "        html_path = os.path.join(OUTPUT_DIR, f\"{PROJECT_NAME}_wheelchair_{STAMP}.html\")\n",
    "        _add_about_box(m, issue_number=ISSUE_NUMBER, map_name=\"Wheelchair near SAT\")\n",
    "        _save_with_latest(m, html_path)\n",
    "        return html_path, pd.DataFrame()\n",
    "\n",
    "    # Distances\n",
    "    sat_m  = sat.to_crs(epsg=3857)\n",
    "    pois_m = pois.to_crs(epsg=3857)\n",
    "    lines_union = sat_m.unary_union\n",
    "    pois_m[\"dist_m\"] = pois_m.geometry.apply(lambda g: _nearest_distance_to_lines(g, lines_union))\n",
    "    pois_m[\"dist_band\"] = pois_m[\"dist_m\"].apply(_band_label)\n",
    "\n",
    "    # Keep ≤200 m\n",
    "    pois_m = pois_m.loc[pois_m[\"dist_m\"] <= DIST_BANDS[-1]].copy()\n",
    "\n",
    "    # Back to WGS84\n",
    "    pois_4326 = pois_m.to_crs(epsg=4326)\n",
    "\n",
    "    # Color by status\n",
    "    def _status_color(s):\n",
    "        s = (str(s) if s is not None else \"\").strip().lower()\n",
    "        if s == \"yes\": return COLOR_YES\n",
    "        if s == \"no\":  return COLOR_NO\n",
    "        return COLOR_MIS\n",
    "\n",
    "    # Layers per distance band\n",
    "    for bl in [f\"≤{DIST_BANDS[0]}m\", f\"≤{DIST_BANDS[1]}m\", f\"≤{DIST_BANDS[2]}m\"]:\n",
    "        sel = pois_4326.loc[pois_4326[\"dist_band\"] == bl]\n",
    "        if sel.empty: continue\n",
    "        fg = folium.FeatureGroup(name=f\"POIs {bl}\")\n",
    "        for _, r in sel.iterrows():\n",
    "            color = _status_color(r.get(\"wheelchair\"))\n",
    "            folium.CircleMarker(\n",
    "                location=[r.geometry.y, r.geometry.x], radius=6, weight=2, color=color, fill=True, fill_opacity=0.9,\n",
    "                popup=folium.Popup(_popup_html(r), max_width=520)\n",
    "            ).add_to(fg)\n",
    "        fg.add_to(m)\n",
    "\n",
    "    # Legend\n",
    "    legend_html = f\"\"\"\n",
    "    <div style=\\\"position: fixed; bottom: 18px; left: 18px; z-index: 9999; background: rgba(255,255,255,0.92);\\\n",
    "                padding: 10px 12px; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.15); font-size: 13px;\\\">\n",
    "      <div style=\\\"font-weight:600; margin-bottom:6px;\\\">Wheelchair status</div>\n",
    "      <div><span style=\\\"display:inline-block;width:14px;height:3px;background:{COLOR_YES};margin-right:6px;\\\"></span>yes (grön)</div>\n",
    "      <div><span style=\\\"display:inline-block;width:14px;height:3px;background:{COLOR_NO};margin-right:6px;\\\"></span>no (röd)</div>\n",
    "      <div><span style=\\\"display:inline-block;width:14px;height:3px;background:{COLOR_MIS};margin-right:6px;\\\"></span>saknas/okänd (orange)</div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    _add_about_box(m, issue_number=ISSUE_NUMBER, map_name=\"Wheelchair near SAT (≤200 m)\")\n",
    "\n",
    "    # Save\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    html_path = os.path.join(OUTPUT_DIR, f\"{PROJECT_NAME}_wheelchair_{STAMP}.html\")\n",
    "    _save_with_latest(m, html_path)\n",
    "\n",
    "    # Stats (status_bucket × distance band)\n",
    "    df_stats = (pois_4326\n",
    "        .assign(status=lambda d: d[\"wheelchair\"].fillna(\"\").str.lower().replace({\"nan\":\"\"}))\n",
    "        .assign(status_bucket=lambda d: d[\"status\"].where(d[\"status\"].isin([\"yes\",\"no\"]), other=\"missing\"))\n",
    "        .groupby([\"status_bucket\",\"dist_band\"]).size().reset_index(name=\"count\")\n",
    "    )\n",
    "\n",
    "    # Per-section stats\n",
    "    pois_sections = gpd.sjoin_nearest(\n",
    "        pois_4326,\n",
    "        sat[[\"section\",\"geometry\"]].to_crs(epsg=4326),\n",
    "        how=\"left\",\n",
    "        distance_col=\"nearest_dist\"\n",
    "    )\n",
    "    #pois_sections = gpd.sjoin(pois_4326, sat[[\"section\",\"geometry\"]].to_crs(epsg=4326), how=\"left\", predicate=\"nearest\")\n",
    "    df_stats_section = (pois_sections\n",
    "    .assign(status=lambda d: d[\"wheelchair\"].fillna(\"\").str.lower().replace({\"nan\":\"\"}))\n",
    "    .assign(status_bucket=lambda d: d[\"status\"].where(d[\"status\"].isin([\"yes\",\"no\"]), other=\"missing\"))\n",
    "    .groupby([\"section\",\"status_bucket\",\"dist_band\"]).size().reset_index(name=\"count\")\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Also write CSV with raw POIs\n",
    "    raw_csv = os.path.join(OUTPUT_DIR, f\"{PROJECT_NAME}_wheelchair_raw_{STAMP}.csv\")\n",
    "    pois_4326.drop(columns=[\"geometry\"]).to_csv(raw_csv, index=False)\n",
    "    \n",
    "    \n",
    "    stats_csv = os.path.join(OUTPUT_DIR, f\"{PROJECT_NAME}_wheelchair_stats_{STAMP}.csv\")\n",
    "    df_stats.to_csv(stats_csv, index=False)\n",
    "    \n",
    "    \n",
    "    stats_section_csv = os.path.join(OUTPUT_DIR, f\"{PROJECT_NAME}_wheelchair_stats_sections_{STAMP}.csv\")\n",
    "    df_stats_section.to_csv(stats_section_csv, index=False)\n",
    "    \n",
    "    \n",
    "    print(\"Saved map:\", html_path)\n",
    "    print(\"Saved stats:\", stats_csv)\n",
    "    print(\"Saved per-section stats:\", stats_section_csv)\n",
    "    print(\"Saved raw POIs:\", raw_csv)\n",
    "    # ==== Per-section stats (nearest section) ===================================\n",
    "    try:\n",
    "        sat_sections = sat[[\"section\", \"geometry\"]].copy()\n",
    "        pois_with_sec = gpd.sjoin_nearest(pois_4326, sat_sections, how=\"left\")\n",
    "        df_stats_section = (\n",
    "            pois_with_sec.assign(\n",
    "                status=lambda d: d[\"wheelchair\"].fillna(\"\").str.lower().replace({\"nan\": \"\"}),\n",
    "                status_bucket=lambda d: d[\"status\"].where(d[\"status\"].isin([\"yes\",\"no\"]), other=\"missing\"),\n",
    "            )\n",
    "            .groupby([\"section\",\"status_bucket\",\"dist_band\"]).size()\n",
    "            .reset_index(name=\"count\")\n",
    "        )\n",
    "        stats_section_csv = os.path.join(OUTPUT_DIR, f\"{PROJECT_NAME}_wheelchair_stats_sections_{STAMP}.csv\")\n",
    "        df_stats_section.to_csv(stats_section_csv, index=False)\n",
    "        print(\"Saved per-section stats:\", stats_section_csv)\n",
    "    except Exception as e:\n",
    "        print(\"Per-section stats skipped:\", e)\n",
    "\n",
    "    return html_path, df_stats_section\n",
    "# =================== About box & save helpers ===============================\n",
    "\n",
    "from string import Template\n",
    "\n",
    "def _add_about_box(\n",
    "    m,\n",
    "    issue_number: int,\n",
    "    map_name: str,\n",
    "    created_date: str | None = None,\n",
    "    repo: str = \"salgo60/Stockholm_Archipelago_Trail\",\n",
    "    collapsed: bool = False,\n",
    "):\n",
    "    if created_date is None:\n",
    "        created_date = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "    map_dom_id = m.get_name()\n",
    "    box_id     = f\"sat-about-{map_dom_id}\"\n",
    "    header_id  = f\"{box_id}-hdr\"\n",
    "    issue_url  = f\"https://github.com/{repo}/issues/{issue_number}\"\n",
    "\n",
    "    links = [\n",
    "        (\"Project repo issues\", \"https://github.com/salgo60/Stockholm_Archipelago_Trail/issues?q=is%3Aissue\"),\n",
    "        (\"Wheelmap\", \"https://wheelmap.org/\"),\n",
    "        (\"Trail on OSM (rel 19012437)\", \"https://www.openstreetmap.org/relation/19012437\"),\n",
    "    ]\n",
    "    links_html = \"\".join(\n",
    "        f'<div><a href=\"{_html.escape(u)}\" target=\"_blank\" style=\"text-decoration:none;\">🔗 {_html.escape(t)}</a></div>'\n",
    "        for t, u in links\n",
    "    )\n",
    "    collapsed_class = \"sat-about-collapsed\" if collapsed else \"\"\n",
    "\n",
    "    tpl = Template(r\"\"\"\n",
    "<style>\n",
    "  .sat-about { position: fixed; z-index: 10000; background: rgba(255,255,255,0.97);\n",
    "    border: 2px solid #666; border-radius: 10px; box-shadow: 0 2px 6px rgba(0,0,0,0.25);\n",
    "    font: 12px/1.35 -apple-system, system-ui, Segoe UI, Roboto, Helvetica, Arial, sans-serif;\n",
    "    pointer-events: auto; min-width: 240px; max-width: 320px; }\n",
    "  .sat-about-header { cursor: pointer; padding: 8px 10px; font-weight: 700;\n",
    "    display: flex; align-items: center; gap: 6px; user-select: none;\n",
    "    background: rgba(248,248,248,.9); border-bottom: 1px solid #e5e7eb; }\n",
    "  .sat-about-body { padding: 8px 10px 10px 10px; }\n",
    "  .sat-about-collapsed .sat-about-body { display: none; }\n",
    "  .sat-chevron { margin-left: auto; transition: transform .15s ease-in-out; }\n",
    "  .sat-about-collapsed .sat-chevron { transform: rotate(-90deg); }\n",
    "  .sat-links { margin-top: 6px; padding-top: 6px; border-top: 1px solid #e5e7eb; }\n",
    "</style>\n",
    "<div id=\"$box_id\" class=\"sat-about $collapsed_class\">\n",
    "  <div id=\"$header_id\" class=\"sat-about-header\" title=\"Click to collapse/expand\">\n",
    "    <span>ℹ️ About</span>\n",
    "    <span class=\"sat-chevron\">▸</span>\n",
    "  </div>\n",
    "  <div class=\"sat-about-body\">\n",
    "    <div style=\"font-weight:700;margin-bottom:4px;\">SAT Wheelchair Map</div>\n",
    "    <div>Issue: <a href=\"$issue_url\" target=\"_blank\">#$issue_number</a>&nbsp;&nbsp; Map: $map_name</div>\n",
    "    <div>Created: $created_date</div>\n",
    "    <div class=\"sat-links\">$links_html</div>\n",
    "  </div>\n",
    "</div>\n",
    "<script>\n",
    "(function(){\n",
    "  var mapId = \"$map_dom_id\";\n",
    "  var boxId = \"$box_id\";\n",
    "  var hdrId = \"$header_id\";\n",
    "  var storageKey = \"satAboutCollapsed_\" + \"$map_dom_id\" + \"_#$issue_number\";\n",
    "  function setCollapsed(box, collapsed) {\n",
    "    var body = box.querySelector(\".sat-about-body\");\n",
    "    if (collapsed) { box.classList.add(\"sat-about-collapsed\"); if (body) body.style.display = \"none\"; }\n",
    "    else { box.classList.remove(\"sat-about-collapsed\"); if (body) body.style.display = \"block\"; }\n",
    "    try { localStorage.setItem(storageKey, collapsed ? \"1\" : \"0\"); } catch(e) {}\n",
    "  }\n",
    "  function placeBox(mapEl, box) {\n",
    "    var zoom = mapEl.querySelector(\".leaflet-control-zoom\");\n",
    "    var mr   = mapEl.getBoundingClientRect();\n",
    "    var top = 10, left = 10;\n",
    "    if (zoom) {\n",
    "      var zr = zoom.getBoundingClientRect();\n",
    "      top  = (zr.bottom - mr.top) + 8;\n",
    "      left = (zr.left   - mr.left) + zr.width + 8;\n",
    "    }\n",
    "    box.style.top  = top  + \"px\";\n",
    "    box.style.left = left + \"px\";\n",
    "  }\n",
    "  function init(tries) {\n",
    "    tries = tries || 0;\n",
    "    var mapEl = document.getElementById(mapId);\n",
    "    var box   = document.getElementById(boxId);\n",
    "    var hdr   = document.getElementById(hdrId);\n",
    "    if (!mapEl || !box || !hdr) { if (tries < 60) return setTimeout(function(){ init(tries+1); }, 120); return; }\n",
    "    try {\n",
    "      var stored = localStorage.getItem(storageKey);\n",
    "      if (stored === \"1\") setCollapsed(box, true);\n",
    "      if (stored === \"0\") setCollapsed(box, false);\n",
    "    } catch(e) {}\n",
    "    hdr.addEventListener(\"click\", function(e){ e.stopPropagation(); setCollapsed(box, !box.classList.contains(\"sat-about-collapsed\")); });\n",
    "    function doPlace(){ placeBox(mapEl, box); }\n",
    "    var placeTries = 0, iv = setInterval(function(){ doPlace(); if (++placeTries > 25) clearInterval(iv); }, 120);\n",
    "    window.addEventListener(\"resize\", doPlace);\n",
    "    requestAnimationFrame(doPlace);\n",
    "  }\n",
    "  if (document.readyState === \"loading\") { document.addEventListener(\"DOMContentLoaded\", function(){ init(0); }); }\n",
    "  else { init(0); }\n",
    "})();\n",
    "</script>\n",
    "\"\"\")\n",
    "\n",
    "    html_snippet = tpl.substitute(\n",
    "        box_id=box_id,\n",
    "        header_id=header_id,\n",
    "        collapsed_class=collapsed_class,\n",
    "        issue_url=issue_url,\n",
    "        issue_number=str(issue_number),\n",
    "        map_name=_html.escape(map_name),\n",
    "        created_date=_html.escape(created_date),\n",
    "        links_html=links_html,\n",
    "        map_dom_id=map_dom_id,\n",
    "    )\n",
    "    m.get_root().html.add_child(folium.Element(html_snippet))\n",
    "\n",
    "\n",
    "\n",
    "def _to_latest_name(filename: str | Path) -> Path:\n",
    "    p = Path(filename)\n",
    "    stem = p.stem\n",
    "    new_stem = re.sub(r\"_(?:20\\d{6})(?:_\\d{4})?$\", \"\", stem)\n",
    "    return p.with_name(new_stem + \"_latest.html\")\n",
    "\n",
    "\n",
    "def _save_with_latest(map_object, filename: str | Path):\n",
    "    map_object.save(str(filename))\n",
    "    latest_path = _to_latest_name(filename)\n",
    "    Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "    from shutil import copyfile\n",
    "    copyfile(filename, latest_path)\n",
    "    print(f\"Saved: {filename}\\nUpdated: {latest_path}\")\n",
    "\n",
    "# =================== Run (single cell in notebook) ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Build SAT sections\n",
    "    etapp_gdfs = build_sat_seg_gdfs(trail_qid=\"Q131318799\", prefer_relation=True)\n",
    "\n",
    "    # 2) Build wheelchair map & stats\n",
    "    html_path, stats_df = make_wheelchair_map(\n",
    "        etapp_gdfs,\n",
    "        OUTPUT_DIR=OUTPUT_DIR,\n",
    "        PROJECT_NAME=PROJECT_NAME,\n",
    "        STAMP=STAMP,\n",
    "        tiled_fetch=True,\n",
    "    )\n",
    "\n",
    "    # 3) Quick console preview of stats\n",
    "    if not stats_df.empty:\n",
    "        try:\n",
    "            print(stats_df.sort_values([\"status_bucket\",\"dist_band\"]).to_string(index=False))\n",
    "        except Exception:\n",
    "            print(stats_df.head())\n",
    "\n",
    "    print(\"✅ Wheelchair analysis ready →\", html_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72452503-cf05-4390-9ec7-2dff77f189bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2025-09-16 04:11:01\n",
      "Total time elapsed: 45.58 seconds\n"
     ]
    }
   ],
   "source": [
    " # End timer and calculate duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time# Bygg audit-lager för den här etappen\n",
    "\n",
    "# Print current date and total time\n",
    "print(\"Date:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03087948-b78c-47ae-8412-eb2b80b0f3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
