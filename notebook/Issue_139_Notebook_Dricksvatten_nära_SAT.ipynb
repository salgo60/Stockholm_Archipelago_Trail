{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "235f3af5-7891-4fd3-a094-5e386844849c",
   "metadata": {},
   "source": [
    "# Issue 139 Notebook Dricksvatten n√§ra SAT \n",
    "\n",
    "* denna [Notebook](https://github.com/salgo60/Stockholm_Archipelago_Trail/blob/main/notebook/Issue_139_Notebook_Dricksvatten_n%C3%A4ra_SAT.ipynb)\n",
    "* [Issue 139](https://github.com/salgo60/Stockholm_Archipelago_Trail/issues/139) \n",
    "\n",
    "J√§mf√∂r \n",
    "* [Issue 132 Toaletter](https://github.com/salgo60/Stockholm_Archipelago_Trail/issues/139) \n",
    "\n",
    "\n",
    "Output \n",
    "* [kartor/Issue_139_dricksvatten_nara_stockholm_archipelago_trail_2025_08_17_23_13.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_139_dricksvatten_nara_stockholm_archipelago_trail_2025_08_17_23_13.html)\n",
    "* [kartor/Issue_139_dricksvatten_nara_stockholm_archipelago_trail_2025_08_18_19_39.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_139_dricksvatten_nara_stockholm_archipelago_trail_2025_08_18_19_39.html)\n",
    "* [kartor/Issue_139_dricksvatten_nara_stockholm_archipelago_trail_2025_08_18_19_49.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/Issue_139_dricksvatten_nara_stockholm_archipelago_trail_2025_08_18_19_49.html)\n",
    "* [kartor/sat_dricksvatten_table_2025_08_19_13_53.html](https://raw.githack.com/salgo60/Stockholm_Archipelago_Trail/main/kartor/sat_dricksvatten_table_2025_08_19_13_53.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90338f-7d9a-4e0b-a4ca-baffe6ef8db8",
   "metadata": {},
   "source": [
    "version 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d2cff1-5935-4e29-af49-09d92a30c7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2025-08-19 14:58:00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = now.timestamp()\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Start:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc8f161-04b3-4d54-9270-50c354354b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç H√§mtar SAT-etapper fr√•n Wikidata...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SPARQLWrapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 131\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# 1) H√§mta SAT-etapper via Wikidata\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîç H√§mtar SAT-etapper fr√•n Wikidata...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 131\u001b[0m sparql \u001b[38;5;241m=\u001b[39m \u001b[43mSPARQLWrapper\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://query.wikidata.org/sparql\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    132\u001b[0m sparql\u001b[38;5;241m.\u001b[39msetQuery(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124mSELECT ?item ?itemLabel ?islandLabel ?osmid WHERE \u001b[39m\u001b[38;5;124m{\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124m  ?item wdt:P361 wd:Q131318799;\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124m}\u001b[39m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m    141\u001b[0m sparql\u001b[38;5;241m.\u001b[39msetReturnFormat(JSON)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SPARQLWrapper' is not defined"
     ]
    }
   ],
   "source": [
    "import os, time, json, hashlib, requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# Mirrors to try (keep the .de one first so /status parsing stays compatible)\n",
    "OVERPASS_ENDPOINTS = [\n",
    "    \"https://overpass-api.de\",\n",
    "    \"https://overpass.kumi.systems\",\n",
    "    \"https://overpass.openstreetmap.fr\",\n",
    "]\n",
    "\n",
    "# Local cache to avoid re-hitting Overpass. Change path if you want.\n",
    "CACHE_DIR = \"./.overpass_cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    # REAL contact helps. Use something you read so admins can reach you.\n",
    "    \"User-Agent\": \"SAT-drinking-water-mapper/1.0 (contact: salgo60@msn.com)\"\n",
    "})\n",
    "retry = Retry(\n",
    "    total=4,\n",
    "    backoff_factor=2.0,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    allowed_methods=[\"GET\", \"POST\"],\n",
    "    raise_on_status=False,\n",
    ")\n",
    "session.mount(\"https://\", HTTPAdapter(max_retries=retry))\n",
    "session.mount(\"http://\",  HTTPAdapter(max_retries=retry))\n",
    "\n",
    "def _cache_key(query: str) -> str:\n",
    "    return hashlib.sha256(query.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def _cache_read(query: str):\n",
    "    path = os.path.join(CACHE_DIR, _cache_key(query) + \".json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    return None\n",
    "\n",
    "def _cache_write(query: str, data: dict):\n",
    "    path = os.path.join(CACHE_DIR, _cache_key(query) + \".json\")\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "def _wait_for_slot(base_url: str, max_wait_s: int = 600):\n",
    "    \"\"\"Poll /api/status until a slot is available (Overpass queue etiquette).\"\"\"\n",
    "    status_url = f\"{base_url}/api/status\"\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            r = session.get(status_url, timeout=20)\n",
    "            txt = r.text\n",
    "        except Exception:\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "\n",
    "        # Common messages:\n",
    "        # - \"Slot available after X seconds.\"\n",
    "        # - \"Currently running queries (N/slots)...\"\n",
    "        # - \"You are already using a slot.\"\n",
    "        if \"You are already using a slot\" in txt or \"available now\" in txt:\n",
    "            return\n",
    "        # Extract seconds to wait if present\n",
    "        wait_s = None\n",
    "        for line in txt.splitlines():\n",
    "            if \"Slot available after\" in line and \"seconds\" in line:\n",
    "                try:\n",
    "                    wait_s = int(line.split(\"after\")[1].split(\"seconds\")[0].strip())\n",
    "                except Exception:\n",
    "                    pass\n",
    "                break\n",
    "        if wait_s is None:\n",
    "            # No explicit wait, be gentle\n",
    "            wait_s = 10\n",
    "\n",
    "        time.sleep(min(wait_s, 30))\n",
    "        if time.time() - start > max_wait_s:\n",
    "            # Stop waiting after max_wait_s; we'll try another mirror\n",
    "            raise TimeoutError(\"Waited too long for an Overpass slot\")\n",
    "\n",
    "def overpass_call(query: str, sleep_between=1.0, timeout=180, use_cache=True):\n",
    "    \"\"\"\n",
    "    Queue-aware Overpass caller with mirrors, waiting on /api/status,\n",
    "    caching, and polite sleeps. Returns parsed JSON.\n",
    "    \"\"\"\n",
    "    if use_cache:\n",
    "        cached = _cache_read(query)\n",
    "        if cached is not None:\n",
    "            return cached\n",
    "\n",
    "    last_err = None\n",
    "    for base in OVERPASS_ENDPOINTS:\n",
    "        interpreter = f\"{base}/api/interpreter\"\n",
    "\n",
    "        # 1) Wait for a free slot on this mirror\n",
    "        try:\n",
    "            _wait_for_slot(base, max_wait_s=600)\n",
    "        except Exception as e:\n",
    "            last_err = f\"status-wait: {e}\"\n",
    "            # try next mirror\n",
    "            continue\n",
    "\n",
    "        # 2) Post query\n",
    "        try:\n",
    "            resp = session.post(interpreter, data={\"data\": query}, timeout=timeout)\n",
    "            ctype = (resp.headers.get(\"Content-Type\") or \"\").lower()\n",
    "            if resp.status_code == 403 or \"text/html\" in ctype:\n",
    "                # Mirror is blocking / overloaded; try next\n",
    "                last_err = f\"{resp.status_code} {ctype}\"\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            if sleep_between:\n",
    "                time.sleep(sleep_between)\n",
    "            if use_cache:\n",
    "                _cache_write(query, data)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last_err = str(e)\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "\n",
    "    raise RuntimeError(f\"Overpass failed on all mirrors. Last error: {last_err}\")\n",
    "\n",
    "# =========================\n",
    "# 1) H√§mta SAT-etapper via Wikidata\n",
    "# =========================\n",
    "print(\"üîç H√§mtar SAT-etapper fr√•n Wikidata...\")\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "SELECT ?item ?itemLabel ?islandLabel ?osmid WHERE {\n",
    "  ?item wdt:P361 wd:Q131318799;\n",
    "        wdt:P31 wd:Q2143825;\n",
    "        wdt:P402 ?osmid.\n",
    "  OPTIONAL { ?item wdt:P706 ?island. }\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"sv,en\". }\n",
    "}\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "etapper = []\n",
    "for r in results[\"results\"][\"bindings\"]:\n",
    "    etapper.append({\n",
    "        \"id\": r[\"osmid\"][\"value\"],\n",
    "        \"label\": r.get(\"itemLabel\", {}).get(\"value\", \"\"),\n",
    "        \"island\": r.get(\"islandLabel\", {}).get(\"value\", \"\")\n",
    "    })\n",
    "osm_ids = [e['id'] for e in etapper]\n",
    "print(f\"‚úÖ Hittade {len(osm_ids)} etapper med OSM-relationer\")\n",
    "\n",
    "# =========================\n",
    "# 2) H√§mta geometrier via Overpass (BATCHEs)\n",
    "# =========================\n",
    "print(\"üì° H√§mtar geometrier fr√•n Overpass (batched)...\")\n",
    "\n",
    "def fetch_relations_geoms(osm_ids, chunk_size=80):\n",
    "    geom_per_rel = {}\n",
    "    all_lines = []\n",
    "    for i in range(0, len(osm_ids), chunk_size):\n",
    "        chunk = osm_ids[i:i+chunk_size]\n",
    "        rels = \";\\n\".join(f\"relation({rid})\" for rid in chunk)\n",
    "        q = f\"\"\"\n",
    "        [out:json][timeout:180];\n",
    "        (\n",
    "        {rels}\n",
    "        );\n",
    "        (._;>>;);\n",
    "        out geom;\n",
    "        \"\"\"\n",
    "        data = overpass_call(q, sleep_between=1.0, timeout=180)\n",
    "\n",
    "        # Build map of relation -> set(way ids)\n",
    "        rel_members = {}\n",
    "        way_by_id = {}\n",
    "\n",
    "        for el in data.get(\"elements\", []):\n",
    "            t = el.get(\"type\")\n",
    "            if t == \"relation\":\n",
    "                rid = str(el[\"id\"])\n",
    "                way_ids = {m[\"ref\"] for m in el.get(\"members\", []) if m.get(\"type\") == \"way\"}\n",
    "                rel_members[rid] = way_ids\n",
    "            elif t == \"way\" and \"geometry\" in el:\n",
    "                way_by_id[el[\"id\"]] = el\n",
    "\n",
    "        # Assemble lines per relation using members\n",
    "        for rid, way_ids in rel_members.items():\n",
    "            rel_geoms = []\n",
    "            for wid in way_ids:\n",
    "                w = way_by_id.get(wid)\n",
    "                if not w:\n",
    "                    continue\n",
    "                coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in w[\"geometry\"]]\n",
    "                if len(coords) >= 2:\n",
    "                    line = LineString(coords)\n",
    "                    rel_geoms.append(line)\n",
    "                    all_lines.append(line)\n",
    "            if rel_geoms:\n",
    "                geom_per_rel[rid] = rel_geoms\n",
    "\n",
    "    return geom_per_rel, all_lines\n",
    "\n",
    "geom_per_rel, all_lines = fetch_relations_geoms(osm_ids, chunk_size=80)\n",
    "\n",
    "if not all_lines:\n",
    "    raise ValueError(\"Inga geometrier hittades fr√•n OSM-relationer kopplade via Wikidata (batched).\")\n",
    "\n",
    "# Bygg MultiLineString/LineString per etapp\n",
    "meta_rows, geom_rows = [], []\n",
    "for meta in etapper:\n",
    "    geoms = geom_per_rel.get(meta[\"id\"])\n",
    "    if not geoms:\n",
    "        print(f\"‚ö†Ô∏è Saknar geometri f√∂r {meta['label']} (rel {meta['id']}) ‚Äì hoppar √∂ver.\")\n",
    "        continue\n",
    "    meta_rows.append(meta)\n",
    "    geom_rows.append(MultiLineString(geoms) if len(geoms) > 1 else geoms[0])\n",
    "\n",
    "gdf_trail = gpd.GeoDataFrame(geometry=all_lines, crs=\"EPSG:4326\")\n",
    "meta_gdf = gpd.GeoDataFrame(meta_rows, geometry=geom_rows, crs=\"EPSG:4326\")\n",
    "print(f\"üß≠ Etapper med geometri: {len(meta_gdf)}\")\n",
    "\n",
    "# =========================\n",
    "# 3) Buffert 200 m (Shapely 2: union_all)\n",
    "# =========================\n",
    "print(\"üßÆ Skapar 200 m-buffert...\")\n",
    "buffer_utm = gdf_trail.to_crs(3006).buffer(200)   # 200 m i SWEREF 99 TM\n",
    "buffer_wgs84 = buffer_utm.to_crs(4326)            # tillbaka till WGS84\n",
    "buffer_union = buffer_wgs84.union_all()           # EN (multi)polygon\n",
    "\n",
    "# =========================\n",
    "# 4) H√§mta dricksvatten (nwr + out center) via robust Overpass\n",
    "# =========================\n",
    "bbox = gdf_trail.total_bounds  # [minx, miny, maxx, maxy]\n",
    "q_water = f\"\"\"\n",
    "[out:json][timeout:120];\n",
    "nwr[\"amenity\"=\"drinking_water\"]({bbox[1]},{bbox[0]},{bbox[3]},{bbox[2]});\n",
    "out center;\n",
    "\"\"\"\n",
    "print(\"üíß H√§mtar dricksvatten (nwr) fr√•n Overpass...\")\n",
    "water_data = overpass_call(q_water, sleep_between=0.7, timeout=180)\n",
    "elements = water_data.get(\"elements\", [])\n",
    "\n",
    "waters = []\n",
    "for el in elements:\n",
    "    tags = el.get(\"tags\", {}) or {}\n",
    "    typ = el.get(\"type\")\n",
    "    if typ == \"node\":\n",
    "        lon, lat = el[\"lon\"], el[\"lat\"]\n",
    "    else:\n",
    "        center = el.get(\"center\")\n",
    "        if not center:\n",
    "            continue\n",
    "        lon, lat = center[\"lon\"], center[\"lat\"]\n",
    "    waters.append({\n",
    "        \"geometry\": Point(lon, lat),\n",
    "        \"tags\": tags,\n",
    "        \"id\": el[\"id\"],\n",
    "        \"osm_type\": typ,\n",
    "        \"water_sites\": 1,  # 1 site per OSM-objekt\n",
    "    })\n",
    "\n",
    "gdf_water = gpd.GeoDataFrame(waters, crs=\"EPSG:4326\")\n",
    "print(f\"‚úÖ Hittade {len(gdf_water)} dricksvatten-objekt inom bbox\")\n",
    "\n",
    "# =========================\n",
    "# 5) Filtrera till de som ligger inom/vid 200 m-bufferten\n",
    "# =========================\n",
    "in_range = gdf_water[gdf_water.geometry.covered_by(buffer_union)]\n",
    "print(f\"‚úÖ {len(in_range)} dricksvatten-objekt inom/vid 200 m\")\n",
    "\n",
    "# =========================\n",
    "# 6) N√§rmaste etapp per dricksvatten\n",
    "# =========================\n",
    "meta_utm = meta_gdf.to_crs(3006)\n",
    "water_utm = in_range.to_crs(3006)\n",
    "joined = gpd.sjoin_nearest(\n",
    "    water_utm,\n",
    "    meta_utm[[\"label\", \"island\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    distance_col=\"distance_m\"\n",
    ").to_crs(4326)\n",
    "\n",
    "# =========================\n",
    "# 7) Summary \n",
    "# =========================\n",
    "summary = (\n",
    "    joined.groupby([\"label\", \"island\"], as_index=False)\n",
    "    .agg(\n",
    "        sites=(\"geometry\", \"count\"),\n",
    "        avg_distance_m=(\"distance_m\", \"mean\"),\n",
    "    )\n",
    "    .sort_values([\"sites\"], ascending=[False])\n",
    ")\n",
    "print(\"üìä Summary drinking water:\")\n",
    "print(summary.head(1000))\n",
    "\n",
    "# =========================\n",
    "# 8) Spara filer + Folium-karta\n",
    "# =========================\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "os.makedirs(\"../kartor\", exist_ok=True)\n",
    "\n",
    "# Spara summary\n",
    "summary_csv = f\"../kartor/sat_dricksvatten_summary_{timestamp}.csv\"\n",
    "summary.to_csv(summary_csv, index=False)\n",
    "\n",
    "# Spara dricksvatten inom 200 m (GeoJSON + CSV)\n",
    "waters_geojson = f\"../kartor/sat_dricksvatten_inrange_{timestamp}.geojson\"\n",
    "waters_csv = f\"../kartor/sat_dricksvatten_inrange_{timestamp}.csv\"\n",
    "in_range[[\"id\", \"osm_type\", \"tags\", \"geometry\"]].to_file(waters_geojson, driver=\"GeoJSON\")\n",
    "in_range.drop(columns=\"geometry\").to_csv(waters_csv, index=False)\n",
    "\n",
    "# Bygg karta\n",
    "center = gdf_trail.geometry.union_all().centroid\n",
    "m = folium.Map(location=[center.y, center.x], zoom_start=9, control_scale=True)\n",
    "\n",
    "# Etapper\n",
    "colors = [\n",
    "    \"blue\",\"green\",\"purple\",\"orange\",\"darkred\",\"cadetblue\",\"lightgray\",\"darkblue\",\n",
    "    \"darkgreen\",\"pink\",\"lightblue\",\"lightgreen\",\"gray\",\"black\",\"beige\",\"lightred\"\n",
    "]\n",
    "for i, row in meta_gdf.reset_index(drop=True).iterrows():\n",
    "    color = colors[i % len(colors)]\n",
    "    popup = f\"<b>{row['label']}</b><br>√ñ: {row['island']}\"\n",
    "    folium.GeoJson(\n",
    "        data=mapping(row.geometry),\n",
    "        name=row[\"label\"],\n",
    "        style_function=lambda x, c=color: {\"color\": c, \"weight\": 3}\n",
    "    ).add_child(folium.Popup(popup, max_width=350)).add_to(m)\n",
    "\n",
    "# Buffert\n",
    "folium.GeoJson(\n",
    "    data=mapping(buffer_union),\n",
    "    name=\"200 m Buffert\",\n",
    "    style_function=lambda x: {'fillColor': '#0000ff', 'color': '#0000ff', 'weight': 1, 'fillOpacity': 0.1}\n",
    ").add_to(m)\n",
    "\n",
    "# Hj√§lpare f√∂r bilder/Commons/Wikidata\n",
    "def _split_multi(s: str):\n",
    "    return [p.strip() for p in re.split(r'[;|]', s) if p.strip()]\n",
    "\n",
    "def commons_thumb_html(value: str, width: int = 300) -> str:\n",
    "    v = value.strip()\n",
    "    lower = v.lower()\n",
    "    if lower.startswith(\"category:\"):\n",
    "        url = f\"https://commons.wikimedia.org/wiki/{quote(v.replace(' ', '_'))}\"\n",
    "        return f'<a href=\"{url}\" target=\"_blank\">{v}</a>'\n",
    "    if any(lower.startswith(p) for p in (\"file:\", \"image:\", \"media:\")):\n",
    "        filename = v.split(\":\", 1)[1]\n",
    "    else:\n",
    "        filename = v\n",
    "    fn_enc = quote(filename.replace(\" \", \"_\"))\n",
    "    img = f\"https://commons.wikimedia.org/wiki/Special:FilePath/{fn_enc}?width={width}\"\n",
    "    page = f\"https://commons.wikimedia.org/wiki/File:{fn_enc}\"\n",
    "    return f'<a href=\"{page}\" target=\"_blank\"><img src=\"{img}\" style=\"max-width:{width}px\"></a>'\n",
    "\n",
    "def link_commons_title(value: str) -> str:\n",
    "    url = f\"https://commons.wikimedia.org/wiki/{quote(value.replace(' ', '_'))}\"\n",
    "    return f'<a href=\"{url}\" target=\"_blank\">{value}</a>'\n",
    "\n",
    "def link_wikidata(qid: str) -> str:\n",
    "    if not qid:\n",
    "        return \"\"\n",
    "    q = qid.strip().upper()\n",
    "    if q.startswith(\"Q\") and q[1:].isdigit():\n",
    "        return f'<a href=\"https://www.wikidata.org/wiki/{q}\" target=\"_blank\">{q}</a>'\n",
    "    return q\n",
    "\n",
    "def images_html_from_tags(tags: dict, max_thumbs: int = 2, thumb_width: int = 300) -> str:\n",
    "    candidates = []\n",
    "    for k, v in tags.items():\n",
    "        if not v:\n",
    "            continue\n",
    "        if k == \"image\" or k.startswith(\"image:\"):\n",
    "            candidates.append(v)\n",
    "    wc = tags.get(\"wikimedia_commons\")\n",
    "    if wc:\n",
    "        candidates.extend(_split_multi(wc))\n",
    "    html_parts = []\n",
    "    for val in candidates:\n",
    "        val = val.strip()\n",
    "        if not val:\n",
    "            continue\n",
    "        if val.startswith(\"http://\") or val.startswith(\"https://\"):\n",
    "            html_parts.append(f'<a href=\"{val}\" target=\"_blank\"><img src=\"{val}\" style=\"max-width:{thumb_width}px\"></a>')\n",
    "        else:\n",
    "            html_parts.append(commons_thumb_html(val, width=thumb_width))\n",
    "        if len(html_parts) >= max_thumbs:\n",
    "            break\n",
    "    return \"<br>\".join(html_parts)\n",
    "\n",
    "# Dricksvatten-lager\n",
    "drinkingwaters_fg = FeatureGroup(name=\"Dricksvatten inom 200 m\")\n",
    "for _, r in joined.to_crs(4326).iterrows():\n",
    "    tags = r.get(\"tags\", {}) or {}\n",
    "    osm_path = ('node' if r['osm_type'] == 'node' else 'way' if r['osm_type'] == 'way' else 'relation')\n",
    "    osm_url = f\"https://www.openstreetmap.org/{osm_path}/{r['id']}\"\n",
    "    pics_html = images_html_from_tags(tags, max_thumbs=2, thumb_width=300)\n",
    "    note_sv = tags.get(\"note\")\n",
    "    note_en = tags.get(\"note:en\")\n",
    "    wc = tags.get(\"wikimedia_commons\")\n",
    "    commons_links = \", \".join(link_commons_title(x) for x in _split_multi(wc)) if wc else \"\"\n",
    "    operator = tags.get(\"operator\")\n",
    "    operator_wd = link_wikidata(tags.get(\"operator:wikidata\", \"\"))\n",
    "    access = tags.get(\"access\")\n",
    "\n",
    "    popup_html = f\"\"\"\n",
    "    <b><a href=\"{osm_url}\" target=\"_blank\">OSM-objekt ({r['osm_type']})</a></b><br>\n",
    "    Etapp: <b>{r.get('label','')}</b> (√ñ: {r.get('island','')})<br>\n",
    "    Avst√•nd: ~{round(r.get('distance_m', 0) or 0, 1)} m<br>\n",
    "    \"\"\"\n",
    "    if pics_html:\n",
    "        popup_html += pics_html + \"<br>\"\n",
    "    if note_sv:\n",
    "        popup_html += f\"Not: {note_sv}<br>\"\n",
    "    if note_en:\n",
    "        popup_html += f\"Note (en): {note_en}<br>\"\n",
    "    if commons_links:\n",
    "        popup_html += f\"Wikimedia Commons: {commons_links}<br>\"\n",
    "    if operator:\n",
    "        popup_html += f\"Operat√∂r: {operator}<br>\"\n",
    "    if operator_wd:\n",
    "        popup_html += f\"Operat√∂r (Wikidata): {operator_wd}<br>\"\n",
    "    if access:\n",
    "        popup_html += f\"Access: {access}<br>\"\n",
    "\n",
    "    Marker(\n",
    "        location=[r.geometry.y, r.geometry.x],\n",
    "        popup=Popup(popup_html, max_width=360),\n",
    "        icon=Icon(color=\"green\", icon=\"tint\")\n",
    "    ).add_to(drinkingwaters_fg)\n",
    "\n",
    "drinkingwaters_fg.add_to(m)\n",
    "LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "map_html = f\"../kartor/Issue_139_dricksvatten_nara_stockholm_archipelago_trail_{timestamp}.html\"\n",
    "m.save(map_html)\n",
    "\n",
    "print(\"‚úÖ Klart!\")\n",
    "print(f\"‚Ä¢ Summary CSV: {summary_csv}\")\n",
    "print(f\"‚Ä¢ Dricksvatten GeoJSON: {waters_geojson}\")\n",
    "print(f\"‚Ä¢ Dricksvatten CSV: {waters_csv}\")\n",
    "print(f\"‚Ä¢ Karta: {map_html}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9194a-03df-46f6-b854-f069c296229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geopandas shapely folium requests SPARQLWrapper --quiet\n",
    "\n",
    "import os, re, requests\n",
    "from urllib.parse import quote\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString, MultiLineString, Point, mapping\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from collections import defaultdict\n",
    "import folium\n",
    "from folium import Marker, Icon, FeatureGroup, LayerControl, Popup\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) H√§mta SAT-etapper via Wikidata\n",
    "# =========================\n",
    "print(\"üîç H√§mtar SAT-etapper fr√•n Wikidata...\")\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "SELECT ?item ?itemLabel ?islandLabel ?osmid WHERE {\n",
    "  ?item wdt:P361 wd:Q131318799;\n",
    "        wdt:P31 wd:Q2143825;\n",
    "        wdt:P402 ?osmid.\n",
    "  OPTIONAL { ?item wdt:P706 ?island. }\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"sv,en\". }\n",
    "}\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "etapper = []\n",
    "for r in results[\"results\"][\"bindings\"]:\n",
    "    etapper.append({\n",
    "        \"id\": r[\"osmid\"][\"value\"],\n",
    "        \"label\": r.get(\"itemLabel\", {}).get(\"value\", \"\"),\n",
    "        \"island\": r.get(\"islandLabel\", {}).get(\"value\", \"\")\n",
    "    })\n",
    "osm_ids = [e['id'] for e in etapper]\n",
    "print(f\"‚úÖ Hittade {len(osm_ids)} etapper med OSM-relationer\")\n",
    "\n",
    "# =========================\n",
    "# 2) H√§mta geometrier per relation via Overpass\n",
    "# =========================\n",
    "print(\"üì° H√§mtar geometrier fr√•n Overpass (per relation)...\")\n",
    "overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "geom_per_rel = {}\n",
    "all_lines = []\n",
    "\n",
    "for rel_id in osm_ids:\n",
    "    q = f\"\"\"\n",
    "    [out:json][timeout:60];\n",
    "    relation({rel_id});\n",
    "    (._;>>;);\n",
    "    out geom;\n",
    "    \"\"\"\n",
    "    r = requests.post(overpass_url, data={\"data\": q})\n",
    "    if r.status_code != 200:\n",
    "        print(f\"‚ö†Ô∏è Fel f√∂r relation {rel_id}: {r.text[:200]}...\")\n",
    "        continue\n",
    "    rel_geoms = []\n",
    "    for el in r.json().get(\"elements\", []):\n",
    "        if el.get(\"type\") == \"way\" and \"geometry\" in el:\n",
    "            coords = [(pt[\"lon\"], pt[\"lat\"]) for pt in el[\"geometry\"]]\n",
    "            if len(coords) >= 2:\n",
    "                line = LineString(coords)\n",
    "                rel_geoms.append(line)\n",
    "                all_lines.append(line)\n",
    "    if rel_geoms:\n",
    "        geom_per_rel[rel_id] = rel_geoms\n",
    "\n",
    "if not all_lines:\n",
    "    raise ValueError(\"Inga geometrier hittades fr√•n OSM-relationer kopplade via Wikidata.\")\n",
    "\n",
    "# Bygg MultiLineString/LineString per etapp\n",
    "meta_rows, geom_rows = [], []\n",
    "for meta in etapper:\n",
    "    geoms = geom_per_rel.get(meta[\"id\"])\n",
    "    if not geoms:\n",
    "        print(f\"‚ö†Ô∏è Saknar geometri f√∂r {meta['label']} (rel {meta['id']}) ‚Äì hoppar √∂ver.\")\n",
    "        continue\n",
    "    meta_rows.append(meta)\n",
    "    geom_rows.append(MultiLineString(geoms) if len(geoms) > 1 else geoms[0])\n",
    "\n",
    "gdf_trail = gpd.GeoDataFrame(geometry=all_lines, crs=\"EPSG:4326\")\n",
    "meta_gdf = gpd.GeoDataFrame(meta_rows, geometry=geom_rows, crs=\"EPSG:4326\")\n",
    "print(f\"üß≠ Etapper med geometri: {len(meta_gdf)}\")\n",
    "\n",
    "# =========================\n",
    "# 3) Buffert 200 m (Shapely 2: union_all)\n",
    "# =========================\n",
    "print(\"üßÆ Skapar 200 m-buffert...\")\n",
    "buffer_utm = gdf_trail.to_crs(3006).buffer(200)   # 200 m i SWEREF 99 TM\n",
    "buffer_wgs84 = buffer_utm.to_crs(4326)            # tillbaka till WGS84\n",
    "buffer_union = buffer_wgs84.union_all()           # EN (multi)polygon\n",
    "\n",
    "# =========================\n",
    "# 4) H√§mta dricksvatten (noder/ways/relationer) via nwr + out center\n",
    "# =========================\n",
    "bbox = gdf_trail.total_bounds  # [minx, miny, maxx, maxy]\n",
    "q_water = f\"\"\"\n",
    "[out:json][timeout:60];\n",
    "nwr[\"amenity\"=\"drinking_water\"]({bbox[1]},{bbox[0]},{bbox[3]},{bbox[2]});\n",
    "out center;\n",
    "\"\"\"\n",
    "print(\"üíß H√§mtar dricksvatten (nwr) fr√•n Overpass...\")\n",
    "r = requests.post(overpass_url, data={\"data\": q_water})\n",
    "elements = r.json().get(\"elements\", [])\n",
    "\n",
    "waters = []\n",
    "for el in elements:\n",
    "    tags = el.get(\"tags\", {})\n",
    "    typ = el.get(\"type\")\n",
    "    if typ == \"node\":\n",
    "        lon, lat = el[\"lon\"], el[\"lat\"]\n",
    "    else:\n",
    "        center = el.get(\"center\")\n",
    "        if not center:\n",
    "            continue\n",
    "        lon, lat = center[\"lon\"], center[\"lat\"]\n",
    "    waters.append({\n",
    "        \"geometry\": Point(lon, lat),\n",
    "        \"tags\": tags,\n",
    "        \"id\": el[\"id\"],\n",
    "        \"osm_type\": typ,\n",
    "        # Dricksvatten saknar normalt \"count\"-taggar; anta 1 punkt per OSM-objekt\n",
    "        \"water_sites\": 1,\n",
    "    })\n",
    "\n",
    "gdf_water = gpd.GeoDataFrame(waters, crs=\"EPSG:4326\")\n",
    "print(f\"‚úÖ Hittade {len(gdf_water)} dricksvatten-objekt inom bbox\")\n",
    "\n",
    "# =========================\n",
    "# 5) Filtrera till de som ligger inom/vid 200 m-bufferten\n",
    "# =========================\n",
    "in_range = gdf_water[gdf_water.geometry.covered_by(buffer_union)]\n",
    "print(f\"‚úÖ {len(in_range)} dricksvatten-objekt inom/vid 200 m\")\n",
    "\n",
    "# =========================\n",
    "# 6) N√§rmaste etapp per dricksvatten\n",
    "# =========================\n",
    "meta_utm = meta_gdf.to_crs(3006)\n",
    "water_utm = in_range.to_crs(3006)\n",
    "joined = gpd.sjoin_nearest(\n",
    "    water_utm,\n",
    "    meta_utm[[\"label\", \"island\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    distance_col=\"distance_m\"\n",
    ").to_crs(4326)\n",
    "\n",
    "# =========================\n",
    "# 7) Summary \n",
    "# =========================\n",
    "summary = (\n",
    "    joined.groupby([\"label\", \"island\"], as_index=False)\n",
    "    .agg(\n",
    "        sites=(\"geometry\", \"count\"),        # antal OSM-objekt (noder/ways/relationer)\n",
    "        avg_distance_m=(\"distance_m\", \"mean\"),\n",
    "    )\n",
    "    .sort_values([\"sites\"], ascending=[False])\n",
    ")\n",
    "print(\"üìä Summary drinking water:\")\n",
    "print(summary.head(1000))\n",
    "\n",
    "# =========================\n",
    "# 8) Spara filer + Folium-karta\n",
    "# =========================\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "os.makedirs(\"../kartor\", exist_ok=True)\n",
    "\n",
    "# Spara summary\n",
    "summary_csv = f\"../kartor/sat_dricksvatten_summary_{timestamp}.csv\"\n",
    "summary.to_csv(summary_csv, index=False)\n",
    "\n",
    "# Spara dricksvatten inom 200 m (GeoJSON + CSV)\n",
    "waters_geojson = f\"../kartor/sat_dricksvatten_inrange_{timestamp}.geojson\"\n",
    "waters_csv = f\"../kartor/sat_dricksvatten_inrange_{timestamp}.csv\"\n",
    "in_range[[\"id\", \"osm_type\", \"tags\", \"geometry\"]].to_file(waters_geojson, driver=\"GeoJSON\")\n",
    "in_range.drop(columns=\"geometry\").to_csv(waters_csv, index=False)\n",
    "\n",
    "# Bygg karta\n",
    "center = gdf_trail.geometry.union_all().centroid\n",
    "m = folium.Map(location=[center.y, center.x], zoom_start=9, control_scale=True)\n",
    "\n",
    "# Etapper\n",
    "colors = [\n",
    "    \"blue\",\"green\",\"purple\",\"orange\",\"darkred\",\"cadetblue\",\"lightgray\",\"darkblue\",\n",
    "    \"darkgreen\",\"pink\",\"lightblue\",\"lightgreen\",\"gray\",\"black\",\"beige\",\"lightred\"\n",
    "]\n",
    "for i, row in meta_gdf.reset_index(drop=True).iterrows():\n",
    "    color = colors[i % len(colors)]\n",
    "    popup = f\"<b>{row['label']}</b><br>√ñ: {row['island']}\"\n",
    "    folium.GeoJson(\n",
    "        data=mapping(row.geometry),\n",
    "        name=row[\"label\"],\n",
    "        style_function=lambda x, c=color: {\"color\": c, \"weight\": 3}\n",
    "    ).add_child(folium.Popup(popup, max_width=350)).add_to(m)\n",
    "\n",
    "# Buffert\n",
    "folium.GeoJson(\n",
    "    data=mapping(buffer_union),\n",
    "    name=\"200 m Buffert\",\n",
    "    style_function=lambda x: {'fillColor': '#0000ff', 'color': '#0000ff', 'weight': 1, 'fillOpacity': 0.1}\n",
    ").add_to(m)\n",
    "\n",
    "# Dricksvatten\n",
    "def _split_multi(s: str):\n",
    "    \"\"\"Split tag lists like 'A;B|C' into ['A','B','C'].\"\"\"\n",
    "    return [p.strip() for p in re.split(r'[;|]', s) if p.strip()]\n",
    "\n",
    "def commons_thumb_html(value: str, width: int = 300) -> str:\n",
    "    \"\"\"\n",
    "    Build a clickable thumbnail for a Commons file, or a link if it's a Category.\n",
    "    Accepts 'File:...', 'Image:...', 'Media:...', 'Category:...', or bare filename.\n",
    "    \"\"\"\n",
    "    v = value.strip()\n",
    "    lower = v.lower()\n",
    "    if lower.startswith(\"category:\"):\n",
    "        url = f\"https://commons.wikimedia.org/wiki/{quote(v.replace(' ', '_'))}\"\n",
    "        return f'<a href=\"{url}\" target=\"_blank\">{v}</a>'\n",
    "\n",
    "    # Extract filename\n",
    "    if any(lower.startswith(p) for p in (\"file:\", \"image:\", \"media:\")):\n",
    "        filename = v.split(\":\", 1)[1]\n",
    "    else:\n",
    "        filename = v\n",
    "    fn_enc = quote(filename.replace(\" \", \"_\"))\n",
    "    img = f\"https://commons.wikimedia.org/wiki/Special:FilePath/{fn_enc}?width={width}\"\n",
    "    page = f\"https://commons.wikimedia.org/wiki/File:{fn_enc}\"\n",
    "    return f'<a href=\"{page}\" target=\"_blank\"><img src=\"{img}\" style=\"max-width:{width}px\"></a>'\n",
    "\n",
    "def link_commons_title(value: str) -> str:\n",
    "    \"\"\"Link any Commons title (File:/Category:/Gallery) to its page.\"\"\"\n",
    "    url = f\"https://commons.wikimedia.org/wiki/{quote(value.replace(' ', '_'))}\"\n",
    "    return f'<a href=\"{url}\" target=\"_blank\">{value}</a>'\n",
    "\n",
    "def link_wikidata(qid: str) -> str:\n",
    "    \"\"\"Link a Wikidata Q-id if it looks like one, else return raw.\"\"\"\n",
    "    if not qid:\n",
    "        return \"\"\n",
    "    q = qid.strip().upper()\n",
    "    if q.startswith(\"Q\") and q[1:].isdigit():\n",
    "        return f'<a href=\"https://www.wikidata.org/wiki/{q}\" target=\"_blank\">{q}</a>'\n",
    "    return q\n",
    "\n",
    "def images_html_from_tags(tags: dict, max_thumbs: int = 2, thumb_width: int = 300) -> str:\n",
    "    \"\"\"\n",
    "    Collect images from:\n",
    "      - image, image:0, image:1, ... (absolute URLs or Commons titles)\n",
    "      - wikimedia_commons (File:/Category:/Gallery) ‚Äî supports multiple separated by ; or |\n",
    "    Returns HTML for up to max_thumbs thumbnails/links.\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    # image + image:* keys\n",
    "    for k, v in tags.items():\n",
    "        if not v:\n",
    "            continue\n",
    "        if k == \"image\" or k.startswith(\"image:\"):\n",
    "            candidates.append(v)\n",
    "\n",
    "    # wikimedia_commons may contain multiple entries\n",
    "    wc = tags.get(\"wikimedia_commons\")\n",
    "    if wc:\n",
    "        candidates.extend(_split_multi(wc))\n",
    "\n",
    "    html_parts = []\n",
    "    for val in candidates:\n",
    "        val = val.strip()\n",
    "        if not val:\n",
    "            continue\n",
    "        if val.startswith(\"http://\") or val.startswith(\"https://\"):\n",
    "            # Direct URL (may be an image or a page)\n",
    "            html_parts.append(f'<a href=\"{val}\" target=\"_blank\"><img src=\"{val}\" style=\"max-width:{thumb_width}px\"></a>')\n",
    "        else:\n",
    "            # Assume Commons title\n",
    "            html_parts.append(commons_thumb_html(val, width=thumb_width))\n",
    "\n",
    "        if len(html_parts) >= max_thumbs:\n",
    "            break\n",
    "\n",
    "    return \"<br>\".join(html_parts)\n",
    "\n",
    "drinkingwaters_fg = FeatureGroup(name=\"Dricksvatten inom 200 m\")\n",
    "for _, r in joined.to_crs(4326).iterrows():\n",
    "    tags = r.get(\"tags\", {}) or {}\n",
    "\n",
    "    # Build OSM object link\n",
    "    osm_path = ('node' if r['osm_type'] == 'node'\n",
    "                else 'way' if r['osm_type'] == 'way'\n",
    "                else 'relation')\n",
    "    osm_url = f\"https://www.openstreetmap.org/{osm_path}/{r['id']}\"\n",
    "\n",
    "    # Pictures (image*, wikimedia_commons)\n",
    "    pics_html = images_html_from_tags(tags, max_thumbs=2, thumb_width=300)\n",
    "\n",
    "    # Notes\n",
    "    note_sv = tags.get(\"note\")\n",
    "    note_en = tags.get(\"note:en\")\n",
    "\n",
    "    # Commons links (all entries, not just thumbs)\n",
    "    commons_entries = []\n",
    "    wc = tags.get(\"wikimedia_commons\")\n",
    "    if wc:\n",
    "        commons_entries = _split_multi(wc)\n",
    "    commons_links = \", \".join(link_commons_title(x) for x in commons_entries) if commons_entries else \"\"\n",
    "\n",
    "    # Operator + Wikidata\n",
    "    operator = tags.get(\"operator\")\n",
    "    operator_wd = link_wikidata(tags.get(\"operator:wikidata\", \"\"))\n",
    "\n",
    "    # Access\n",
    "    access = tags.get(\"access\")\n",
    "\n",
    "    # Popup HTML\n",
    "    popup_html = f\"\"\"\n",
    "    <b><a href=\"{osm_url}\" target=\"_blank\">OSM-objekt ({r['osm_type']})</a></b><br>\n",
    "    Etapp: <b>{r.get('label','')}</b> (√ñ: {r.get('island','')})<br>\n",
    "    Avst√•nd: ~{round(r.get('distance_m', 0) or 0, 1)} m<br>\n",
    "    \"\"\"\n",
    "\n",
    "    if pics_html:\n",
    "        popup_html += pics_html + \"<br>\"\n",
    "\n",
    "    if note_sv:\n",
    "        popup_html += f\"Not: {note_sv}<br>\"\n",
    "    if note_en:\n",
    "        popup_html += f\"Note (en): {note_en}<br>\"\n",
    "\n",
    "    if commons_links:\n",
    "        popup_html += f\"Wikimedia Commons: {commons_links}<br>\"\n",
    "\n",
    "    if operator:\n",
    "        popup_html += f\"Operat√∂r: {operator}<br>\"\n",
    "    if operator_wd:\n",
    "        popup_html += f\"Operat√∂r (Wikidata): {operator_wd}<br>\"\n",
    "\n",
    "    if access:\n",
    "        popup_html += f\"Access: {access}<br>\"\n",
    "\n",
    "    Marker(\n",
    "        location=[r.geometry.y, r.geometry.x],\n",
    "        popup=Popup(popup_html, max_width=360),\n",
    "        icon=Icon(color=\"green\", icon=\"tint\")\n",
    "    ).add_to(drinkingwaters_fg)\n",
    "\n",
    "drinkingwaters_fg.add_to(m)\n",
    "LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "map_html = f\"../kartor/Issue_139_dricksvatten_nara_stockholm_archipelago_trail_{timestamp}.html\"\n",
    "m.save(map_html)\n",
    "\n",
    "print(\"‚úÖ Klart!\")\n",
    "print(f\"‚Ä¢ Summary CSV: {summary_csv}\")\n",
    "print(f\"‚Ä¢ Dricksvatten GeoJSON: {waters_geojson}\")\n",
    "print(f\"‚Ä¢ Dricksvatten CSV: {waters_csv}\")\n",
    "print(f\"‚Ä¢ Karta: {map_html}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a9bfc-389f-4742-9c1d-a75cc8f2487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, time\n",
    "NOTES_API = \"https://api.openstreetmap.org/api/0.6/notes.json\"\n",
    "\n",
    "def _deg_buffer(lat: float, radius_m: float):\n",
    "    dlat = radius_m / 111_320.0\n",
    "    coslat = max(0.01, math.cos(math.radians(lat)))\n",
    "    dlon = dlat / coslat\n",
    "    return dlat, dlon\n",
    "\n",
    "def get_osm_notes_nearby(lat: float, lon: float, radius_m: float = 50, limit: int = 50, sleep_s: float = 0.0):\n",
    "    dlat, dlon = _deg_buffer(lat, radius_m)\n",
    "    bbox = f\"{lon-dlon:.6f},{lat-dlat:.6f},{lon+dlon:.6f},{lat+dlat:.6f}\"\n",
    "    params = {\"bbox\": bbox, \"limit\": str(limit), \"closed\": \"no\", \"sort\": \"created_at\"}\n",
    "    try:\n",
    "        resp = requests.get(NOTES_API, params=params, timeout=25)\n",
    "        if sleep_s: time.sleep(sleep_s)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "    except Exception as e:\n",
    "        return [{\"id\": None, \"status\": \"error\", \"last_text\": f\"(notes API-fel: {e})\", \"last_date\": None}]\n",
    "    out = []\n",
    "    for feat in data.get(\"features\", []):\n",
    "        props = feat.get(\"properties\", {})\n",
    "        comments = props.get(\"comments\", [])\n",
    "        last_text, last_date = (comments[-1].get(\"text\"), comments[-1].get(\"date\")) if comments else (None, None)\n",
    "        out.append({\"id\": props.get(\"id\"), \"status\": props.get(\"status\"), \"last_text\": last_text, \"last_date\": last_date})\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f35a90c-6c87-4746-b317-12d5a8fd754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 9) Tabell √∂ver alla dricksvattenobjekt med extra metadata\n",
    "# =========================\n",
    "rows = []\n",
    "for i, r in joined.iterrows():\n",
    "    tags = r.get(\"tags\", {}) or {}\n",
    "    osm_num = f\"{r['osm_type']}/{r['id']}\"\n",
    "    lat, lon = r.geometry.y, r.geometry.x\n",
    "\n",
    "    # --- OSM Notes inom 50 m via OSM Notes API ---\n",
    "    notes = get_osm_notes_nearby(lat, lon, radius_m=50, limit=50, sleep_s=0.0)\n",
    "    note_texts  = [n[\"last_text\"] for n in notes if n.get(\"last_text\")]\n",
    "    note_ids    = [str(n[\"id\"]) for n in notes if n.get(\"id\")]\n",
    "    note_links  = [f\"https://www.openstreetmap.org/note/{nid}\" for nid in note_ids]\n",
    "\n",
    "    # --- Operator & felanm√§lan ---\n",
    "    operator = tags.get(\"operator\")\n",
    "    operator_wd = tags.get(\"operator:wikidata\")\n",
    "    contact_url = tags.get(\"contact:website\") or tags.get(\"operator:website\")\n",
    "    contact_phone = tags.get(\"contact:phone\")\n",
    "\n",
    "    # --- Wikimedia Commons ---\n",
    "    commons = tags.get(\"wikimedia_commons\")\n",
    "\n",
    "    # --- Senaste check ---\n",
    "    check_date = tags.get(\"check_date\")\n",
    "    start_date = tags.get(\"start_date\")  # om den finns\n",
    "\n",
    "    row = {\n",
    "        \"number\": i + 1,\n",
    "        \"OSM Number\": osm_num,\n",
    "        \"Wikidata Number\": tags.get(\"wikidata\") or operator_wd,\n",
    "        \"label\": r.get(\"label\"),\n",
    "        \"island\": r.get(\"island\"),\n",
    "        \"access\": tags.get(\"access\"),\n",
    "        \"drinking_water\": tags.get(\"drinking_water\"),\n",
    "        \"note\": tags.get(\"note\"),\n",
    "        \"note:en\": tags.get(\"note:en\"),\n",
    "        \"operator\": operator,\n",
    "        \"operator:wikidata\": operator_wd,\n",
    "        \"contact_url\": contact_url,\n",
    "        \"contact_phone\": contact_phone,\n",
    "        \"wikimedia_commons\": commons,\n",
    "        \"image\": tags.get(\"image\"),\n",
    "        \"image:license\": tags.get(\"image:license\"),\n",
    "        \"image:license:wikidata\": tags.get(\"image:license:wikidata\"),\n",
    "        \"check_date\": check_date,\n",
    "        \"start_date\": start_date,\n",
    "        \"osm_notes_nearby\": \" | \".join(note_texts) if note_texts else \"\",\n",
    "        \"osm_note_ids\": \", \".join(note_ids) if note_ids else \"\",\n",
    "        \"osm_note_links\": \", \".join(note_links) if note_links else \"\",\n",
    "    }\n",
    "\n",
    "    # --- Fixme-logik ---\n",
    "    fixme = []\n",
    "    if not tags.get(\"drinking_water\"):\n",
    "        fixme.append(\"saknar drinking_water-tag\")\n",
    "    elif (tags.get(\"drinking_water\") or \"\").lower() == \"unknown\":\n",
    "        fixme.append(\"dricksvatten ej testat / unknown\")\n",
    "    if not tags.get(\"access\"):\n",
    "        fixme.append(\"saknar access\")\n",
    "    if not commons and not tags.get(\"image\"):\n",
    "        fixme.append(\"saknar bild\")\n",
    "    if tags.get(\"image\") and not (tags.get(\"image:license\") or tags.get(\"image:license:wikidata\")):\n",
    "        fixme.append(\"bild utan licensinfo\")\n",
    "    if not operator:\n",
    "        fixme.append(\"saknar operator\")\n",
    "    if not (tags.get(\"wikidata\") or operator_wd):\n",
    "        fixme.append(\"saknar l√§nk till Wikidata\")\n",
    "    if not check_date:\n",
    "        fixme.append(\"saknar check_date\")\n",
    "    if note_texts:\n",
    "        fixme.append(\"kolla n√§rliggande OSM Note\")\n",
    "\n",
    "    row[\"fixme\"] = \"; \".join(fixme) if fixme else \"\"\n",
    "    rows.append(row)\n",
    "\n",
    "df_water = pd.DataFrame(rows)\n",
    "\n",
    "print(\"‚úÖ Klart!\")\n",
    "\n",
    "# Spara som CSV + HTML + Markdown\n",
    "table_csv = f\"../kartor/sat_Issue_139_dricksvatten_table_{timestamp}.csv\"\n",
    "print(f\"‚Ä¢ Table_CSV: {table_csv}\")\n",
    "\n",
    "df_water.to_csv(table_csv, index=False)\n",
    "\n",
    "table_html = f\"../kartor/sat_Issue_139_dricksvatten_table_{timestamp}.html\"\n",
    "print(f\"‚Ä¢ Table_htlm: {table_html}\")\n",
    "df_water.to_html(table_html, index=False, escape=False)\n",
    "\n",
    "table_md = f\"../kartor/sat_Issue_139_dricksvatten_table_{timestamp}.md\"\n",
    "print(f\"‚Ä¢ Table_md: {table_md}\")\n",
    "with open(table_md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(df_water.head(20).to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5054f97d-74d6-46eb-bb02-a9d6e7de4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itables import init_notebook_mode, show\n",
    "from itables import options as itbl_options\n",
    "\n",
    "init_notebook_mode(all_interactive=True)\n",
    "itbl_options.warn_on_undocumented_option = False  \n",
    "\n",
    "# visa upp till 200 rader\n",
    "itbl_options.lengthMenu = [10, 25, 50, 100, 200, -1]  # -1 = alla\n",
    "itbl_options.pageLength = 200\n",
    "#itbl_options.dom = 'lfrtip'\n",
    "#itbl_options.searchHighlight = True\n",
    "\n",
    "show(df_water, scrollX=True, autoWidth=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d31a6-10cf-4d5a-84ea-7d239942d620",
   "metadata": {},
   "outputs": [],
   "source": [
    " # End timer and calculate duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print current date and total time\n",
    "print(\"Date:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46456812-9f47-4f73-a947-1ac6a1ea69b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
